text,link,title,Category,Type
"[""Cohere For AI launched in June of this year as a non-profit research lab and community dedicated to contributing fundamental research in machine learning. The vision for the lab was simple but ambitious: change how, where, and by whom research is done. Since that launch, the C4AI team has been hard at work publishing and promoting fundamental ML research, growing our community, and creating programs designed to provide more entry points into ML research. Now that it's the end of the year, we think it's a good time to pause and reflect on everything we've done so far. Here's a look back at the highlights from the first six months at Cohere For AI!"", 'The field of machine learning moves fast, and the research published by Cohere For AI and Cohere technical staff is contributing to that momentum. Led by the work of Sara Hooker, Head of Cohere For AI, our lab has published a range of cutting-edge ML research papers, including metadata archeology, NLP efficiencies, and compression on multilingual models. This research is the result of collaborations across 20+ institutions and organizations, including the University of Toronto, the University of Waterloo, University College London, Cambridge University, and Google Research, to name a few! 2022 also saw Cohere For AI join Cohereâ€™s technical staff in presenting research at several major ML conferences, including NAACL, ICML, Deep Learning Indaba, RIIAA, NeurIPS, and EMNLP. Presenting keynote addresses at Deep Learning Indaba and RIIAA and organizing the Broadening Research Collaborations workshop at NeurIPS were particularly special moments to share the values of expanding research access and inclusion at the heart of our lab. Weâ€™re proud to have contributed fundamental research that advances the field of machine learning and fosters the collaborations vital to ensuring responsible innovation.', 'A key part of Cohere For AIâ€™s commitment to solving complex machine learning problems is providing more entry points for talented people to participate in research. We launched the Cohere For AI Scholars Program this September to help close the gap between research experience and opportunity. The Scholars Program is designed to provide an open and supportive research environment that doesnâ€™t insist on a particular degree or publication history to participate. We were humbled and excited by our Scholars Program applicants and canâ€™t wait to welcome our first cohort in January!', 'The C4AI Community launched alongside Cohere For AI as a space for anyone interested in machine learningâ€”from lifelong learners to seasoned engineers and all points in betweenâ€”to connect and collaborate. In the span of six short months, the C4AI Community has grown to include over 800 members from 90+ countries around the world. Even more impressive than the numbers is the spirit of generosity, creativity, and collaboration that animates our community. From reading groups to mentorship to lightning talks, community members constantly share their skills to elevate and empower their fellow members. ', 'To cap off our first six months, Cohere For AI invited some of the best ML researchers to share their experiences with our community. We were honoured to host Samy Bengio and Pablo Samuel Castro to launch our Fireside Chats series and hear more about their inspiring research journeys. To keep the sparks flying, we also hosted a series of technical talks designed to spread the word about the latest advancements in ML research and practice. We have even more exciting events planned for 2023, so sign up for our mailing list and donâ€™t miss a moment!', 'We are grateful for all of your support over the last six months. Thank you for sharing our work, packing our events, stopping by our conference booths to say hello, and joining us as we explore the unknown, together. Apply to join our community and follow our journey on Twitter and LinkedIn today.Onwards to 2023 with more collaboration, more creativity, more events, and more innovation!', ""Senior Google/YouTube Exec to join Cohere, focusing on the enormous commercial opportunity of NLP.Since Cohereâ€™s beginning, we've been focused on unlocking the vast potential of language for every developer and business. To do that, weâ€™re making natural language processing more accessible to developers, including those without"", 'Develop, test, and experiment with the industryâ€™s first multilingual text understanding model that supports 100+ languages Humans speak over 71001 languages, yet the majority of language models only support the English language. This makes it incredibly challenging to build products and projects using multilingual language understanding. Cohereâ€™s mission', 'In this multi-part guide, we will go through everything that you need to know about generative AI with Cohereâ€™s large language models (LLMs). In Part 1, we talk about model prompting.']",https://txt.cohere.ai/c4ai-2022/,"Exploring the Unknown, Together: 2022 at Cohere For AI",Research,Blog
"[""Since Cohereâ€™s beginning, we've been focused on unlocking the vast potential of language for every developer and business. To do that, weâ€™re making natural language processing more accessible to developers, including those without big tech resources or specialized teams. In turn, more businesses have been able to tap into the power of NLP. Just last month, independent research from Stanford confirmed that Cohere has built one of the most accurate commercially available large language models in the world. While Iâ€™m incredibly proud of the progress weâ€™ve made, weâ€™re just getting started. "", ""Today, Iâ€™m thrilled to announce Martin Kon as Cohereâ€™s new President & COO. From his role as CFO of Google's YouTube division (known internally as Business Finance Officer), Martin brings extensive experience delivering innovative products to market, optimizing existing ones, and creating new revenue streams. At YouTube, Martin led global strategy, finance, business operations and commercial data analytics functions. His team worked closely with stakeholders across YouTube and Google to launch and optimize many new products and businesses such as YT Shorts, rolling them out to YouTube's two billion plus users and millions of creators. He managed a sustainable balance of revenue, growth and margin for YouTubeâ€™s multi-billion dollar global business â€” truly operating at scale. Before joining Google, Martin was Senior Partner & Managing Director at Boston Consulting Group, and had over 20 years experience advising C-Suite executives at major enterprises around the world, especially in tech, media, and telecoms."", 'Martin will join Cohere on February 1, focused on understanding enterprise customer needs, bringing commercial products and solutions to market, and helping businesses realize enormous value from harnessing the power of language models. With Martinâ€™s network and experience, I look forward to ushering in Cohereâ€™s next chapter, one where we establish ourselves as the commercial leader of language AI. ', 'Massive strides have been made in artificial intelligence, but to date, companies have focused primarily on research. Cohereâ€™s focus is on helping businesses of all sizes better take advantage of language models in the real world â€” whether through predictive text generation like in copywriting, or through other functions like search, conversational AI, summarization and content moderation. ', ""Every business uses text. In fact, nearly all data generated by humans is in the form of language, but few companies today have the resources to leverage it. That's why we believe understanding human language is the next frontier for artificial intelligence. And thatâ€™s why, regardless of industry, size, or geography, every business stands to benefit from NLP. "", 'As an experienced global leader with the know-how to engage with global enterprises to understand their needs, bring new in-demand products to market, and operate at scale, Martin will be instrumental in addressing the massive commercial opportunities of NLP for business. Please join me in welcoming him to Cohere.', 'Interested in joining our growing team? Check out open positions on our careers page.', 'Looking back at the moments that shaped the first six months of C4AI Cohere For AI launched in June of this year as a non-profit research lab and community dedicated to contributing fundamental research in machine learning. The vision for the lab was simple but ambitious: change how, where, and', 'Develop, test, and experiment with the industryâ€™s first multilingual text understanding model that supports 100+ languages Humans speak over 71001 languages, yet the majority of language models only support the English language. This makes it incredibly challenging to build products and projects using multilingual language understanding. Cohereâ€™s mission', 'In this multi-part guide, we will go through everything that you need to know about generative AI with Cohereâ€™s large language models (LLMs). In Part 1, we talk about model prompting.']",https://txt.cohere.ai/martin-kon/,Cohere Welcomes Martin Kon as President & COO,Press,Blog
"['Humans speak over 71001 languages, yet the majority of language models only support the English language. This makes it incredibly challenging to build products and projects using multilingual language understanding. Cohereâ€™s mission is to solve that by empowering our developers with technology that possesses the power of language. Thatâ€™s why today weâ€™re introducing our first multilingual text understanding model that supports over 100 languages and delivers 3X better performance than existing open-source models. This will enable new markets, countries, and global companies to better serve their customers across the globe.', 'Multilingual text understanding models are powerful models that can derive insights from text data across languages. At Cohere, weâ€™ve trained our model specifically to be used for search, content aggregation and recommendation, and zero-shot cross-lingual text classification. ', 'While many of these models are available for English, similar existing multilingual models only work well for short sentences and canâ€™t capture the meaning behind longer text. This prevents them from being used for semantic search, which typically aims to match a short query with a longer, relevant document.', 'In this blog post, we will cover three relevant use cases that showcase the power of Cohereâ€™s new multilingual model:', 'Cohereâ€™s multilingual text understanding model maps text to a semantic vector space (also known as â€œembeddingsâ€), positioning texts with a similar meaning in close proximity. This process unlocks a range of valuable use cases for multilingual settings. For example, one can map a query to this vector space during a search to locate relevant documents nearby. This often yields search results that are several times better than keyword search.', 'To train multilingual models, you need large quantities (hundreds of millions) of suitable training pairs, like question/answer pairs. So far, such training data has been primarily available in English, and prior work tried to use machine translation to map it to other languages. However, these models donâ€™t capture the nuances behind language usage in different countries.', 'Contrary to this approach, we collected a dataset of nearly 1.4 billion question/answer pairs across tens of thousands of websites in hundreds of languages. These are questions actually asked by speakers of said languages, allowing us to capture language- and country-specific nuances.', 'So, today we are happy to release our first multilingual embeddings model: multilingual-22-12!', 'The multilingual-22-12 model can be used to semantically search within a single language, as well as across languages. Compared to keyword search, where you often need separate tokenizers and indices to handle different languages, the deployment of the multilingual model for search is trivial: no language-specific handling is needed â€” everything can be done by a single model within a single index. Weâ€™re extremely proud of the performance of our multilingual understanding model. It outperformed the industry standard (the next best model) in search tasks by more than 230%.', 'We extensively benchmarked our new model to ensure the best performance across a wide range of applications, domains and languages. Specifically, we used:', 'We compared our results against other state-of-the-art multilingual embedding models, specifically paraphrase-multilingual-mpnet-base-v2 (the best model from Sentence-Transformers), LaBSE (from Google), and Universal Sentence Encoder cMLM (from Google). The following chart shows how they compare:', 'The Cohere multilingual-22-12 model performs much better in all use cases. In particular, we see a robust improvement in multilingual search. The other models we tested against perform rather poorly, in many cases less effectively than keyword search. The main reason is that these models have just been trained at a sentence level, and they are not able to produce meaningful embeddings for longer text, like paragraphs.', 'Traditional keyword search has its limitations in that it often doesnâ€™t find the relevant information that matches the userâ€™s search intent. For instance, the simple search query, â€œWhat is the capital of the United States?â€ produced the following results:', 'To further exacerbate the problem, keyword search with Elasticsearch ranks an article about Capital Punishment at the top position, as it contains many instances of the words capital, united, and states. The second and third-ranked results are also not much better. These are articles about Ohio and Nevada, which are states in the United States and they also have a capital.', 'By contrast, search quality can be greatly improved by using semantic search powered by Cohereâ€™s multilingual model. In this example, the relevant article about Washington, D.C., is ranked at the top position of the search results. And such a gain in search quality is found not only with English queries, but also for a wide range of languages that we have tested (see benchmark results).', 'Semantic search does not restrict itself to queries and documents in the same language, but it also works across languages. For example, if we phrase the search query in Arabic (â€œÙ…Ø§ Ù‡ÙŠ Ø¹Ø§ØµÙ…Ø© Ø§Ù„ÙˆÙ„Ø§ÙŠØ§Øª Ø§Ù„Ù…ØªØ­Ø¯Ø©ØŸâ€), we get the same results, while keyword search can obviously not retrieve any relevant documents.', 'The multilingual flexibility of semantic search enables interesting use cases in industries like finance, where users need to quickly find information that may be published across multiple languages.', 'When successful products like the iPhone launch, tens of thousands of users around the world post their feedback (in their own language) on eCommerce sites, social media, blogs, and elsewhere. Extracting insights from these reviews enables companies to quickly respond to the market, better understand their customer base, and improve their product roadmap. ', 'However, previous methods for content aggregation have only worked well for English, and they didnâ€™t allow users to see patterns across languages or to compare feedback from different markets.', 'Cohereâ€™s multilingual model maps text in different languages to the same vector spaces, allowing users to derive insights across languages and find patterns for specific markets (e.g., which markets care about the picture quality of smartphones).', 'Using thousands of commands directed at a digital assistant, we created a representation demo and video to demonstrate how you can visualize and pull insights from multilingual customer feedback.', 'In todayâ€™s world, content moderation remains a major challenge. Social platforms like online gaming are attracting a wider international audience, which increases the complexity of content moderation efforts. As hateful content makes its way across multiple languages, it has a greater probability of passing through current content moderation tools that only catch English comments.', 'To tackle this challenge, platforms can now use Cohereâ€™s multilingual embeddings model to build a content moderation tool that works across 100+ languages and only requires training data in English.', 'For the content moderation use case, the model just needs a handful of training examples in one language that demonstrate harmful and acceptable content. Developers can then train a classifier (in English or a language of their choice) to find the decision boundary in the vector space that helps determine which type of content â€” in 100+ languages â€” is undesirable on their platform.', 'The following demo showcases Cohereâ€™s multilingual model used to build a recommendation movie engine and obtain relevant results regardless of the language used in the search query or the content source. In addition, it demonstrates multilingual sentiment analysis classification across a wide variety of languages', 'Test out the multilingual search and recommendation demo, multilingual sentiment analysis classification demo, and watch a demonstration:', 'To get started using Cohereâ€™s multilingual model, just create a free account and get your API key. You can then either query our REST API endpoints or install our SDK to use the model within Python. ', 'The following video navigates through the Cohere Platform to select the multilingual model, and shows how the multilingual model can embed text from multiple languages into the embedding space.', 'Additionally, we have added to the Cohere Sandbox, a collection of experimental, open-source GitHub repositories \xa0that make building applications using large language models fast and easy with Cohere. You can find an example of how to use the Cohere API to build a multilingual semantic search engine. The search algorithm used in this project is fairly simple: it finds the paragraph which most closely matches the representation of the question using the co.embed endpoint.', 'Training embedding models require data in a specific format. For example, question/answer pairs or title/document pairs. We can then learn which text pairs should be closer together in the vector space in order to enable applications like semantic search.', 'To train Cohereâ€™s new multilingual model, we processed and carefully cleaned terabytes of data from various sources: Wikipedia, news publications, scientific articles, and online communities across hundreds of languages. This resulted in a large training corpus of more than 900 million training pairs for English and 450 million training pairs for other languages. ', 'Other multilingual embedding models often rely on machine translation for training dataset creation, which creates an awkward bias for these models. A lot of existing English training data has a focus on topics that are primarily interesting for U.S. citizens, for example, how to fill out specific U.S. tax forms. If these question/answer pairs are then translated into another language, e.g., Korean, the model learns in Korean how to file taxes in the U.S., but it doesnâ€™t learn how to file taxes in Korea, a topic that is likely more relevant for Korean citizens. This makes prior models rather suboptimal for multilingual semantic search, as they donâ€™t capture country-specific interests well. ', 'Our training process included actual authentic question/answer pairs from users across hundreds of languages from tens of thousands of websites from hundreds of countries. This is what makes the Cohere multilingual model so powerful: it has seen thousands of topics in each language.', 'At Cohere, we are committed to breaking down barriers and expanding access to cutting-edge NLP technologies that power projects across the globe. By making our innovative multilingual language model available to all developers, we continue to move toward our goal of empowering developers, researchers, and innovators with state-of-the-art NLP technologies that push the boundaries of language AI.', 'Sign up and try our new multilingual model for free. If you would like to discuss your multilingual use case, please donâ€™t hesitate to contact us.', '1. â€œEthnologue: Languages of the World,â€ Ethnologue, 2022 (accessed Nov. 25, 2022).', 'Looking back at the moments that shaped the first six months of C4AI Cohere For AI launched in June of this year as a non-profit research lab and community dedicated to contributing fundamental research in machine learning. The vision for the lab was simple but ambitious: change how, where, and', ""Senior Google/YouTube Exec to join Cohere, focusing on the enormous commercial opportunity of NLP.Since Cohereâ€™s beginning, we've been focused on unlocking the vast potential of language for every developer and business. To do that, weâ€™re making natural language processing more accessible to developers, including those without"", 'In this multi-part guide, we will go through everything that you need to know about generative AI with Cohereâ€™s large language models (LLMs). In Part 1, we talk about model prompting.']",https://txt.cohere.ai/multilingual/,Cohere's Multilingual Text Understanding Model is Now Available,Product Launch,Blog
"['In this multi-part guide, we will go through everything that you need to know about generative AI with Cohereâ€™s large language models (LLMs). In Part 1, we talk about model prompting.', 'Generative AI is a type of artificial intelligence that focuses on creating or generating new content or data. This can be in the form of language, images, videos, and more. ', 'Its market potential is significant as it has the potential to revolutionize many industries and drive innovation in a wide range of fields. For example, in the creative arts, generative AI can be used to generate unique and engaging content, such as music or visual art, with minimal need for human input. In the business world, generative AI can be used to generate reports, presentations, and other business documents, reducing the need for manual data analysis and enhancing productivity.', 'At Cohere, our focus is on language. We want to enable developers to add language AI to their technology stack and build impactful applications with it.', 'In this multi-part guide, we will go through everything that you need to know about generative AI with Cohereâ€™s large language models (LLMs).', 'Here is what weâ€™ll cover throughout this series:', 'In this Part 1 article, we will cover the following topics:', 'Throughout the series, we will cover the full spectrum of working with generative AI to enable you to build applications with it. But to start with, letâ€™s take the no-code route: weâ€™ll show you how AI text generation works, and how you can experiment with it in the Cohere Playground.', 'First, sign up for a Cohere account and then visit the Playground.', 'The Playground UI consists of a few sections. The main window is where you enter your prompt and where the output, or response, is generated. A menu of saved prompts, or presets, is shown in the left-hand pane, and model parameter controls are located in the right-hand pane.', 'Weâ€™ll cover presets and parameters later in this article, but now, letâ€™s start with the fun part: prompt design.', 'Prompting is at the heart of working with LLMs. The prompt provides a context for the text that we want the model to generate. The prompts we create can be anything from simple instructions to more complex pieces of text, and they are used to encourage the model to produce a specific type of output. ', 'Coming up with a good prompt is a bit of both science and art. On the one hand, we know the broad patterns that enable us to construct a prompt that will generate the output that we want. But on the other hand, there is so much room for creativity and imagination in coming up with prompts that can get the best out of a model.', 'To understand how model prompting works, letâ€™s start by entering the following prompt into the playground.', 'Once upon a time in a magical land called', 'Clicking Generate gives us a continuation of the text (model-generated text is in bold).', 'This is the most basic form of prompting, which is simply asking the model to complete the text that we have entered. But this type of prompt is rather open-ended, and in more practical applications, you will need to make the prompt tighter, so that the output generated will be more predictable.', 'With that, letâ€™s now dive into how you can design more effective prompts.', 'How a prompt is designed is dependent on the type of model you are using. There are two types of generative models available on the Cohere Platform: one where you prompt by instruction and another where you prompt by example.', 'In summary, this is how the two types of models differ:', 'Prompting by Instruction', 'Prompting by Example', 'Now letâ€™s learn more about designing these two types of prompts.', 'The Command-Xlarge model works best when we provide an instruction-based prompt. One way to do this is by using imperative verbs to tell the model what to do, for example: generate, write, list, provide, and other variations.', 'Letâ€™s say that we are creating social media ad copy for a wireless earbuds product. We can write the prompt as follows.\nGenerate a social ad copy for the product: Wireless Earbuds.', 'At this point, ensure that you select command-xlarge in the MODEL dropdown in the right pane. Then, click on Generate.', 'This generates the following output.', 'Thatâ€™s not bad. With a simple, one-line prompt, we already have a piece of ad copy that will make a digital marketer proud!', 'But perhaps we want to be more specific in terms of what we want the output to look like. For this, we can layer additional instructions onto the model in the prompt.', 'Letâ€™s say that we want the model to provide the ad copy in the form of a wellâ€“known copywriting technique, called the AIDA Framework (which stands for Attention, Interest, Desire, and Action). In this case, we can append this specific instruction in the prompt as follows.', 'Generate an ad copy for the product: Wireless Earbuds. The copy consists of four parts (Attention, Interest, Desire, Action), following the AIDA Framework.', 'The model picks up what the AIDA Framework is, and duly returns an output following the format that we wanted. Wonderful!', 'The prompt can be constructed as a combination of an instruction and some context. Letâ€™s see this in action with another example: emails. We can create a simple instruction to write an email as follows.', 'Or we can create an instruction to summarize an email, and that email now becomes part of the prompt, acting as the context.', 'This is just a taste of what kinds of prompts you can design. You can keep layering your instructions to be as specific as you want, and see the output generated by the model. And there is really no right or wrong way to design a prompt. Itâ€™s really about applying an idea and continuing to iterate the prompt until you get the outcome you are looking for.', 'Sometimes you want the model output to be more attuned to a specific pattern or nuance that you have in mind. For this, a better option might be to use the XLarge or Medium model and prompt it by example instead of by instruction.', 'For example, say you want to generate product descriptions for a long list of products. You want each of the descriptions to be of similar length. And for each product description, you want to be able to input a few keywords to guide the content of the descriptions. ', 'A basic prompt format that generally works well is as follows.', 'With our product description case, hereâ€™s what the prompt looks like:', 'At this point, ensure that you select xlarge or medium in the MODEL dropdown in the right pane.', 'And this is what the output looks like:', 'Notice that since the examples we provided were concise, the model generated one with a style for this new product. If you want the output to be more elaborate, or as a list, or in any format, what you need to do is to alter your examples, and the model will duly return similar outputs.', 'Letâ€™s take another example. This one is for generating haikus, a type of short-form poetry originally from Japan. Say we want the haiku to be precisely three lines, each with a similar length. The Command-XLarge model might still work for this, but over many generations, the output format could vary. This is where we can use the XLarge model to provide examples of the type of output we want.', 'Hereâ€™s what the prompt looks like, where we give a few haiku examples:', 'And this is what the output looks like:', 'Perfect, just as we want it!', 'Other than the prompt design, there is another way to control the kind of output we want, that is, by adjusting the model parameters. These parameters are available on the right pane of the Playground. They are applicable to both types of prompting we discussed earlier.', 'Letâ€™s now see what we can do with these parameters.', 'There are a couple of parameters that let you decide when the model should stop.', 'Probably the most useful set of parameters are the ones that we can tune to control the randomness of the output. The beauty of working with LLMs is, for the same prompt, the next generated token will not be the same every time. Rather, it is sampled from a long list of possible tokens. This is where the creative aspect of LLM comes from, allowing us to generate a variety of outputs, given the exact same prompt.', 'But depending on your application, you may want to reduce, or increase, this level of randomness. You can do this by adjusting a number of parameters.', 'But before looking at the parameters, itâ€™s worth taking the time to understand how the model selects the next token to generate. It does this by assigning a likelihood number to each of all possible next tokens. The model would see that the token cookies has a much higher likelihood than chair for appearing after the phrase I like to bake.', 'During text generation, thereâ€™s still a probability that chair would appear, but the probability is much lower than cookies. The parameters we are going to see now can change this behavior.', 'There are three parameters we can adjust for this.', 'Two parameters allow you to control the amount of repetition in the generated text.', 'You can save the prompts that you have created by clicking on the Save button on the bottom right of the Playground. Once you have saved a prompt, it will appear as a preset on the Playgroundâ€™s left pane.', 'You can also share these prompts with others. To do this, click on the Share button on the top right of the Playground. You will get a link which you can share with anyone!', 'In this article, we covered how to prompt a model â€” probably the most important, and definitely the most fun part of working with large language models. If youâ€™d like to dive deeper into it, here are some resources you can go to for further reading:', 'In the coming Part 2, we will explore the range of use cases and areas where generative AI in language can be applied. And along the way, weâ€™ll see the different ways a prompt can be designed.', 'Ready to get started with Generative AI? Sign up for a free Cohere account to start building.', 'Looking back at the moments that shaped the first six months of C4AI Cohere For AI launched in June of this year as a non-profit research lab and community dedicated to contributing fundamental research in machine learning. The vision for the lab was simple but ambitious: change how, where, and', ""Senior Google/YouTube Exec to join Cohere, focusing on the enormous commercial opportunity of NLP.Since Cohereâ€™s beginning, we've been focused on unlocking the vast potential of language for every developer and business. To do that, weâ€™re making natural language processing more accessible to developers, including those without"", 'Develop, test, and experiment with the industryâ€™s first multilingual text understanding model that supports 100+ languages Humans speak over 71001 languages, yet the majority of language models only support the English language. This makes it incredibly challenging to build products and projects using multilingual language understanding. Cohereâ€™s mission']",https://txt.cohere.ai/generative-ai-part-1/,Generative AI with Cohere: Part 1,Guide,Blog
"['- This roundup highlights some interesting NLP papers from November 2022 around language model capabilities. ', 'This articleâ€™s title and TL;DR have been generated with Cohere.Get started with text generation', 'Language models are evolving at a rapid pace, and every month we discover new capabilities. Large language models, like those built by Cohere, are being used for use cases that we couldnâ€™t have imagined even just a few months ago.', 'In this roundup, we highlight some exciting papers on natural language processing, our work from Cohere For AI and Cohereâ€™s technical staff, along with our involvement at NeurIPS 2022. Topics for this month include different prompting methods for understanding dialogue and humor, use cases like summarization and essay scoring, and what language models learn beyond language. \xa0', 'Have fun reading these! For feedback, please let us know on our Discord communityâ€”weâ€™d love to hear from you.', 'Authors: Nikhil Kandpal, Haikang Deng, Adam Roberts, Eric Wallace, Colin Raffel', 'There is a wealth of information on the internet, including birthdays of historical figures and tutorials on how to code, that can be learned by language models. On the other hand, there is a lot of variability in the number of times a piece of information appears online. In this paper, the authors examine the relationship between their pre-training datasets and their knowledge memorized.', 'Relevant documents are identified by entity linking pre-training datasets and counting documents containing the same entities as a given question-answer pair. In the study, they found strong correlations between accuracy and document count for numerous question-answering datasets.', 'Authors: Leshem Choshen, Elad Venezian, Shachar Don-Yehia, Noam Slonim, Yoav Katz', 'In previous studies, finetuned models were found to be better base models than vanilla pretrained ones. By finetuning a model on a source dataset, one may have a better starting point when finetuning a target dataset. The authors analyze this intertraining scheme over a wide range of English classification tasks in this paper.', 'It turns out that the potential intertraining gain can be analyzed independently for each target dataset under consideration, and for each base model used as a starting point. In contrast to popular perception, alignment between the target dataset and the source dataset that generated the base model is a major determinant of intertraining success.', 'Authors: Haihao Shen, Ofir Zafrir, Bo Dong, Hengyu Meng, Xinyu Ye, Zhe Wang, Yi Ding, Hanwen Chang, Guy Boudoukh, Moshe Wasserblat', 'The standard approach to solving natural language processing tasks is transform-based language models. Transformer models cannot be used in production because industry adoption usually requires the maximum throughput to meet certain latency constraints. Model compression techniques such as quantization and pruning may be used to fill this gap.', 'Despite this, deploying and applying these compression techniques at scale requires specialized software.', 'The authors propose a new pipeline for creating and running Fast Transformer models on CPUs, using hardware-aware pruning, knowledge distillation, quantization, and a Transformer runtime engine.', 'Authors: Hattie Zhou, Azade Nova, Hugo Larochelle, Aaron Courville, Behnam Neyshabur, Hanie Sedghi', 'Through scaling up model and data size, large language models have demonstrated increasing in-context learning capabilities. However, algorithmic reasoning problems are still difficult for LLMs to solve. Even simple algorithmic reasoning tasks such as parity are far from being solved, although providing a rationale with the final answer has improved the performance of multi-step reasoning problems.', 'A four-stage approach to teaching algorithmic reasoning to LLMs is identified and studied in this work: (1) formulating algorithms as skills, (2) teaching multiple skills simultaneously, (3) teaching skill composition, and (4) teaching skill utilization. The use of algorithmic prompting, which we call in-context learning, is shown to be an effective method of teaching algorithmic reasoning to LLMs.', 'Authors: Rishi Bommasani, Percy Liang, Tony Lee', ""We must be measured as language models generate excitement and fear. In order to be able to gain a better understanding of the technology and its societal impact, we need to know what it can and can't do, as well as what risks it poses. A vital first step towards these two goals is transparency."", 'A new benchmarking method, Holistic Evaluation of Language Models (HELM), has been developed at the Center for Research on Foundation Models to help provide transparency in language modeling. Through collaboration with the broader community, HELM intends to serve as a map of the world of language models that is continuously updated over time.', 'Authors: Minqi Jiang, Tim RocktÃ¤schel, Edward Grefenstette', 'The field of artificial intelligence (AI) is poised to shift from learning from data to learning what data to use. Despite not being completely resolved, large models under unified architectures, such as transformers, have moved the learning bottleneck from training our models to acquiring and using relevant data.', 'In open-ended domains, such as the real world, exploration is a universal problem in learning. The authors argue that exploration is integral to all learning systems, including supervised learning, despite the fact that the study of exploration in AI has mostly focused on reinforcement learning.', 'By presenting the generalized exploration problem, which highlights key similarities across learning settings and research challenges, the authors conceptually link exploration-driven learning to reinforcement learning and supervised learning. The process of generalized exploration also provides a promising path to general intelligence by maintaining open-ended learning processes that constantly learn to solve new problems and discover new things.', 'Authors: Kelechi Ogueji, Orevaoghene Ahia, Gbemileke Onilude, Sebastian Gehrmann, Sara Hooker, Julia Kreutzer', 'In order to generalize to an increasing number of languages, multilingual models often rely heavily on scaling. Compression techniques are used to reconcile model size growth with real world resource constraints, but compression can adversely affect the performance of low-resource languages. Therefore, understanding the tradeoffs between multilingualism, scale, and compression is crucial.', 'This study finds that compression confers several interesting and previously unknown generalization properties on mBERT named entity recognition models across 40 languages.', 'Contrary to prior findings, the authors found that compression can improve model robustness, as well as enhancing low-resource language performance under certain sparsification regimes rather than adversely impacting it.', 'We are thrilled to be part of NeurIPS this year! Make sure to visit us at booth #615. Weâ€™d love to meet you.', 'Authors: Jesse Mu, Victor Zhong, Roberta Raileanu, Minqi Jiang, Noah Goodman, Tim RocktÃ¤schel, Edward Grefenstette', 'Reinforcement learning (RL) agents are particularly hard to train when rewards are sparse. One common solution is to use intrinsic rewards to encourage agents to explore their environment. However, recent intrinsic exploration methods often use state-based novelty measures which reward low-level exploration and may not scale to domains requiring more abstract skills. Instead, we explore natural language as a general medium for highlighting relevant abstractions in an environment. Unlike previous work, we evaluate whether language can improve over existing exploration methods by directly extending (and comparing to) competitive intrinsic exploration baselines: AMIGo (Campero et al., 2021) and NovelD (Zhang et al., 2021). These language-based variants outperform their non-linguistic forms by 47-85% across 13 challenging tasks from the MiniGrid and MiniHack environment suites.', 'Authors: Victor Zhong, Jesse Mu, Luke Zettlemoyer, Edward Grefenstette, Tim RocktÃ¤schel', 'Recent work has shown that augmenting environments with language descriptions improves policy learning. However, for environments with complex language abstractions, learning how to ground language to observations is difficult due to sparse, delayed rewards. We propose Language Dynamics Distillation (LDD), which pretrains a model to predict environment dynamics given demonstrations with language descriptions, and then fine-tunes these language-aware pretrained representations via reinforcement learning (RL). ', 'In this way, the model is trained to both maximize expected reward and retain knowledge about how language relates to environment dynamics. On SILG, a benchmark of five tasks with language descriptions that evaluate distinct generalization challenges on unseen environments (NetHack, ALFWorld, RTFM, Messenger, and Touchdown), LDD outperforms tabula-rasa RL, VAE pretraining, and methods that learn from unlabeled demonstrations in inverse RL and reward shaping with pretrained experts. In our analyses, we show that language descriptions in demonstrations improve sample-efficiency and generalization across environments, and that dynamics modeling with expert demonstrations is more effective than with non-experts.', 'Authors: Minqi Jiang, Michael Dennis, Jack Parker-Holder, Andrei Lupu, Heinrich KÃ¼ttler, Edward Grefenstette, Tim RocktÃ¤schel, Jakob Foerster', 'Adaptive curricula in reinforcement learning (RL) have proven effective for producing policies robust to discrepancies between the train and test environment. Recently, the Unsupervised Environment Design (UED) framework generalized RL curricula to generating sequences of entire environments, leading to new methods with robust minimax regret properties. Problematically, in partially-observable or stochastic settings, optimal policies may depend on the ground-truth distribution over aleatoric parameters of the environment in the intended deployment setting, while curriculum learning necessarily shifts the training distribution. We formalize this phenomenon as curriculum-induced covariate shift (CICS), and describe how its occurrence in aleatoric parameters can lead to suboptimal policies. Directly sampling these parameters from the ground-truth distribution avoids the issue, but thwarts curriculum learning. We propose SAMPLR, a minimax regret UED method that optimizes the ground-truth utility function, even when the underlying training data is biased due to CICS. We prove, and validate on challenging domains, that our approach preserves optimality under the ground-truth distribution, while promoting robustness across the full range of environment settings.', 'Authors: Yingchen Xu, Jack Parker-Holder, Aldo Pacchiano, Philip J. Ball, Oleh Rybkin, Stephen J. Roberts, Tim RocktÃ¤schel, Edward Grefenstette', 'Building generally capable agents is a grand challenge for deep reinforcement learning (RL). To approach this challenge practically, we outline two key desiderata: 1) to facilitate generalization, exploration should be task agnostic; 2) to facilitate scalability, exploration policies should collect large quantities of data without costly centralized retraining. Combining these two properties, we introduce the reward-free deployment efficiency setting, a new paradigm for RL research. We then present CASCADE, a novel approach for self-supervised exploration in this new setting. CASCADE seeks to learn a world model by collecting data with a population of agents, using an information theoretic objective inspired by Bayesian Active Learning. CASCADE achieves this by specifically maximizing the diversity of trajectories sampled by the population through a novel cascading objective. We provide theoretical intuition for CASCADE which we show in a tabular setting improves upon naÃ¯ve approaches that do not account for population diversity. We then demonstrate that CASCADE collects diverse task-agnostic datasets and learns agents that generalize zero-shot to novel, unseen downstream tasks on Atari, MiniGrid, Crafter and the DM Control Suite. Code and videos are available in this website.', 'If youâ€™re working with large volumes of text, you can possibly benefit greatly by incorporating large language models into your workflow. It may take some experimentation and tweaking to get the model to do exactly what you want, but these papers should give you an idea of how others go about it.', 'Is there a paper we should include in our next issue? Let us know on our Discord community. To get started with Cohere, try out our NLP API on our playground and start building.', 'Looking back at the moments that shaped the first six months of C4AI Cohere For AI launched in June of this year as a non-profit research lab and community dedicated to contributing fundamental research in machine learning. The vision for the lab was simple but ambitious: change how, where, and', ""Senior Google/YouTube Exec to join Cohere, focusing on the enormous commercial opportunity of NLP.Since Cohereâ€™s beginning, we've been focused on unlocking the vast potential of language for every developer and business. To do that, weâ€™re making natural language processing more accessible to developers, including those without"", 'Develop, test, and experiment with the industryâ€™s first multilingual text understanding model that supports 100+ languages Humans speak over 71001 languages, yet the majority of language models only support the English language. This makes it incredibly challenging to build products and projects using multilingual language understanding. Cohereâ€™s mission']",https://txt.cohere.ai/top-nlp-papers-november-2022/,Top NLP Papers—November 2022,Research,Blog
"['In this talk, Dr. Rachael Tatman introduced us to Cohere LLMs and walked us through the reasons behind using them for data augmentation. She explained several strategies and the problems that we may face while augmenting our models. She also offered advice and recommendations for performing data augmentation with a focus on data diversity while also demonstrating a few examples using the Cohere LLM and how it gives us a warm start for our models. ', 'This articleâ€™s title and TL;DR have been generated with Cohere.Get started with text generation', 'Discover some tips and techniques for creating chatbots with LLMs. In this video, Rachael Tatman, a language technology educator, offers some advice and ideas for developing chatbots with LLMs. She details the what, why, and how of data augmentation while illustrating how we may validate the created data and add diversity to our data. One of her goals is for everyone interested in NLP to be able to build reliable, useful language technology tools that genuinely improve peopleâ€™s lives.', 'Dr. Rachael Tatman started her talk by strongly advising against serving raw-generated text to users for both UX and security reasons because of its unpredictability. She also mentions that most of the adversarial attacks on the LLMs require access to raw text output. So, if we donâ€™t release the raw data, we wonâ€™t have to deal with adversarial attacks. She recommends human-in-the-loop data augmentation for a warmer start when training or fine-tuning a chatbot.', 'Data augmentation is beneficial when we donâ€™t have representative data for all our targeted user personas. She also states that data augmentation is fruitful when we have representative data, but there are missing examples for specific intents. For instance, it happens when a new topic suddenly becomes relevant. In addition, data augmentation is crucial when working with some research data that is typically very clean and does not represent user-generated text.', 'We can avoid repetition and unintended errors by using LLMs over other techniques like templatic-rule-based data augmentation. Besides, the templatic-rule-based approach lags in generating data with different syntax. She also says that LLMs are more efficient than other translation-based approaches that are usually full of errors. In addition to that, using LLMs is a faster, cheaper, and more reliable approach than generating all new data. ', 'While LLMs also represent noisy user-generated textâ€“so, while training our model, it will undoubtedly benefit from such a diverse range of data.', 'Cohereâ€™s Generation Large Language Model is trained on the Google Books dataset, CommonCrawl, and other text from the internet scraped by the Cohere infrastructure team [see: Generation Model Card]. The top ten domains scraped by the infrastructure team at Cohere include: wordpress.com, medium.com, stackexchange.com, tumblr.com, elsevier.com, genius.com, bbc.co.uk, libsyn.com, yahoo.com, nytimes.com. Based on this, Cohere LLMs have used various data to train the model, including noisy data. ', 'Now, depending on your specific case, you may have variations in what you actually choose to do, but here are some recommendations.', 'Itâ€™s recommended to work with the data you have and use that to train the model using prompt engineering to generate new data. In this example, Dr. Tatman walks us through an example she created by using the SLURP dataset (Bastianelli et al. 2020). She takes this data because it is very clean and fairly formal. ', ""Example: We have some training data. Now, how we can use this training data to generate more data based on it. The following image is a screenshot of Cohere's playground. In the following example, we are giving it the intent: Play Music. With that, we are supplying it with a bunch of examples. When we click the generate button, it will generate relevant text."", 'The following image demonstrates another example of using the Cohere playground to generate text. Here, we are feeding it with an intent, for instance, setting an alarm or a reminder.', 'So far, we have seen the ways of increasing the data we have using data augmentation techniques. But, the generated data was similar to the existing data. What if we want to add data diversity? Dr. Tatman divides the approaches to adding diversity into two parts.', 'Prompts Based on Emotions:', 'Prompt Based on Specific User Persona', 'Prompt by Referencing Specific Websites', 'For instance, the above approaches wonâ€™t work very well if our intents are too specific or unique. The provided approaches will work best if your target users are a large chunk of existing social media users. Also, adding that data diversity in the given way does not represent your actual users. It is basically a stopgap that gives us a warmer start.', 'Itâ€™s recommended to do hand validations in the first pass. She asks to add a human-in-the-loop for better performance. Other than that, she recommends using embedding visualizations to ensure a mix of real and generated data across the distribution. You can also figure out whether youâ€™re happy with your new clusters using embedding visualizations.', 'To summarize this talk, LLMs can help us with data augmentation by volume and diversity until we get some actual data. It will give us a warm start to make our system more usable. She adds that we can prompt with our existing and newly generated data. Finally, she recommends hand-verifying the generated data in the first pass to ensure it is up to the standards and quality we are looking for.', 'Get started building with large language models. Follow us on Twitter, Linkedin, and Youtube to stay tuned!', 'Looking back at the moments that shaped the first six months of C4AI Cohere For AI launched in June of this year as a non-profit research lab and community dedicated to contributing fundamental research in machine learning. The vision for the lab was simple but ambitious: change how, where, and', ""Senior Google/YouTube Exec to join Cohere, focusing on the enormous commercial opportunity of NLP.Since Cohereâ€™s beginning, we've been focused on unlocking the vast potential of language for every developer and business. To do that, weâ€™re making natural language processing more accessible to developers, including those without"", 'Develop, test, and experiment with the industryâ€™s first multilingual text understanding model that supports 100+ languages Humans speak over 71001 languages, yet the majority of language models only support the English language. This makes it incredibly challenging to build products and projects using multilingual language understanding. Cohereâ€™s mission']",https://txt.cohere.ai/tips-and-tricks-to-build-chatbots-with-large-language-models-llms/,Tips and Tricks to Build Chatbots With Large Language Models (LLMs),Guide,Blog
"['This NLP Jumpstart Series outlines how startups can use natural language processing (NLP) to build a competitive moat.', 'This articleâ€™s title and TL;DR have been generated with Cohere.Get started with text generation', 'Startups need all the advantages they can get as they strive to get a foothold in the marketplace. One such advantage they can use is unstructured language data. In all the content that people create on a daily basisâ€“chats, email, social media, reviews, even customer service logs and contractsâ€“there are insights to be mined and efficiencies to be found, if only companies have the right tools to unlock language data.', 'Natural language processing (NLP) is the key, but up until now, this key has been held by only the largest companies that could afford the compute power and AI/ML engineers with the skills to train the large language models (LLMs) that NLP relies upon to understand language. Today, all that is changing, with more accessible and powerful NLP that can be used by businesses of any size. ', 'In our recent NLP Jumpstart Series, â€œHow Startups Can Use NLP to Build a Competitive Moat,â€ we explore how language AI can fundamentally transform how startups can leverage LLMs to build products and experiences. ', 'Watch the full video replay below, or continue reading for some key takeaways from this NLP Jumpstart session.', 'Learn what NLP is and where it sits within the broader category of artificial intelligence. ', 'Building large language models that can understand language at a human level is extremely difficult. It requires a particular set of ML engineering and modeling skills, a ton of computing power, and access to large volumes of data.', 'Google Cloud and Cohere are working together to bring powerful NLP to all companies and developers. Our mission is to make it accessible, easy, affordable, and safe for any company looking to build an NLP solution. Google Cloud brings the technology and Cohere brings the machine learning expertise to your company.', 'Cohereâ€™s endpoints are specific operations that your developers can use to classify, search, summarize, generate, extract, and cluster text. They power a range of business processes, such as content moderation, customer support, and generating marketing copy, allowing your startup to build with NLP much more quickly and economically. ', 'In this demonstration, learn how Cohereâ€™s co-founder Nic Frosst used Cohere and a third-party text-to-image API to create a generator for the card game, Magic the Gathering. Learn more about Urzaâ€™s AI in our blog.', 'Watch this demonstration to learn how simple it is to work with and fine-tune Cohere models and endpoints for your startupâ€™s needs.', 'NLP offers a wealth of opportunities for startups building with language AI to create efficiencies, develop differentiated products, and get to market faster. With Cohere, you can achieve all of that and integrate NLP quickly with no model training required. ', 'Ready to get started building with LLMs? Learn more about developing content with Cohere and sign up for a free Cohere account to start building.', 'Looking back at the moments that shaped the first six months of C4AI Cohere For AI launched in June of this year as a non-profit research lab and community dedicated to contributing fundamental research in machine learning. The vision for the lab was simple but ambitious: change how, where, and', ""Senior Google/YouTube Exec to join Cohere, focusing on the enormous commercial opportunity of NLP.Since Cohereâ€™s beginning, we've been focused on unlocking the vast potential of language for every developer and business. To do that, weâ€™re making natural language processing more accessible to developers, including those without"", 'Develop, test, and experiment with the industryâ€™s first multilingual text understanding model that supports 100+ languages Humans speak over 71001 languages, yet the majority of language models only support the English language. This makes it incredibly challenging to build products and projects using multilingual language understanding. Cohereâ€™s mission']",https://txt.cohere.ai/how-startups-can-use-nlp-to-build-a-competitive-moat/,How Startups Can Use NLP to Build a Competitive Moat,Guide,Blog
"['Last month, co:lab fridays made one heck of a comeback! Not only did we restart our community meetup after a short break, but we added a few brand-new segments to the agenda. Now happening on the last Friday of every month, co:lab fridays is featuring a lineup of demos from our amazing makers around the world. Hereâ€™s a recap of what went down at the first demo event. Watch the full session for all the details.', 'First and foremost, we kicked off the event with an exciting announcement: our Discord community has surpassed 2000 members! Woohoo!! Weâ€™re super grateful to all our members, and to mark the occasion, weâ€™ll send an extra â€œthank youâ€ gift to our most active members. ', 'Next, our experiment-obsessed co-founder Nick Frosst spoke about his hot topic of the month: Discord bots. Not only is building Discord bots just plain fun, but the Discord platform makes it increasingly easier to trigger and share them. Nick introduced us to two projects that heâ€™s been involved with: the Grounded QA bot for contextualized search (now open source, see GitHub repo) and the Web LM bot for automating a browser through language. Feel free to contribute to either, and if youâ€™re making your own Discord bot, apply to speak at co:lab or simply approach Sandra Kublik or Nick Frosst on Discord! ', 'Then, we proceeded to the heart of our event: community demos. It was super exciting to see makers from around the world showcase four very different demos:', 'Perfect Prompt by Arjun Patelâ€“Arjun wanted to solve the problem of slow image generation when trying different prompts using Stable Diffusion and some of the open-sourced models out there today. He used Cohereâ€™s Generate and Classify endpoints to create a one-stop shop for prompt engineering and image generation. Arjun created the app as part of a hackathon hosted by lablab.ai. See his GitHub repo.', 'Project Idea Generator by Tobechukwu Okamkpaâ€“Tobechukwuâ€™s app helps students generate creative project topics based on their discipline. The app allows users to enter their favorite courses in order to generate topics better suited to their interests. He built the app on Streamlit and used the Cohere Generate endpoint and X-Large language model. See his GitHub repo.', 'SuperTransformer by Amir Nagri and Team Megatronâ€“Amir and team built an AI-assisted email inbox manager that helps busy people organize incoming emails based on urgency and importance. Using Cohere Classify, the app categorizes emails and adds an appropriate action label. The team also built their app during a lablab hackathon. See their GitHub repo.', 'SCRIPTure by Arnav Kartikeya and Satyajith Bavisetty, Atharva Guptaâ€“Inspired by Dungeons & Dragons, this app is a fantasy creature generator that helps creative writers develop new characters that fit their storylines. Given a simple prompt, such as â€œcave monster,â€ the app uses Cohere Generate to create an image, description, and even a backstory for a new creature. The team built their app during a Cal Hacks 9.0 hackathon. See their GitHub repo.', 'Our demo session ended with our co-founder Aidan Gomez picking his favorite out of the four. It was a tough decision, but Aidan picked the one he could use most right now: SuperTransformer. That means that Amir and team will get a one-on-one mentoring session with Aidan, a special Discord badge, a little promotional love on our social channels, and visibility in our booth at one of our upcoming conferences. ', 'So, Octoberâ€™s a wrap, but November is coming up fast. Co:lab friday community demos happen on the last Friday of every month. Register for our next event on November 25, 12 pm ET!', 'If you have a Cohere-powered demo youâ€™d like to share at co:lab fridays, please fill out our application form. ', 'P.S. Be sure to join the co:mmunity conversation on Discord, if you havenâ€™t yet!', 'Looking back at the moments that shaped the first six months of C4AI Cohere For AI launched in June of this year as a non-profit research lab and community dedicated to contributing fundamental research in machine learning. The vision for the lab was simple but ambitious: change how, where, and', ""Senior Google/YouTube Exec to join Cohere, focusing on the enormous commercial opportunity of NLP.Since Cohereâ€™s beginning, we've been focused on unlocking the vast potential of language for every developer and business. To do that, weâ€™re making natural language processing more accessible to developers, including those without"", 'Develop, test, and experiment with the industryâ€™s first multilingual text understanding model that supports 100+ languages Humans speak over 71001 languages, yet the majority of language models only support the English language. This makes it incredibly challenging to build products and projects using multilingual language understanding. Cohereâ€™s mission']",https://txt.cohere.ai/co-lab-fridays-community-demos-october-recap/,Co:lab Fridays Community Demos—October Recap,Co:lab,Blog
"['In this article, we go over how the Turing team used text generation with embedding endpoints to build a chatbot for customer support.', 'This articleâ€™s title and TL;DR have been generated with Cohere.Get started with text generation', 'Team Turing, consisting of Bence Gadanyi, Edwin Holst, Jonathan Fernandes, and Artur Gasparyan, presented their project as an NLP tool for customer chat support agents. The program uses a companyâ€™s knowledge base to generate automated responses to customer queries. When implemented successfully, this type of app could substantially reduce the costs and time associated with customer support training and increase overall staff efficiency. ', 'In this article, weâ€™ll go over the details of this application from frontend to backend, including how this creative team used the Cohere Generate and Cohere Embed endpoints to develop a practical business solution for customer support chatbots.', 'One of the main reasons it takes so long to contact customer support is the extended wait time due to high request volumes from both customers and internal staff. Additionally, because many of these queries relate to specific product information, support agents either need to research the queries manually, undergo continual training to familiarize themselves with inventory products and specifications, orâ€”in many casesâ€”both.', 'The Turing teamâ€™s app aims to solve this issue by providing agents with automated responses to these product-specific questions. This allows agents to reply to customers more rapidly, enabling them to resolve more requests in the same amount of time.', 'The step-by-step process behind this NLP-powered app is relatively simple. First, the app extracts product information from the company website and stores it in a knowledge base as text. It then uses the Cohere Embed and Cohere Generate endpoints to generate questions and answers (Q&As) from that text.', 'Based on input from the customer support chatbot, the tool creates three appropriate responses to the customerâ€™s message. The support agent can either reply using one of the responses as-is, edit one before sending it as a response, or answer the query manually.', 'That is the appâ€™s process in a nutshell. Next, letâ€™s explore each step in more detail, starting with the knowledge base.', 'The app generates a knowledge base by extracting the product description from the companyâ€™s website and creating a vector embedding. It will use this embedding later for comparing the semantic similarity between the knowledge base and the customerâ€™s message.', 'For this project, the developers used information from Two Wests & Elliott, an eCommerce store selling equipment for greenhouses and gardens, to generate the knowledge base. Below is the webpage for the â€œHalls Standard Cold Frameâ€ item, which lists product information, including the price, dimensions, materials, and delivery options.', 'The app includes a prompt instructing the Generate endpoint to create Q&As using the productâ€™s description. It also provides sample Q&As that better enable the model to understand the downstream task.', 'In this example, the app uses the pictured product description to create a prompt with the instruction: â€œGenerate questions from this text.â€ This prompt contains product information and a sampling of Q&As that need to be generated. ', 'From this example, you can see that the app has collected everything it needs to generate responses for the most common types of customer support questions. But how exactly does it do that?', 'The backend of the app consists of two parts. The first uses semantic search to compare the prompt that the customer enters and the existing information in the knowledge base. To do so, it uses Cohere Embed endpoint to capture semantic information about the customerâ€™s query. Cohere returns a list of floating point numbersâ€”called embeddingsâ€”that capture the semantic information about the text. Embeddings are a way to represent the meaning of the text as a list of numbers. ', 'The app also uses Annoyâ€”a Python library used to perform a nearest neighbor search for points in spaceâ€”to build an index that stores the embeddings and searches these using nearest neighbor search.', 'The second part of the tool handles cases where the answer to the customerâ€™s question is not in the knowledge base or when the question is not relevant to the product. To do this, the tool uses the Generate endpoint to provide a reasonable response to the customerâ€™s query.', 'In this example, the customerâ€™s statement has not specified the product for which they need information.', 'In this instance, Cohere Generate returns the following response:', 'While the backend operates in Python, the front-end interfacesâ€”one for the customer and one for the support agentâ€”run using JavaScript.', 'This support agent can access the interface by navigating to {url}/customer-support. Then, they can connect with a customer in the chatbot window to send and receive messages.', 'The code for this connection looks as follows:', 'The customer interface is accessible at the path {url}/customer-chat. The customer initiates a chat with an agent and can send and receive messages when the agent connects.', 'Hereâ€™s the code for connecting at a customerâ€™s address:', 'Now that youâ€™ve thoroughly explored the application, letâ€™s see how all the pieces come together.', 'First, the customer initiates a chat by entering a message into the window prompt. Then, the customer chatbot support agent joins. The customer can then ask for product-specific information by entering their query. The app converts this query into a vector embedding and measures the semantic similarity between the query and the information from the knowledge base.', 'Cohere Embed then returns two potential responses to the query. Cohere Generate also returns a product-nonspecific response as the third automated response.', 'From there, the agent can answer the query using any of these responses. The agent can also choose to edit the automated response before sending it.', 'While NLP is relatively new as a widely available tool, it is already changing how technology and businesses operate. Chat-based customer support systems can benefit substantially from implementing NLP-based functionality. They represent just one of an abundance of NLP applications, and the potential of NLP extends as far as its usersâ€™ aspirations. The developers of the customer support app had just three days to create it, so imagine what you can create with just a little more time. ', 'Moreover, these tools are well within your reach. Cohere brings this technology right to your fingertips, providing access to advanced NLP functionality via an innovative and intuitive platform.Check out Team Turingâ€™s project code or watch their hackathon presentation to learn more about their customer support app powered by Cohere. Maybe youâ€™ll even feel inspired to try out your own programming prompts in the Cohere Playground. Or better yet, join the next Cohere/lablab.ai hackathon starting on December 2, 2022!', 'Looking back at the moments that shaped the first six months of C4AI Cohere For AI launched in June of this year as a non-profit research lab and community dedicated to contributing fundamental research in machine learning. The vision for the lab was simple but ambitious: change how, where, and', ""Senior Google/YouTube Exec to join Cohere, focusing on the enormous commercial opportunity of NLP.Since Cohereâ€™s beginning, we've been focused on unlocking the vast potential of language for every developer and business. To do that, weâ€™re making natural language processing more accessible to developers, including those without"", 'Develop, test, and experiment with the industryâ€™s first multilingual text understanding model that supports 100+ languages Humans speak over 71001 languages, yet the majority of language models only support the English language. This makes it incredibly challenging to build products and projects using multilingual language understanding. Cohereâ€™s mission']",https://txt.cohere.ai/improving-chatbot-support-systems-using-llms/,Improving Chatbot Support Systems: Cohere Hackathon Winner,Guide,Blog
"[""This article's title and TL;DR have been generated with Cohere.Get started with text generation."", 'Marketing and advertising are crucial to getting your products in front of your target audience. But itâ€™s not enough to call attention to your products through an ad. You also have to describe their composition, features, benefits, and so on if you want to:', 'Creating new content for each product description can be time-consuming and repetitive. So, instead of writing these descriptions manually, you can use natural language processing (NLP) to do them automatically. Using NLP helps you keep up with changing trends, quickly generate content for new and updated products, and easily manage large product catalogs.', 'This tutorial teaches you how to use large language models (LLMs) to generate advertising content quickly, specifically product descriptions. Using the artificial intelligence (AI) capabilities of the Cohere Platform and its Generate endpoint, you can create a simple web application that uses keywords in a short phrase to generate multiple product descriptions and automate this repetitive copywriting task. \xa0', 'The Cohere Platform provides access to Cohereâ€™s LLMs through an easy-to-use API and endpoints like Cohere Generate. Cohereâ€™s LLMs have been trained using extensive text-based data from a wide variety of sources. When given a prompt or a phrase as input, the model can use what it has learned to paraphrase or create new content.', 'To build our product description generator using Cohere Generate, we can take either the prompt engineering or the fine-tuning approach. Prompt engineering involves writing inputs in a way that achieves the best generations, while fine-tuning consists of creating a custom model using your dataset, which makes the generated text more adaptable for your use case. In this tutorial, weâ€™ll use the prompt engineering approach.', 'Check out the final project code on Github.', 'To follow this tutorial, ensure you have the following:', 'On the left menu, click API Keys and create a trial API key. You use this key to gain access to the Cohere API and Generate endpoint. Itâ€™s important to note that trial keys are free, but theyâ€™re rate-limited, meaning itâ€™s not advisable to use them in production applications.', 'To get started, open a terminal window and navigate to your working directory using the command below.', 'cd /path/to/directory', 'Create a new Angular application by running the following command to bootstrap your web application.', 'ng new ad-generator â€”style=scss', 'Next, install these package dependencies:', 'The cohere-ai package needs them to work in a browser.', 'Enter the commands below in your terminal window.', 'Then, add some configurations to make the cohere-ai package work using the Angular framework. Open the tsconfig.json file. Add the following ""paths"" code block to the existing ""compilerOptions"" code block. This addition allows the Angular compiler to resolve packages needed by the cohere-ai package.', 'Finally, open the src/polyfill.ts file and add the following code block at the end of the file. This code attaches the required global variables to the windows object.', 'Now, you must integrate Cohereâ€™s Generate endpoint. Cohereâ€™s Node.js SDK supports TypeScript, making it easy to integrate with Angular. ', 'Open the src/app/app.component.ts file and import the SDK at the top of the file.', ""const cohere = require('cohere-ai');"", 'Next, delete the code inside the AppComponent class. Add a constructor function and initialize Cohere with the previously created API key.', 'In the AppComponent class, add the code snippet below. Youâ€™ll add a class property called generated to hold all the generated product descriptions for ads and another called prompt, which saves the product description entered by the user. ', 'Create a method for the AppComponent class called generateCopy. This method takes your product name and keywords as input and passes them to Cohereâ€™s Generate endpoint to get the generated product descriptions.', 'The Generate endpoint has parameters that allow you to shape the inputs provided and generate conditioned text results. These parameters include:', 'Check out the documentation for more information about configuring Cohere Generate.', 'In this section, youâ€™ll develop the user interface with a form to take in the product name and keywords in the form of a prompt. The user interface displays the generated product descriptions in a list.', 'First, install bootstrap, the package you use for styling. Open your terminal, navigate to the root directory of your web application, and run the following command.', 'npm i bootstrap@5.2.2 -s', 'Make sure you have bootstrapâ€™s styles loaded by opening the src/style.css file and adding the following import.', ""@import '../node_modules/bootstrap/dist/css/bootstrap.min.css';"", 'For forms to work in the web application, open the src/app/app.module.ts and import FormsModule by adding the following code at the top of the file.', ""import { FormsModule } from '@angular/forms';"", 'Next, add FormsModule in the imports array of the @NgModule decorator, as shown below.', 'Now, use the src/app/app.component.html file to write the markup code for your interface. Start by deleting all the code present in this file. Then create a form, two buttons, and a list using the code below.', 'To test the web application, open your terminal and run the command below to start the app.', 'ng serve', 'This launches your web application, which you access on port 4200 by opening a browser and entering http://localhost:4200. Youâ€™ll see an input for the product phrase with keywords on this page. Describe your product here and click Submit to generate copy text for the product.', 'The screenshot below shows your web application in action. The app can help you or your team create product descriptions with ease.', 'To build the web application for production, run the following command. The dist/ folder contains the compiled web application ready for deployment.', 'ng build ad-generator', 'AI-generated content can help companies describe products quickly and effectively. It helps advertisers keep up with the ever-changing trends in digital platforms. ', 'This tutorial explained how to use the Cohere Platform to generate product descriptions through a simple web application. The process outlined above can help you generate descriptions for hundreds of products with ease. ', 'Ready to get started with AI-generated content? Learn more about developing content with Cohere and sign up for a free Cohere account to start building.', 'Looking back at the moments that shaped the first six months of C4AI Cohere For AI launched in June of this year as a non-profit research lab and community dedicated to contributing fundamental research in machine learning. The vision for the lab was simple but ambitious: change how, where, and', ""Senior Google/YouTube Exec to join Cohere, focusing on the enormous commercial opportunity of NLP.Since Cohereâ€™s beginning, we've been focused on unlocking the vast potential of language for every developer and business. To do that, weâ€™re making natural language processing more accessible to developers, including those without"", 'Develop, test, and experiment with the industryâ€™s first multilingual text understanding model that supports 100+ languages Humans speak over 71001 languages, yet the majority of language models only support the English language. This makes it incredibly challenging to build products and projects using multilingual language understanding. Cohereâ€™s mission']",https://txt.cohere.ai/how-to-build-a-product-description-generator-with-llms/,How to Build a Product Description Generator with LLMs,Guide,Blog
"['Recent advances in large language models (LLMs) have fueled state-of-the-art performance for NLP applications, such as copy generation, tooling for conversational agents, semantic search, and more. At Cohere, we are fans of empowering our developer community to experiment and work with language AI. With Cohereâ€™s Sandbox open-source libraries, we want to inspire and empower you to quickly build novel language applications powered by Cohereâ€™s LLMsâ€”all while tackling your specific use case.', 'For the past few months, we\'ve been hard at work building Sandbox, a place where we release experimental and ""earlybird"" versions of open-source language AI modules, libraries, and demos to empower and inspire developers to build and deploy novel language applications fast with Cohere\'s LLMs.', 'Sandbox is a collection of experimental, open-source GitHub repositories (links available below) that make building applications using large language models fast and easy with Cohere, and/or showcase how such applications are built. Sandbox repositories aim to enable all developers, regardless of ML experience, to:', ""Sandbox aims to help build and strengthen language AI communities while enabling contributors to build more robust applications and services faster than ever. At Cohere, we want to help keep that pace of innovation going and empower developers to gain access, knowledge, and exposure to LLMs. Developers can contribute to Sandbox, regardless of their skill level. Just fork it, read our contribution guidelines (located under each repository's README), and support our open-source efforts."", 'Today, we want to share those development efforts with our developer community via a series of open-source GitHub repositories included in our first release. ', 'In this initial release, we are introducing:', ""While LLMs are relatively new and incredibly powerful, not everyone has first-hand access to them. By sharing experimental code as part of Cohere's Sandbox, we want to empower you with the right open-source tools to discover what's possible with language AI and help you build and deploy, fast."", ""This is just the beginning for Sandbox, as we plan to continue releasing new hands-on repositories to help with your use cases and deliver know-how and inspiration, over time. If you're feeling creative, consider supporting our open-source efforts by forking and experimenting with the projects, and feel free to share them with your friends and colleagues."", ""We welcome all feedback, issues, feature requests, contributions, documentation improvements, and bug reports. For more info, visit our guide on how to contribute (located under each project's repo). Don't forget to visit our Discord community and submit any ideas or feedback. For updates on our OSS efforts, follow us on Twitter and Linkedin."", 'Looking back at the moments that shaped the first six months of C4AI Cohere For AI launched in June of this year as a non-profit research lab and community dedicated to contributing fundamental research in machine learning. The vision for the lab was simple but ambitious: change how, where, and', ""Senior Google/YouTube Exec to join Cohere, focusing on the enormous commercial opportunity of NLP.Since Cohereâ€™s beginning, we've been focused on unlocking the vast potential of language for every developer and business. To do that, weâ€™re making natural language processing more accessible to developers, including those without"", 'Develop, test, and experiment with the industryâ€™s first multilingual text understanding model that supports 100+ languages Humans speak over 71001 languages, yet the majority of language models only support the English language. This makes it incredibly challenging to build products and projects using multilingual language understanding. Cohereâ€™s mission']",https://txt.cohere.ai/introducing-sandbox-coheres-experimental-open-source-initiative/,Introducing Cohere Sandbox: Open-Source Libraries to Help Developers Experiment with Language AI,Guide,Blog
"[""This article's title and TL;DR have been generated with Cohere.Get started with text generation."", ""Natural language processing (NLP) is invaluable, whether you're moderating member-posted content, quickly summarizing news articles, or providing auto-completion and auto-correction capabilities. In Python, NLP is mainly carried out using the Natural Language Toolkit (NLTK), which helps developers easily tap into Python's NLP capabilities. "", ""Cohere provides a Python software development kit (SDK) that you can add to your Python project with a simple pip install command. You can use Cohere's NLP capabilities, like summarization and classification, for a wide range of use cases, from eCommerce systems and social media platforms to team communication and news apps. "", ""In this tutorial, you'll use Cohere's Python SDK to add NLP functionality to an existing Python application. Then, your app will use Cohere's text summarizer endpoint to automatically summarize user reviews and analyze their overall sentiment and toxicity levels. "", ""You'll start by setting the sentiment of a review manually, after which the Cohere Platform will extract the first sentence and use it as the summary. Cohere will learn from this example and begin to classify text automatically, reducing the need for your input. Finally, Cohere will automatically analyze the overall sentiment of each review, determine whether or not it is suitable for saving based on toxicity, and then write a summary."", 'Before you begin, ensure that you have:', 'See the full project code on GitHub.', ""First, let's look at the initial Django app (see full build instructions)."", 'This is the home screen.', ""Under each product, there's a button that, when clicked, takes the user to a page where they can view the product's reviews and add a new review."", 'When the user clicks the Add a review button, the system displays the following page. ', 'There is a radio button for each sentiment and a form element where the user enters their review.', ""The following image shows the project's directory structure. Make a note of the directory's file names and locations."", ""You can locate the app's routes in the demoshop/urls.py. After firing, they render the respective views:"", ""The index method above displays the home page, product displays the product page, and add_review displays the review entry form. The last method, process_request, processes the POST request by tapping the user's form entries and removing trailing spaces using the strip() method. "", ""The if statement in the product function ensures the appropriate image is rendered based on the product's ID as passed in from the route."", ""The code In the demoshop/models.py file is used to add the review model. It will store a review using five fields: the summary (rev_summary), the reviewed product's ID (product_id), sentiment (rev_sentiment), full review (full_review), and the review id, which Django autogenerates. In the review class, the create method creates an instance of the class. This comes in handy when saving data to the database."", ""The images are stored in the demoshop/static/images in agreement with Django's static files semantics."", 'For the UI, use HTML files in the demoshop/templates/demoshop folder. Bootstrap 5 is used for styling. The files are for building user interfaces, which you can create or modify as preferred. ', 'Those are the essential files for the project. Make the necessary migrations and try running the app using the python manage.py runserver command.', ""In this final section, you'll add Cohere's NLP toolkit or dependency to the project. The project will first determine whether or not a review is appropriate to save to the database by using the classify class to check for toxic language. After the toxicity check, it will determine the sentiment using the classify class again. Lastly, it will summarize the review using the generate class."", 'Install Cohere using the command below.', 'pip install cohere', 'Then, open the demoshop/views.py file and import the required modules.', ""In the classify methods, set the user's entry in the prompt and set the model type and the test values in the examples array. The examples array takes in the test values in the Example class constructor. The generate class receives several parameters, but let's focus on prompt."", 'This parameter differs from classify as the value to be checked is added in the prompt and not an inputs array. Part of the test values for the generate class were taken from this Kaggle dataset. Using the generate class, Cohere does the summarization using the examples given. It learns the trends from the examples given and suitably summarizes a new prompt. Learn more about summarization in this Cohere guide.', 'Modify the demoshop/templates/demoshop/review_form.html by removing the snippet below to remove the radio buttons.', 'To make the application more accurate, feed in more data and try adjusting the parameters passed into the classes, especially generate.', 'Here is a working demo GIF.', 'NLP has countless applications, and the Cohere platform makes it easier to add NLP capabilities to your products. You only need an account and a test API Key. As the article demonstrates, you can easily add NLP to your Django applications using Cohere, and use the text summarizer endpoint to analyze user reviews as shown.', ""When you're ready, learn more about working with NLP in Python with Cohere."", 'Looking back at the moments that shaped the first six months of C4AI Cohere For AI launched in June of this year as a non-profit research lab and community dedicated to contributing fundamental research in machine learning. The vision for the lab was simple but ambitious: change how, where, and', ""Senior Google/YouTube Exec to join Cohere, focusing on the enormous commercial opportunity of NLP.Since Cohereâ€™s beginning, we've been focused on unlocking the vast potential of language for every developer and business. To do that, weâ€™re making natural language processing more accessible to developers, including those without"", 'Develop, test, and experiment with the industryâ€™s first multilingual text understanding model that supports 100+ languages Humans speak over 71001 languages, yet the majority of language models only support the English language. This makes it incredibly challenging to build products and projects using multilingual language understanding. Cohereâ€™s mission']",https://txt.cohere.ai/text-summarizer-app-user-reviews/,Integrate a Text Summarizer to your App to Analyze User Reviews,Guide,Blog
"['In the first episode of the Talking Language AI series, I spoke with Maarten Grootendorst, author and maintainer of the BERTopic open source package (over 3,000 stars on Github). BERTopic is used to explore collections of text to spot trends and identify the topics in these texts. This is an NLP task called Topic Modeling.', ""View the full episode here. It's also embedded in the bottom of this overview. Feel free to post questions or comments in this thread in the Cohere Discord."", 'Maarten started by giving an overview of BERTopic and what topic modeling is. In this overview, Maarten used awesome visual to explain what topic modeling is:', 'A visual way to describe BERTopic is as pipeline of the following steps:', 'Maarten discussed three central pillars of BERTopic:', '1- Modularity. To demonstrate modularity, Maarten showed the following awesome visual of the building blocks in the BERTopic pipeline and other options to construct the pipeline.', '2- Visualization', 'BERTopic allows for a number of ways to visualize the created topics. This includes the topic word scores plot:', 'Another commonly used visual is the Documents and Topics visual:', '3- Variations', 'Topic modeling needs different approaches in different scenarios, to address that, Maarten says that BERTopic is built to be flexible for use in many different scenarios. ', '', 'Maarten also went through a demo of how to use BERTopic to explore a dataset of research papers. I then proceeded to ask Maarten a few questions about his experience building NLP tools like BERTopic and others.', ""After Maarten's overview of BERTopic, I asked him the following questions. The links should lead you to that section of the video."", 'Q: How do you think about evaluating topic modeling tasks?', 'Q: BERTopic assigns a single topic to each document. Is that a limitation, or is it good enough for many use cases?', 'Q: How differently should long texts and short texts should be treated when using BERTopic?', 'Q: How do you think about API design philosophy for tasks like this?', 'Q: You have built library called KeyBERT. What does KeyBERT do?', ""Q: Another package you've built is PolyFuzz. What is PolyFuzz?"", 'Q: When using BERTopic in a language other English, what should BERTopic users change in the pipeline?', 'Q: When using the default BERTopic pipeline, HDBSCAN clustering often results in a large noise cluster (cluster: -1). How do you suggest users deal with that?', 'Q: How does BERTopic compare to LDA and Top2vec?', 'Q: What happens after topic modeling? Is it only used to generate reports? Have you seen it being used to create online systems?', 'Q: What do you think of using GPT language models in the topic modeling pipeline?', 'Q: By creating and maintaining BERTopic, you have created value for a lot of people. How can people contribute back?', 'Looking back at the moments that shaped the first six months of C4AI Cohere For AI launched in June of this year as a non-profit research lab and community dedicated to contributing fundamental research in machine learning. The vision for the lab was simple but ambitious: change how, where, and', ""Senior Google/YouTube Exec to join Cohere, focusing on the enormous commercial opportunity of NLP.Since Cohereâ€™s beginning, we've been focused on unlocking the vast potential of language for every developer and business. To do that, weâ€™re making natural language processing more accessible to developers, including those without"", 'Develop, test, and experiment with the industryâ€™s first multilingual text understanding model that supports 100+ languages Humans speak over 71001 languages, yet the majority of language models only support the English language. This makes it incredibly challenging to build products and projects using multilingual language understanding. Cohereâ€™s mission']",https://txt.cohere.ai/topic-modeling-with-bertopic/,Topic Modeling with BERTopic - Talking Language AI Ep#1,Guide,Blog
"[""If you work in NLP, it's important to keep up to date with the latest research. In this post, we look at some of the best papers on NLP that were published in October 2022"", 'This roundup highlights some interesting NLP papers from October 2022 around language model capabilities. ', ""This article's title and TL;DR have been generated with Cohere."", 'Get started with text generation.', ""NLP is evolving at a rapid pace, and every month we discover new capabilities. Large language models, like those built by Cohere, are being used for use cases that we couldn't have imagined even just a few months ago."", 'In this roundup, we highlight some interesting NLP papers on language model capabilities that were published in October 2022. Topics include recent work from Cohere For AI, different prompting methods for understanding dialogue and humor, use cases like summarization and essay scoring, and what language models learn beyond language. \xa0', 'Have fun reading these!', 'Authors: Jesse Mu, Victor Zhong, Roberta Raileanu, Minqi Jiang, Noah Goodman, Tim RocktÃ¤schel, Edward Grefenstett', 'Reinforcement learning agents have a hard time learning when rewards are few and far between. To solve this, we often use intrinsic rewards, which act as encouragement for the agent to explore its environment. ', 'However, many intrinsic exploration methods rely on state-based novelty measures, which can end up rewarding low-level exploration instead of more abstract skills. In this paper, the authors explore the use of natural language as a way to highlight relevant abstractions in an environment. ', ""Unlike previous work, they're testing to see if language can improve on existing exploration methods by directly extending (and comparing to) competitive intrinsic exploration baselines. So far, language-based variants are outperforming their non-linguistic counterparts by 45-85% across 13 challenging tasks from the MiniGrid and MiniHack environment suites."", 'Authors: Victor Zhong, Jesse Mu, Luke Zettlemoyer, Edward Grefenstette, Tim RocktÃ¤schel', 'Some recent work has shown that it can be helpful to provide language descriptions when learning how to do something in a new environment. However, in environments where the language descriptions are complex, it can be difficult to learn how to match the language to what is happening in the environment. This is because there are usually only a few opportunities to practice, and the rewards for getting it right are often delayed.', 'In this paper, the authors propose a method called Language Dynamics Distillation (LDD) to address this problem. With LDD, they first train a model to predict environment dynamics based on demonstrations that include language descriptions. Then, they fine-tune these language-aware pretrained representations using reinforcement learning (RL). This allows the model to learn not only how to maximize expected reward, but also how to retain knowledge about how language relates to environment dynamics.', 'They evaluated LDD on a benchmark of five tasks with language descriptions that present different challenges in generalizing to unseen environments. These tasks are called NetHack, ALFWorld, RTFM, Messenger, and Touchdown. Across all of these tasks, LDD outperformed tabula-rasa RL, VAE pretraining, and other methods that learn from demonstrations, either with or without language descriptions.', 'Authors: Laura Ruis, Akbir Khan, Stella Biderman, Sara Hooker, Tim RocktÃ¤schel, Edward Grefenstette', 'It\'s important to be able to understand language in context in order to communicate effectively. Humans are able to do this by using their beliefs and prior knowledge about the world. For example, if someone asks ""Did you leave fingerprints?"" and we respond, ""I wore gloves,"" they will understand that this means ""No.""', 'The authors wanted to see if language learning models (LLMs) could also make this type of inference, known as an implicature. They designed a simple task and evaluated it using different LLMs. They found that most LLMs performed close to random on this task. Models that were adapted to be ""aligned with human intent"" did better, but there was still a significant gap between their performance and human performance.', 'This research provides a starting point for further investigation into how LLMs interpret language in context. It can also help guide the development of more pragmatic and useful models of human discourse.', 'Authors: Niklas Muennighoff, Nouamane Tazi, LoÃ¯c Magne, Nils Reimers', ""There's a problem with the way people are evaluating text embeddings. Right now, people are only testing a small set of data from one task. This makes it hard to know if the text embeddings will work well for other tasks, like clustering or reranking. To solve this problem, the authors created the Massive Text Embedding Benchmark (MTEB). "", 'MTEB spans 8 embedding tasks covering a total of 56 datasets and 112 languages. Through the benchmarking of 33 models on MTEB, they were able to establish the most comprehensive benchmark of text embeddings to date. They found that no particular text embedding method dominates across all tasks. This suggests that the field has yet to converge on a universal text embedding method and scale it up sufficiently to provide state-of-the-art results on all embedding tasks.', 'Authors: Maximillian Chen, Alexandros Papangelis, Chenyang Tao, Andy Rosenbaum, Seokhwan Kim, Yang Liu, Zhou Yu, Dilek Hakkani-Tur', 'Dialogue understanding can be difficult when there is not a lot of data to work with. You need a lot of annotated data to achieve good performance. ', 'In this paper, the authors came up with a way to use large, pre-trained language models and iteratively apply weakly-supervised filters to improve augmentation quality. They put their methods to the test on emotion and act classification tasks in the DailyDialog dataset, and the intent classification task in the Facebook Multilingual Task-Oriented Dialogue dataset. ', 'Results showed that models fine-tuned on their augmented data mixed with a small amount of ground truth data outperform existing state-of-the-art models on both datasets. In fact, for DailyDialog specifically, using only 10% of the ground truth data, they were still able to outperform the current state-of-the-art model, which uses 100% of the data.', 'Authors: Junze Li, Mengjie Zhao, Yubo Xie, Antonis Maronikolakis, Pearl Pu, Hinrich SchÃ¼tze', 'Humor is subjective; what one person finds funny may not be what another person finds funny. This was first noted by ancient Greek philosophers, who observed that people laugh during comedies as a way of mocking or belittling others. The superiority theory of humor suggests that laughter is a way of showing superiority over other people, either by making fun of their physical defects or by making fun of their shortcomings.', 'However, this theory also suggests that some humor recognition datasets may include offensive content that could be offensive to certain groups of people. This is undesirable because a machine learning-based NLP system, such as a virtual assistant, should never respond to a user query with offensive content. Therefore, it is crucial to identify, mitigate, and reduce offensive content when modeling humor computationally.', 'In this paper, the authors found that prompting performs just as well as fine-tuning when there are numerous annotations available. However, prompting enables much better performance in low-resource humor recognition, which is when there are fewer annotations available. The authors also looked at the relationship between humor and offense by applying influence functions to prompting. They found that models could rely on offense to determine humor during transfer.', 'Authors: Liam van der Poel, Ryan Cotterell, Clara Meister', 'Although there has been some progress in the quality of language generated from abstractive summarization models, these models still tend to hallucinate and output content that is not supported by the source document. A number of methods have tried to fix this problem but with limited success.', 'In this paper, the authors identify a simple criterion under which models are significantly more likely to assign more probability to hallucinated content during generation: high model uncertainty. This finding offers a potential explanation for hallucinations: when models are uncertain about a continuation, they default to favoring text with high marginal probability, i.e., high-frequency occurrences in the training set.', 'The authors propose a decoding strategy that switches to optimizing for pointwise mutual information of the source and target token when the model exhibits uncertainty. Experiments on the XSum dataset show that this method decreases the probability of hallucinated tokens while maintaining the Rouge and BertS scores of top-performing decoding strategies.', 'Author: Kshitij Gupta', 'Investigating automated essay scoring has been a long-standing focus in the natural language processing (NLP) community because of its potential applications in both education and business. Recent advances in large, pre-trained models and data augmentation have made significant progress in this area, but many challenges remain.', 'This work demonstrates the effectiveness of transformer models and data augmentation for automated essay grading across a variety of topics. The findings show that transformer models are a promising approach for automated essay scoring, and they suggest avenues for further research.', 'Authors: Avinash Madasu, Shashank Srivastava', 'Large language models play an important role in natural language processing. These models are trained on large amounts of text, and they are known to acquire rich linguistic knowledge from this training. ', 'In this paper, the authors consider whether pretraining on text also gives these models helpful ""inductive biases"" for non-linguistic reasoning. They test this by training models on a set of 19 diverse non-linguistic tasks involving quantitative computations, recognizing regular expressions, and reasoning over strings.', 'The authors found that pre-trained models significantly outperform comparable non-pre-trained neural models. This remains true even in experiments with training non-pre-trained models with fewer parameters to account for model regularization effects. ', 'They further explore the effect of text domain on LLMs by pretraining models using text from different domains and provenances. The experiments surprisingly reveal that the positive effects of pretraining persist even when pre-training on multilingual text or computer code, and even on text generated from synthetic languages. This suggests an unexplored deep connection between pretraining and the inductive learning abilities of language models.', ""As we've seen, language models are evolving rapidly. Large language models are being used for a vast array of use cases beyond natural language generation (NLG). We still have a lot to learn about how these features work and how they should be constructed. If you're working with large volumes of text, you can possibly benefit greatly by incorporating large language models into your workflow. It may take some experimentation and tweaking to get the model to do exactly what you want, but these papers should give you an idea of how others go about it."", 'Is there a paper we should include in our next issue? Let us know on our Discord community. Get started with Cohere, try out our playground and start building.', 'Looking back at the moments that shaped the first six months of C4AI Cohere For AI launched in June of this year as a non-profit research lab and community dedicated to contributing fundamental research in machine learning. The vision for the lab was simple but ambitious: change how, where, and', ""Senior Google/YouTube Exec to join Cohere, focusing on the enormous commercial opportunity of NLP.Since Cohereâ€™s beginning, we've been focused on unlocking the vast potential of language for every developer and business. To do that, weâ€™re making natural language processing more accessible to developers, including those without"", 'Develop, test, and experiment with the industryâ€™s first multilingual text understanding model that supports 100+ languages Humans speak over 71001 languages, yet the majority of language models only support the English language. This makes it incredibly challenging to build products and projects using multilingual language understanding. Cohereâ€™s mission']",https://txt.cohere.ai/best-nlp-papers-october-2022/,Best NLP Papers — October 2022,Research,Blog
"['- Use an invoice scanning application to scan invoices and extract data for use in their accounting processes.- Use your companyâ€™s own dataset to train and use a pre-trained model to extract data from invoices.This articleâ€™s title and TL;DR have been generated with Cohere. Get started with text generation', 'From e-commerce platforms to brick-and-mortar chains to nationwide service providers, modern businesses utilize electronic documents, and one of the most widely used types of electronic documents is the invoice. Busy enterprises will handle a large volume of invoices as part of their accounting processes. This seems manageable enough until you need to start looking for specific information or categorizing invoices based on specific data, such as a customerâ€™s name and location, invoice amount, invoice reference number, and of course, the charges incurred.', 'Like searching for any kind of data, trying to sort through invoice data manually is inefficient and time-consuming. Adding to this challenge, external invoices can come in various formats with different layouts and data. Since standardization and consistency are key to keeping accounts balanced, monitoring and quantifying sales, and developing a holistic understanding of business processes and success, you need to extract data from these invoices both effectively and efficiently.', 'The best way is to build an invoice scanning application and then automate the data extraction process using machine learning (ML) or artificial intelligence (AI) language models. But doing so would require you to build, train, and retrain those models using your datasets for quite some time before their results would be refined enough for business use. In addition to being time-consuming, this training also requires high-level ML/AI expertise and consistent attention as youâ€™ll need to adjust the models to have them extract different invoice elements and handle different formats regularly.', 'Instead of taking on this laborious work, you can make handling and extracting invoice data easier and faster with the Cohere Platform. With pre-trained models for natural language processing (NLP), you donâ€™t need to worry about model training. Instead, you can use one of Cohereâ€™s pre-trained large language models and prompts â€” the inputs for the models â€” and start using them in your invoice scanner application immediately. All you need to do is provide prompts that contain the text to be analyzed and the label or element to be extracted, and then pass the prompts without the label. Then, Cohere will extract the text for you automatically. ', 'In this article, youâ€™ll see how to use the Cohere platform to extract different forms of data from invoices using a real-life dataset via Kaggle.', 'As mentioned earlier, this tutorial demonstrates how to extract data from restaurant invoices using a real-life dataset. Youâ€™ll begin by extracting a restaurantâ€™s name from an invoice, and then youâ€™ll extract its address.', 'Before beginning this tutorial, be sure you:', 'You can find the final project on GitHub.', 'To get started, create a new folder on your machine and call it cohere-invoice-extractor. Inside the folder, bootstrap an npm project by running npm init -y.', 'Next, install cohere-ai as a project dependency using the command below.', 'npm install cohere-ai', 'Next, youâ€™ll need to get your API key. After signing up or logging in, go to the Cohere dashboard. Once you see it, click on the Create API Key button at the bottom of the screen.', 'After clicking on the Create API Key button, proceed to enter the API name (enter any name of your choice) in the popup and click the Create API Key button.', 'Copy the API key and store it safely, as youâ€™ll need it later.', 'As mentioned in the introduction, this tutorial uses real-life datasets available via Kaggle. To access these datasets, begin by registering for a Kaggle account or signing in to your account if youâ€™ve used Kaggle before.', 'Then, download the invoice dataset by clicking the Download button.', 'This section guides you through extracting restaurant names from an invoice to demonstrate how Cohere can help you extract entities from an invoice.', 'To begin extraction, unzip the downloaded file and open the invoices.csv file in the folder. Then, copy the text from the invoices in the format shown below. You can use a few lines for this or all of them. The larger the number of lines, the better results.', ""In the invoice labels above, you have the buyer's name, email address, product ID, item quantity, and so on. â€œ--â€ \xa0is used to separate the data from different invoices. "", 'Cohere learns the pattern shown in the pasted invoice data and applies the ML algorithm to generate the product code of the invoice in question, which is usually the last piece of invoice data. Note the empty label, Product code:. That is where the extracted ID will be appended to.', 'Next, youâ€™ll use Cohereâ€™s NPL algorithm in a Node application that allows the user to enter the invoice details in a form that then displays the name to the user with the click of a button. This is visually summarized in the image below.', ""Since a user interface is being built, youâ€™ll need a way to parse the body of the request sent from the form. To do that, you'll need the Express framework and two modules: express and body-parser. The latter is the middleware for parsing the body request from the form."", 'Implement the two modules using the command below.', 'npm install express body-parser', 'With this installation done, you need to create the applicationâ€™s backend. Create a file called app.js from the root of your folder and add the code below.', 'The code first starts by importing the required modules, initializing the Express app, and goes through the Cohere dependency by passing in the API key. It then proceeds to add an async-await function called extractIt.', 'In this function, youâ€™ve used the generatemethod of the Cohere object to send a prompt for analysis. The generate method accepts an anonymous object with several options that you configure to control predictions (same as on the dashboard). Here, youâ€™ve used the following options:', 'After that, Expressâ€™s app.get function is used to render the HTML page where the UI will be placed. ', 'The app.post function takes in the parsed request body from the form, where the Node engine will internally use it to process the data. The text entered into the form by the user is retrieved and passed into the extractIt function, which will be sent to Cohereâ€™s NLP engine for extraction. The extracted value is then captured, converted to JSON, and then sent to the user.', 'Before creating the front end, be sure to add this line to the scripts object of the package.json file, as it sets the entry point for your Express app. The file is found in the root of your folder. ', '""start"": ""node app.js""', 'Next, you need to build the frontend. Create a file called ui.html in your root folder and add this snippet below to it. It contains the HTML elements for building out the form. Bootstrap 5 is used for styling. Itâ€™s added to the file using a CDN link.', 'At the end of the file, a JavaScript script is added. It starts with an arrow function called sendForExtraction, which fires after the button is clicked. It displays the extracted value in a <h5> element after retrieving it from the fetchValue method. fetchValueâ€™s logic shares similarities with what was done in the backend in the value retrieval. Next, test the code by running npm start in your terminal and heading on to http://localhost:4000/. This will be the output.', 'And as you can see, the NLP model correctly extracted the restaurant name! ', 'Note that itâ€™s good to experiment with this application and run it several times. If it outputs random values, the model becomes too creative. If this happens, you need to reduce the temperature. You can also experiment with the code to change the parameters p and k to see how it will affect the number of generations.', 'As another example of how Cohere can extract invoice entities, this section demonstrates how to extract an email address.', 'The data is the same, with only the labels changing.', 'After running the app again, youâ€™ll see the following output.', 'Again, the NLP model correctly recognized the email address.', 'Manually extracting data from invoices brings about many challenges. Some of them include inaccuracies, fatigue, slowness, and increased labor costs. With NLP, this can be automated and done quickly with little or no human intervention.', 'This has been a demonstration of how to use the Cohere Platform to perform text extraction quickly and efficiently in an invoice use case. You saw that using Cohere, the complex capabilities of natural language processing can be quickly and easily incorporated into your Node.JS applicationsâ€”all done using a form you created and linked with the backend.', 'Learn more about Cohereâ€™s Large Language Models and start building!', 'Looking back at the moments that shaped the first six months of C4AI Cohere For AI launched in June of this year as a non-profit research lab and community dedicated to contributing fundamental research in machine learning. The vision for the lab was simple but ambitious: change how, where, and', ""Senior Google/YouTube Exec to join Cohere, focusing on the enormous commercial opportunity of NLP.Since Cohereâ€™s beginning, we've been focused on unlocking the vast potential of language for every developer and business. To do that, weâ€™re making natural language processing more accessible to developers, including those without"", 'Develop, test, and experiment with the industryâ€™s first multilingual text understanding model that supports 100+ languages Humans speak over 71001 languages, yet the majority of language models only support the English language. This makes it incredibly challenging to build products and projects using multilingual language understanding. Cohereâ€™s mission']",https://txt.cohere.ai/extract-entities-from-invoices-using-large-language-models/,Extract Entities from Invoices Using Large Language Models,Guide,Blog
"['Today, weâ€™re thrilled to announce an entirely reimagined platform pricing structure designed to provide more flexibility, control, and value to every developer and business building on the Cohere Platform. Our new pricing opens up the platform to allow you greater access and a simpler experience when choosing the right resources for your project. Youâ€™ll be able to experiment more for free, estimate costs more easily, and see less jargon from us. Read on for the full details!', '1. Weâ€™re providing a brand new free developer tier. Natural language processing (NLP) has become part of the public consciousness due to its rapid evolution and increasing number of applications. We want to make it easier for every developer to explore the vast potential of NLP and experiment with it on the Cohere Platform. So, weâ€™re replacing our current $75 free credit program with a new freemium tier that gives you more hands-on experience with our API.', 'To enable the free tier, weâ€™re introducing two types of API keys that give users access to all of Cohereâ€™s endpoints: Trial API keys and Production API keys. All current API keys will automatically be converted to a Trial API key, which is rate-limited to 100 API calls per minute and cannot be used in production scenarios. If youâ€™re new to Cohere, get your Trial API key by signing up for an account.For developers looking for higher rate limits, or to serve Cohere to users in an application, you can upgrade to a Production API key where the throughput is 100 times higher (10,000 calls per minute). To upgrade your key now, simply complete the â€œGo to Productionâ€ workflow under the Usage tab in your dashboard (it takes less than 3 minutes).We hope that the new free tier will allow you to prototype using Cohere without worrying about having to upgrade in order to complete your experiment or proof of concept.', '2. We heard you, and weâ€™ve simplified our pricing plans. Thanks to your feedback and our relentless focus on improving efficiencies, weâ€™ve simplified our pricing structure to make it easier for you to estimate the costs of using our platform. Weâ€™re also reducing the price of our embeddings (decreased by more than 10x depending on the length of your inputs) to enable and encourage a broader range of applications and tasks to be built with Cohere. ', 'Hereâ€™s a summary of the new pricing model per endpoint:', 'We also want to make it easier for you to use our largest, best performing models by removing the pricing differences by model size â€” pricing of each endpoint will be standardized across sizes. This way, itâ€™s a no brainer to get the best product Cohere has to offer!', 'Custom Generate and Embed models will continue to be twice the price of their standard counterparts, whereas pricing for both Classify categories remain the same. Hereâ€™s a summary of the new costs:', '3. We continue to optimize how developers interact with Cohere. \xa0For starters, weâ€™re removing jargon in our product terminology. We recognize that language choices are not only critical to how we communicate in our every day lives, but they also impact the platform experience of our users. One aspect of this is how we refer to our products and features.', 'Since Cohere began, weâ€™ve been referencing â€œfinetuningâ€ to mean re-training the last few layers of a large language model, so that it performs better at a specific task. To better capture the meaning and spirit of this experience, â€œfinetuned modelsâ€ will be called â€œcustom models.â€ This means that instead of referring to the process of â€œfinetuning a model,â€ youâ€™ll see us referring to it as â€œtraining a custom model.â€', 'What about the standard, non-customized models (those that you would use as a starting point for re-training)? Theyâ€™ll be getting a naming makeover, too. Now, â€œbaseline modelsâ€ will be called â€œdefault models.â€', 'Nothing will change in how you access, use, or train our models, itâ€™s just the terminology that will be different. It may seem like a small thing, but we believe that it will give you a much more straightforward (i.e., enjoyable) experience on the platform. Youâ€™ll also notice a number of other changes, including four QuickStart guides for faster onboarding, easier sharing of custom models with team members, accuracy metrics and training logs for custom models, and more! Check out our full release notes.', 'At Cohere, weâ€™re dedicated to making developersâ€™ lives easier, and we hope these changes enable you to build even more awesome applications with Cohere. Let us know your feedback in our Discord Community or by sending us an email at team@cohere.ai.', 'Looking back at the moments that shaped the first six months of C4AI Cohere For AI launched in June of this year as a non-profit research lab and community dedicated to contributing fundamental research in machine learning. The vision for the lab was simple but ambitious: change how, where, and', ""Senior Google/YouTube Exec to join Cohere, focusing on the enormous commercial opportunity of NLP.Since Cohereâ€™s beginning, we've been focused on unlocking the vast potential of language for every developer and business. To do that, weâ€™re making natural language processing more accessible to developers, including those without"", 'Develop, test, and experiment with the industryâ€™s first multilingual text understanding model that supports 100+ languages Humans speak over 71001 languages, yet the majority of language models only support the English language. This makes it incredibly challenging to build products and projects using multilingual language understanding. Cohereâ€™s mission']",https://txt.cohere.ai/free-developer-tier-announcement/,Introducing a Free Developer Tier + Simplified Pricing,Product Launch,Blog
"['We are thrilled to announce the first event in the \xa0â€œTalking Language AI,â€ series hosted by Cohere Engineering Fellow Jay Alammar. Jay will be hosting a series of talks, panels, and discussions focused on applied natural language processing topics and tools.', 'For our first talk, we are honored to invite Maarten Grootendorst, open-source developer and maintainer of BERTopic, PolyFuzz, and KeyBERT, to share his insights and journey about creating BERTopic and explore three critical pillars on topic modelingâ€”modularity, variations, and visualizations.', 'These special sessions will begin on October 21st at noon ET and will be presented on a monthly cadence. To join the series, please register on Zoom. ', 'We hope to see you there!', 'Cohere Team', 'Looking back at the moments that shaped the first six months of C4AI Cohere For AI launched in June of this year as a non-profit research lab and community dedicated to contributing fundamental research in machine learning. The vision for the lab was simple but ambitious: change how, where, and', ""Senior Google/YouTube Exec to join Cohere, focusing on the enormous commercial opportunity of NLP.Since Cohereâ€™s beginning, we've been focused on unlocking the vast potential of language for every developer and business. To do that, weâ€™re making natural language processing more accessible to developers, including those without"", 'Develop, test, and experiment with the industryâ€™s first multilingual text understanding model that supports 100+ languages Humans speak over 71001 languages, yet the majority of language models only support the English language. This makes it incredibly challenging to build products and projects using multilingual language understanding. Cohereâ€™s mission']",https://txt.cohere.ai/announcing-the-talking-language-ai-series/,Announcing the Talking Language AI Series,Guide,Blog
"['Monitoring product feedback on social media is challengingâ€”even for businesses with a smaller product portfolio or market share. There can be countless messages sent at all hours of the day, with lots of text to review, and little time to analyze and sort them manually.', 'In this project tutorial, youâ€™ll learn how to create a Discord bot that harnesses the power of natural language processing (NLP) by using Cohere representation models to automatically analyze feedback and classify it into different product areas.', 'To build this bot, youâ€™ll need:', 'Youâ€™ll start by creating a Cohere API key, which allows you to access large language models from your code.', 'Log in to the Cohere Dashboard, scroll to the bottom to find the API Keys section, and click Create API Key.', 'Provide a name for the API Key, such as â€œFeedback Bot,â€ and click the Create API Key button. ', 'Copy and save the newly generated key, as youâ€™ll need it to use the Cohere API.', 'For this tutorial, youâ€™ll use a pre-trained text classification model and finetune it using a collection of example feedback that refers to four different product areas. Youâ€™ll do so using a simple two-column .csv spreadsheet containing the text sample and its label. You can find the sample data on GitHub.', 'Start by clicking on the Create finetune button in the Cohere Dashboard.', 'Change the Model type to Representation (Embed, Classify), select the Link to your .csv radio button and enter this link. Then, click Preview data.', 'On the next menu, check the Remove column headings option to exclude the top row of the .csv file, click Review data, and then name your finetune model and click Start finetuning. The finetuning process can take several minutes, so you may want to get a snack.', 'Once finetuning is completed, you can click on the Model ID to copy it to your clipboard. Save this ID alongside the API key you generated earlier.', 'Now, youâ€™ll test and make sure this finetuned model works. Click on Playground at the bottom of the dashboard and select the finetuned model. Enter some example text, such as â€œcurrent UI design is lacking in aestheticsâ€ (Product area 4) or â€œhow do we perform sentiment analysis on tweetsâ€ (Product area 2), to see how they perform.', 'Notice that, on the right side, thereâ€™s a column called Confidence Levels. Youâ€™ll set a threshold value of 0.8 to filter out low-confidence predictions, so you only send feedback on text with high-confidence levels. This means that most of the messages unrelated to product feedback will also be ignored.', 'Next, you need to configure a Discord application for the project.', 'If you donâ€™t already have a Discord server where you can add a Discord bot application, youâ€™ll need to create one from the Discord app on the browser or the downloaded application. Click the + button on the bottom left of the icon menu.', 'Select Create My Own or select from one of the templates. Skip the next question and then give a name for the server, such as â€œFeedback Test Server.â€', 'Open the Discord Developer Portal and select New Application on the top right.', 'Name the application something that youâ€™d like the bot to display and click Create.', 'Navigate to the Bot tab, press Add Bot, then click Yes, do it to create a new Discord bot.', 'Scroll down to the Privileged Gateway Intents section and toggle on the Message Content Intent option, so your bot can read the text of chat messages. Save the changes.', 'Next, open the OAuth2 > URL Generator page using the left menu and check the following options: bot, Read Messages/View Channels, and Send Messages. Scroll to the bottom and copy the generated linkâ€”this is the link to invite the bot into a Discord server.', 'Open a new browser tab and go to the generated link. Select the Discord server youâ€™ll use, then click Continue. Discord will ask you to authorize the permissions you previously selected, and your bot will be added to the Discord server.', 'Now you need the bot authentication token. Return to the application page in the Developer Portal, reopen the Bot tab, and click Reset Token.', 'This step will create an app token that youâ€™ll need for your code. Click the Copy button and save it with your Cohere API key from the earlier step.', 'The final step for your Discord app is to create a test channel on the server. This is where it will send feedback analysis. You can use the default #general channel to check messages for product feedback.', 'Create a text channel on the server by right-clicking in an empty area of the channel list section, selecting Create Channel, and naming it #feedback. If you want, you can create it as a private channel and organize it into its own category, so that itâ€™s closer to a real scenario.', 'In your Discord application, click on User Settings and navigate to Advanced. Toggle the Developer Mode to enable it and exit the settings. \xa0', ""Right-click on the #general channel and choose Copy ID to get the channel's ID. Then, save it with the other saved keys/tokens. Repeat this step for the #feedback channel."", 'Open a terminal window or command prompt to a new project folder and initialize the Node.js project with npm init -y.', 'Next, install the required dependencies for this project using npm install cohere-ai discord.js dotenv.', 'With your preferred code editor, open the project folder and create a new .env file at the project root. Then, enter your key/token information that you saved during the project setup process as follows.', 'Save and close the .env file and create an index.js file to contain your bot code.', 'Initialize the environment variables using dotenv.', 'require(""dotenv"").config();', 'Below that, import the cohere-ai and discord.js modules.', 'Next, you can set up some constants for your code from the environment variables.', 'Then, create the Cohere client and the Discord client.', 'Now, youâ€™ll create a helper function that can take any text message and try to classify it using the finetuned model you trained. This function calls the classifyMessage function in the cohere-api module with your finetuned model ID. Then, it returns the label and score of the best prediction.', 'Add a Discord message event handler to check sent messages. If the message is in the channel where youâ€™re checking for product feedback, and the prediction confidence is high enough, it should notify the #feedback channel.', 'Finally, at the bottom of the code, you can add an event handler for when your Discord client is ready and have the bot log in using your Discord API key.', 'For your reference, the full project code is also available to download on GitHub.', 'Youâ€™re ready to run the bot and see how it performs.', 'From your terminal window or command prompt, run node index.js to start the Discord bot. Try typing some of the product feedback messages into the #general channel, such as â€œwhat is this product?â€ and â€œI want more than 3 results per endpoint.â€ You can also try a message like, â€œthis message should be ignoredâ€ to check that non-feedback messages return a low confidence value and are ignored.', 'Cool, right?', 'As you can see, itâ€™s very easy to analyze and sort natural language text when you use a Cohere representation model. You can finetune it the way you want and add more training data to improve the accuracy of your classification.', 'While this is only an example project, the code can be extended to connect to other social media, such as Twitter, and analyze text across different sources.', 'To learn more, you can read about finetuning Cohere representation models or check out the full Cohere documentation. Finally, go out and connect with other members of the Cohere community on Discord.', 'Looking back at the moments that shaped the first six months of C4AI Cohere For AI launched in June of this year as a non-profit research lab and community dedicated to contributing fundamental research in machine learning. The vision for the lab was simple but ambitious: change how, where, and', ""Senior Google/YouTube Exec to join Cohere, focusing on the enormous commercial opportunity of NLP.Since Cohereâ€™s beginning, we've been focused on unlocking the vast potential of language for every developer and business. To do that, weâ€™re making natural language processing more accessible to developers, including those without"", 'Develop, test, and experiment with the industryâ€™s first multilingual text understanding model that supports 100+ languages Humans speak over 71001 languages, yet the majority of language models only support the English language. This makes it incredibly challenging to build products and projects using multilingual language understanding. Cohereâ€™s mission']",https://txt.cohere.ai/automating-user-feedback-monitoring-on-discord-using-ai/,Automating User Feedback Monitoring on Discord Using AI,Guide,Blog
"['Hello Cohere Makers,', 'We are so stoked to see you getting creative with our API! To showcase the amazing work of our community, weâ€™ll be hosting live co:lab friday Community Demos sessions featuring your Cohere-powered projects. These special sessions will begin on October 28th and will happen on the last Friday of every month during our regular co:lab friday meetup time, 12:00 pm ET.', 'The Community Demos session is your place to chat about what you are building, so you can get feedback on your project, well deserved love from the community, and practice your pitch game in case you need it later on! ðŸ”¥', ""Whenever you're ready, you can sign up to present your demo using the form linked below, and we will add you to the lineup for the upcoming session. You can sign up as many times as you like and with as many projects as you want!"", 'Apply to share your demo/s project here:', 'To join sessions as a participant, register here:', '28 Oct- https://discord.gg/BVgxkjGP?event=1029472280243359815', '25 Nov- https://discord.gg/BVgxkjGP?event=1029472876358799401', '16 Dec- https://discord.gg/BVgxkjGP?event=1029473076812972153', 'P.S. Make sure to join the co:mmunity conversation on Discord, if you havenâ€™t yet!', 'Canâ€™t wait to see what yâ€™all have been cooking with our API ðŸ‘©\u200dðŸ³ðŸ’•,', 'Sandra', 'Looking back at the moments that shaped the first six months of C4AI Cohere For AI launched in June of this year as a non-profit research lab and community dedicated to contributing fundamental research in machine learning. The vision for the lab was simple but ambitious: change how, where, and', ""Senior Google/YouTube Exec to join Cohere, focusing on the enormous commercial opportunity of NLP.Since Cohereâ€™s beginning, we've been focused on unlocking the vast potential of language for every developer and business. To do that, weâ€™re making natural language processing more accessible to developers, including those without"", 'Develop, test, and experiment with the industryâ€™s first multilingual text understanding model that supports 100+ languages Humans speak over 71001 languages, yet the majority of language models only support the English language. This makes it incredibly challenging to build products and projects using multilingual language understanding. Cohereâ€™s mission']",https://txt.cohere.ai/share-your-demo-project-with-the-community-at-our-new-co-lab-friday-events/,Share Your Demo Project with the Community at Our New co:lab friday Events,Co:lab,Blog
"['The petabytes of data held by global online communities, such as Twitter, make them valuable sources during data collection. You can use the data to study your target audience to gain insight into what people are tweeting about â€” as well as the sentiment of those tweets.', 'Twitter records over 500 million tweets per day from millions of users across the world. This volume presents analysts with a wide range of diverse datasets from users across different regions and backgrounds. However, this large size also makes manually searching for tweets \xa0a daunting and time-consuming task. ', 'So, what can you do instead? ', 'Using Cohere, Twitterâ€™s Standard Search API, and the Python programming language, you can apply automation and text classification to extract insights from a large volume of tweets. To do this, you will need to build a bot that fetches a large volume of tweets and classifies the sentiment expressed within them â€” either positive, negative, or neutral â€” using Cohere classifiers. ', 'This tutorial demonstrates how to create a keyword-driven tweet analysis bot that scrapes tweets related to a particular topic from the Twitter platform and performs sentiment analysis on them. Below is a quick preview of the Twitter bot in action.', 'You can find the final project code on GitHub.', 'This tutorial contains hands-on steps to build a tweet analysis bot using Python. To follow the tutorial, ensure you have the following:', 'The tweet analysis bot youâ€™re about to build will extract user sentiments related to the React, Next.js, Angular, Vue, Node.js, and Ember frameworks. The bot fetches 10,000 Tweets that contain a mention of these frameworks from the Search endpoint within the Twitter V2 API, and it then uses a Cohere classifier to classify the sentiment in the tweets as positive, negative, or neutral.', 'The bot uses Twitterâ€™s Standard Search API as the source of data and Cohere to classify the retrieved tweets. To interact with these two platforms, you need specific credentials to authenticate your HTTP requests to these services. ', 'Letâ€™s proceed to generate or retrieve these credentials.', 'Cohere API keys authenticate requests to the Cohere endpoints. The Cohere web console and CLI provide features to manage the API key generated for your Cohere account. Youâ€™ll use your API key to connect to Cohere when you have a batch of tweets ready for analysis. ', 'Using your browser, navigate to the Dashboard tab of your Cohere console to generate an API key. Click Create API Key to launch a dialogue box for specifying the name of your API key. Enter your preferred text in the API Key Name field to name the API key.', 'Click Create API Key on the dialog box to save the API key. Then, copy the generated API key to a secure file, as youâ€™ll use it in the next section.', ""Next, you need to create a Twitter application and retrieve the application's API credentials. "", 'A Twitter applicationâ€™s API credentials are within the Keys and tokens tab on the applicationâ€™s settings page. ', 'If your bearer token value is unknown, click Regenerate to regenerate the Bearer Token and copy the token to a secure file. Youâ€™ll use the Bearer Token to authenticate HTTP requests for fetching data from Twitter. ', 'With your Cohere API Key and the Bearer Token for your Twitter app, the stage is set for you to begin building the tweet analysis bot with Python.', 'To begin development, execute the series of commands below in your console to create a project directory (python-analysis-bot), move into the directory, then create a virtual environment using the virtualenv package and activate it. A virtual environment enables you to isolate the dependencies for your project. \xa0 ', 'Note: If you donâ€™t have the virtualenv package on your computer, execute the pip install virtualenv command to install it. ', 'Execute the pip command below to install the cohere, python-dotenv, and more-itertools packages from PyPi. ', 'You use the python-dotenv package to securely access your API credentials before fetching data from the Twitter Search endpoint and transforming the response with the more-itertools package. The installed Cohere package will perform all operations to classify text. \xa0', 'Next, create a .env file to store the Cohere and Twitter credentials securely. By separating your API credentials from the code, you prevent them from leaking whenever you push your code to a public code host.', 'Replace the placeholders below with your Cohere API Key and Twitter Bearer Token. \xa0', 'Create a file named app.py within the python-analysis-bot project. This file is the entry point and will execute when you run the bot.', ""Add the code block's content below into the app.py file to add the import and variable declarations needed for the application. "", 'Note: Take note of the indentation of the code blocks below, as indentation is mandatory for Python code. \xa0 ', 'Take note of the value of the query key within the request_params dictionary. The string \xa0â€œReact.js, Next.js, Angular.js, Vue, and Node.jsâ€ \xa0uses the OR standard search operator to find only tweets containing text written in English. ', 'Next, add the code below to the existing code within the app.py file to create a class for the analysis bot. The use of classes helps you keep the bot code clean, organized, and readable. ', 'The constructor method of the AnalysisBot above uses the requests package to make a GET request to the search endpoint of Twitter APIs, fetching 100 tweets and storing them in the retrieved_tweets list. The code places the request in a while loop to execute the GET request 100 times, fetching 10,000 tweets at the end of the loop.', 'Alongside the retrieved tweets, a token value is part of the API response for pagination purposes. The code adds the token value to a next_token key within the request_params to fetch the next batch of 100 tweets. \xa0', 'Note: Twitter allows developers with Elevated access to fetch a maximum of 100 tweets per API request, while allowing developers with Academic Research access to fetch a maximum of 500 tweets per API request. ', 'Add the code below to create the next method within the AnalysisBot class to classify all the fetched tweets. \xa0', 'The code above uses the more_itertools package to split the retrieved tweets into chunks containing 32 tweets each. This is because a Cohere classifier can simultaneously process a maximum of 32 inputs. The classifier also has eight examples of three positives, two negatives, and three neutral statements copied from usersâ€™ tweets on Twitter.', 'After classifying a batch of 32 tweets, the fields are further passed into a determine_results helper function to determine what framework was in the tweet and extract the classification type. ', 'Add the code below to create the helper method used by the classify_tweets method. ', 'Finally, add the code below to instantiate the AnalysisBot class and invoke the classify_tweets method on an instance of the AnalysisBot class.', 'At this point, you have put together the code for the tweet analysis bot. Proceed to run the application and watch the output. ', 'Execute the command below to run the app.py script. Due to the large volume of API requests, it can take 10-20 minutes for the entire process to complete. ', 'After its completion, the values of the results list will print out to show how many frameworks had a positive sentiment and how many times they did so. In the image below, you will see that React is used more often, but Node has a higher percentage of positive comments, with 224 positive tweets. ', 'At this point, you now have a basic analysis bot that you can run multiple times to analyze data from the Twitter Search API. ', 'However, keep in mind that, since the Twitter Search API returns new data upon each search, you may get a different result after running the bot multiple times.', 'Congratulations on completing this tutorial!', 'Using Cohere and Python, you classified 10,000 tweets from Twitterâ€™s Search endpoint. Manually classifying such a massive volume of data would have taken several hours or even an entire day. Using Cohere, youâ€™ve saved a significant amount of time and easily performed sentiment analysis to determine that Node.js is the best-liked Javascript framework. Now you know! .', 'Not done learning yet? Learn more about sentiment analysis through similar tutorials from Cohere.', '', 'Looking back at the moments that shaped the first six months of C4AI Cohere For AI launched in June of this year as a non-profit research lab and community dedicated to contributing fundamental research in machine learning. The vision for the lab was simple but ambitious: change how, where, and', ""Senior Google/YouTube Exec to join Cohere, focusing on the enormous commercial opportunity of NLP.Since Cohereâ€™s beginning, we've been focused on unlocking the vast potential of language for every developer and business. To do that, weâ€™re making natural language processing more accessible to developers, including those without"", 'Develop, test, and experiment with the industryâ€™s first multilingual text understanding model that supports 100+ languages Humans speak over 71001 languages, yet the majority of language models only support the English language. This makes it incredibly challenging to build products and projects using multilingual language understanding. Cohereâ€™s mission']",https://txt.cohere.ai/top-js-frameworks-using-a-tweet-analysis-bot/,Top JS Frameworks According to a Tweet Analysis Bot,Guide,Blog
"['The adoption of large language models (LLMs) is on the rise. Previously, many natural language processing (NLP) use cases required deploying several different models. With LLMs, one general-purpose model can support a wide variety of NLP use cases, greatly simplifying the integration of language-based machine learning capabilities, such as text generation, classification, semantic search, topic modeling, and entity extraction, into applications and systems.', 'At Cohere, our mission is to reduce the complexity of integrating NLP even further by exposing the capabilities of LLMs via a simple API. Our platform enables developers and teams to leverage the versatility and performance of LLMs without having to have the resources and expertise to build and deploy these models themselves.', 'The Cohere platform currently offers three types of endpoints:', 'As the Cohere platform grows, we are continually looking for ways to improve the experience of interacting with our API. One of our key focus areas is the platformâ€™s inference latency and throughput. From a userâ€™s point of view, this translates into the time it takes to receive a response after making a request.', 'This is especially important in time-sensitive applications, such as customer support chatbots. For example, when conversing with a virtual agent, an end-user expects a swift response to their queries. Frequent delays may result in the user leaving the conversation in frustration and not getting the support they were looking for.', 'As we explored ways to get the best possible model performance, we realized the importance of having the flexibility to choose how our backend is implemented. We wanted to maximize the potential of the NVIDIA GPUs, and we could only achieve that if we had more implementation options.', ""For example, our previous setup's inference mechanism was deployed primarily based on pipeline parallelism, which didnâ€™t allow us to take full advantage of multi-GPU inference. We would have realized a better model latency by switching to tensor parallelism, but with our previous backend framework, this would have taken an enormous amount of effort and customization to make it work."", 'Because of these reasons, we opted for the NVIDIA Triton Inference Server as our inference server framework. The key factor in our decision was that Triton could provide the flexibility of choosing different backend frameworks out of the box, allowing us to evaluate a selection of backends and identify the one best suited to our platform needs.', 'One of the backend frameworks that Triton supports is FasterTransformer, an open-source library that implements a highly optimized transformer layer for both the encoder and decoder to speed up inference. So, along with migrating to Triton as our inference server, we also migrated to FasterTransformer as our backend framework.', 'Overall, the outcome has been impressiveâ€”after we migrated to Triton and started using the FasterTransformer backend, weâ€™ve observed an increase of up to 4x in inference speed.', 'This was possible because FasterTransformer supports multi-GPU inference with tensor sharding. In other words, we were able to add tensor parallelism in our inference setup. This alone was massive because it meant that we could really maximize the potential of the multi-GPU system by significantly increasing its overall efficiency and utilization.', 'There were a few other factors in our decision. For example, the fast inter-GPU communication and ready-to-use fused operation kernels provided by the FasterTransformer backend also make it possible to further improve speed and performance.', 'Look at any industry vertical or individual organization, and you will find piles of unstructured text data. And this volume will only continue to grow as more and more of the worldâ€™s population interacts online at an unprecedented rate. Imagine if there was a much easier way to process this data and make it useful and actionable?', 'Cohere is dedicated to making NLP technologyâ€”previously only available to the big playersâ€”accessible to developers and teams of any size. By continuing to enhance the experience of interacting with our API, we can unlock even more use cases and serve even more developers and organizations. Migrating to NVIDIA Triton Inference Server helps us take significant strides toward this goal, and we are excited about what we can achieve with it going forward. ', 'Looking back at the moments that shaped the first six months of C4AI Cohere For AI launched in June of this year as a non-profit research lab and community dedicated to contributing fundamental research in machine learning. The vision for the lab was simple but ambitious: change how, where, and', ""Senior Google/YouTube Exec to join Cohere, focusing on the enormous commercial opportunity of NLP.Since Cohereâ€™s beginning, we've been focused on unlocking the vast potential of language for every developer and business. To do that, weâ€™re making natural language processing more accessible to developers, including those without"", 'Develop, test, and experiment with the industryâ€™s first multilingual text understanding model that supports 100+ languages Humans speak over 71001 languages, yet the majority of language models only support the English language. This makes it incredibly challenging to build products and projects using multilingual language understanding. Cohereâ€™s mission']",https://txt.cohere.ai/nvidia-boosts-inference-speed-with-cohere/,Cohere Boosts Inference Speed With NVIDIA Triton Inference Server,Press,Blog
"['Forums like Reddit contain vast amounts of text. In this demo, we should you how to summarize that automatically and get valuable insights.', 'Sites like Reddit contain a huge amount of text information on a variety of different topics, spread out across a huge forum. Because of this, itâ€™s both difficult and time-consuming to manually summarize and obtain key insights. However, with the use of the right AI model, it is possible to accomplish this type of summarization quickly and easily. ', 'Using a pre-trained model allows us to perform this task without the need to construct and train our own model. In this tutorial, youâ€™ll see how to use Cohereâ€™s LLM API to produce summaries of the top 20 posts of all time from Redditâ€™s literature subreddit. The subreddit of choice can easily be changed in the App.js file, which is explained later on. ', 'To begin, youâ€™ll bootstrap a React app.', 'Follow the steps below to create your React application for this guide.', 'First, run npx create-react-app reddit-posts-summarizer in your terminal. The image below shows the structure of your created project.', 'Then, change directories using cd reddit-posts-summarizer and launch the dev server with npm start.', 'Next, youâ€™ll connect the project to the Reddit API.', 'Before summarizing the Reddit posts, you first have to grab them from the /literature subreddit. You can choose whichever subreddit you want by replacing literature in the Reddit link below.', 'First, replace the contents of src/App.js with the following code.', 'The componentWillMount function invokes the getRedditPosts function, which grabs the top 20 posts in r/literature (with limit=20) of all time (with t=all).', 'To confirm that youâ€™ve retrieved the posts, visit r/literature and then launch your browserâ€™s console (CTRL + SHIFT + I on Windows). Once youâ€™ve connected, your console will list posts with some of their properties.', 'First, register your account, then select the Dashboard tab to navigate to your dashboard.', 'Next, select Create API Key. Give it a name and safely store the API key â€” youâ€™ll need it later. ', 'The application youâ€™ll build in this tutorial connects to Cohere using the JavaScript fetch API. Alternatively, you could use Cohereâ€™s official API client, which lets you use the Cohere Playground to quickly test parameter values for optimal results.', 'Text summarization with Cohere requires making a request to the Generate endpoint. The endpoint requires two specific parameters in your request:', 'For example, you can summarize the text, â€œHome is anywhere I find peace, even if itâ€™s a foreign landâ€, by providing the following prompt.', 'The first line of the prompt describes the task. Then, the Text and In summary statements give the LLM an example of successful task execution. In summary, is a simple output indicator, but you can also provide more elaborate indicators to tailor your results.', 'The Generate endpoint also accepts several optional parameters:', 'Next, youâ€™ll add a function that sends requests to the Generate endpoint.Paste the following code into src/App.js, above the getRedditPosts function inside the previously defined class App extends Component.', 'In the code above, you initialized an empty array, cohereSummaries, in your constructor. You then defined the getPostsSummaries function, which accepts a list of Reddit posts.', 'In the getPostsSummaries function, you configured your request headers. Remember to replace YOUR_API_KEY with your retrieved Cohere API key.', 'The same function then looped through the list of posts passed to it. For each post, you crafted a prompt following the rules discussed earlier, initialized your request parameters in the data variable, and then initiated a request to Cohere with fetch.', 'Finally, you updated your empty cohereSummaries array with this.setState({cohereSummaries: summaries}).', 'Now, with getPostsSummaries in place, invoke it in the getRedditPosts function with this.getPostsSummaries(posts).Your getRedditPosts() function should now appear as below.', 'Now, run your local development server. If everything goes well, youâ€™ll see the Cohere summaries logged in your browserâ€™s console.', 'Next, youâ€™ll render the post summaries to the DOM using the steps outlined below.First, create a file called src/components/Article.js and paste the snippet below into the file.', 'In the above code, you initialized a component: Article. This component displays the summary of a Reddit post and a link to the original post for reference. ', ""Now, open the src/App.js file and add import Article from './component/Article'; to the top of the file. Next, replace the render() block in src/App.js with the snippet below."", 'In the snippet above, the Article component renders each summary in the cohereSummaries array that you declared in the constructor, then populates it with data in the getPostsSummaries function.', 'Finally, fire up your local development server. You should then see summaries of the top 20 Reddit posts of all time, along with their links and confidence levels, as shown in the image below.', ""You've now experienced how large language models are enhancing the capabilities of machines to process language. Moreover, Cohereâ€™s straightforward API makes it even simpler to integrate NLP features into a project."", 'Because Cohereâ€™s LLMs have been trained with a massive dataset, they are well equipped to perform tasks like text summarization.To explore all that Cohere can do for you, sign up for an account and get started!', '', 'Looking back at the moments that shaped the first six months of C4AI Cohere For AI launched in June of this year as a non-profit research lab and community dedicated to contributing fundamental research in machine learning. The vision for the lab was simple but ambitious: change how, where, and', ""Senior Google/YouTube Exec to join Cohere, focusing on the enormous commercial opportunity of NLP.Since Cohereâ€™s beginning, we've been focused on unlocking the vast potential of language for every developer and business. To do that, weâ€™re making natural language processing more accessible to developers, including those without"", 'Develop, test, and experiment with the industryâ€™s first multilingual text understanding model that supports 100+ languages Humans speak over 71001 languages, yet the majority of language models only support the English language. This makes it incredibly challenging to build products and projects using multilingual language understanding. Cohereâ€™s mission']",https://txt.cohere.ai/how-to-build-an-ai-summarizer-for-any-sub-reddit/,How To Use AI To Summarize The Top Posts Of A Sub-Reddit,Guide,Blog
"['Aidan was featured on stage at the Elevate Festival in Toronto, joined by essayist Stephen Marche to discuss large language models and whatâ€™s next for the emerging technology.', 'Last week, our CEO and co-founder Aidan Gomez was featured on stage at the Elevate Festival in Toronto. He was joined by Stephen Marche, a novelist and essayist who has written about NLP for The New Yorker, The Atlantic and The New York Times.', 'Aidan and Stephen sat down for a discussion on language technology and what the future holds. In case you missed it, hereâ€™s part of their conversation:', 'Stephen: My â€œholy shitâ€ moment using language models was when I was writing a piece for The New Yorker. I asked GPT-3 to finish famous unfinished poems, and they worked. They truly sounded like Coleridge or Shakespeare. When was your â€œholy shitâ€ moment?', 'Aidan: It happened shortly after the Transformer paper came out. I was in Toronto, and I got an email from my colleague back at Google. He sent me what was seemingly a Wikipedia page on the Transformer. I started reading and it went into a story about a Japanese punk band, how the members had broken up. At the end of the email he said, â€œI just put in â€˜the Transformer,â€™ everything else was written by the model.â€ I was floored. Up until that point, our models could barely do anything. They couldnâ€™t spell correctly. He trained a language model on Wikipedia and it crafted a super compelling story about the Transformer, the Japanese punk band.', 'Stephen: Thereâ€™s so much of this that I donâ€™t understand. Obviously, my PhD is in Shakespeare so Iâ€™m not supposed to understand it, but you are. Can you tell me what you do and donâ€™t understand about the process? \xa0', 'Aidan: Iâ€™m so close to the nuts and bolts of it that I often just see a bunch of matrix multiplications and floating point numbers. But when I step back and I look at the outputs â€” at a system we built where you can say â€œhey solve this problem for meâ€ and it solves the problem â€” that is so extraordinary. Itâ€™s still magical for me. Thereâ€™s still so much to be understood. ', 'I understand how you source the data. I understand how the model is trained on that data. I understand how to scale up. When you put those three things together and actually get the output â€” youâ€™re sitting in front of a trained model â€” I still donâ€™t fully understand why the outputs are the outputs. Why does a model pick one option over another option? Getting into the way it makes those selections, thatâ€™s still an area of active research.', 'Stephen: Why arenâ€™t we seeing more of this technology out in the world?', ""Aidan: Yeah, there's frustration there. We were promised that AI will change the world, and Iâ€™m just not seeing it. Iâ€™m a consumer too â€” I use all the same products that everyone else uses. I know the technology, I know what itâ€™s capable of, but itâ€™s not out there. "", 'For Cohere, the mission is to push it out further. The way weâ€™re doing that is by trying to lower barriers. One of the largest barriers that Iâ€™m sure a lot of people are aware of is that the people who know how to do this stuff â€” MLEs or machine learning engineers â€” we canâ€™t train enough of them. Thereâ€™s a supply-demand dynamic where thereâ€™s not enough talent on the face of the planet and there wonâ€™t be. ', 'Stephen: Why?', 'Aidan: Itâ€™s going to take us so long to meet that demand â€” decades of education and new students. The way to bring AI into the products of today is not to train a bunch of people with highly specialized knowledge, instead itâ€™s to present the technology in a different way. ', ""At Cohere, weâ€™re creating an interface onto Transformers and onto supercomputers that's accessible to anyone, to any developer. Using this technology should be intuitive and natural. Thatâ€™s the mission; thatâ€™s our product vision."", 'Stephen: When you imagine where language AI is going to be in 5-10 years, what do you see?', 'Aidan: In gaming, for instance, today if youâ€™re interacting with a character, thereâ€™s a dialogue tree that someoneâ€™s written, and thereâ€™s maybe ten paths through that dialogue tree. Every single player has the same experience. I imagine a world where games have a dialogue tree of 8 or 10 billion paths, and everyone experiences a different conversation with that character. Every single play-through is unique. ', 'When you introduce this concept to the rest of the world, you have more mundane examples, like in customer support. As soon as I get a customer support chatbot, the first thing I write is â€œhuman,â€ â€œI want to talk to a human.â€ If we actually had compelling models of language â€” if we could actually create a chatbot that a human wants to talk to â€” it would change the interface of tech. Dialogue would be the interface. You could talk to your technology. ', 'Right now, we must learn the computerâ€™s language. I went to school for five years to learn how to talk to a computer, to tell it what to do, and to code it. I learned to speak its language. Weâ€™re not yet in a place where our products speak our language. That will change.', 'Looking back at the moments that shaped the first six months of C4AI Cohere For AI launched in June of this year as a non-profit research lab and community dedicated to contributing fundamental research in machine learning. The vision for the lab was simple but ambitious: change how, where, and', ""Senior Google/YouTube Exec to join Cohere, focusing on the enormous commercial opportunity of NLP.Since Cohereâ€™s beginning, we've been focused on unlocking the vast potential of language for every developer and business. To do that, weâ€™re making natural language processing more accessible to developers, including those without"", 'Develop, test, and experiment with the industryâ€™s first multilingual text understanding model that supports 100+ languages Humans speak over 71001 languages, yet the majority of language models only support the English language. This makes it incredibly challenging to build products and projects using multilingual language understanding. Cohereâ€™s mission']",https://txt.cohere.ai/cohere-elevate-festival-2022/,The Future of Language AI: A Conversation with CEO & Cofounder Aidan Gomez,Press,Blog
"['Weâ€™ll explore how developers can build the next generation of digital note-taking tools, powered by language AI.', 'The internet has made the world a smaller place and enabled us to collectively produce a massive amount of information. But turning this firehose of raw data into useful knowledge is challenging.', 'Because of this, the topic of Personal Knowledge Management (PKM) has been getting a lot of attention in recent years. It looks into how we can efficiently capture, organize, and ultimately make use of all the information around us.', 'So, itâ€™s not surprising that digital note-taking applications are now proliferating, coming in different shapes and flavors. They allow us to conveniently capture and organize our notes, give us access to them when we need them, easily search for the information we need, or share notes with others. ', 'Having said that, these tools still very much require that users invest a significant amount of time and effort to make them work. But not everyone has the patience and discipline to keep their personal PKM system running.', 'What if we could leverage language AI technology to make the whole experience more frictionless, and even more enjoyable? Imagine fusing language AI into these note-taking tools and taking them to the next level â€” organize, condense, connect, and even create new information. ', 'There exists an opportunity for developers and entrepreneurs to build innovative products that help users get even more out of what they consume.', 'In this article, weâ€™ll focus on one particular PKM use case: how we make sense of our notes. The premise is that, while we typically organize information in files and folders, our brains donâ€™t actually work that way. Our creativity comes from connecting seemingly disconnected ideas, and a folder structure for organizing information does not help us do that. ', 'This is where the graph approach comes in. The idea is to connect information in a network-like fashion rather than in folders, which frees up information instead of having it stuck in compartments.', 'The way of thinking about the graph is analogous to how the world wide web is organized. One web page contains links pointing to other web pages, which in turn contain more links pointing to other web pages. As a websiteâ€™s information expands, its number of pages increases, and eventually they all form a web of information connected via links.', 'The graph works in a similar manner, except now the context is your personal collection of notes. When your notes are connected in this way (instead of being buried somewhere and never to be found again), they become more discoverable. This facilitates the serendipitous generation of ideas from the notes that you have been curating all the while.', 'There are already a number of digital note-taking tools that support the creation of such graphs. But the problem is, as weâ€™ve mentioned earlier, to make it work, users will have to invest a substantial amount of effort to build the links manually over time.', 'What if we could build an AI-assistant that can make these connections automatically? And what if this AI-assistant could also help generate notes and surface new ideas collaboratively with users? ', 'Letâ€™s go through a demo to explore this idea.', 'In this demo, weâ€™ll explore two specific ways that language AI can be used to enhance the experience of using note-taking applications, namely:', 'Large language models (LLM) have been pre-trained with a massive collection of text, which makes them capable of capturing the patterns of how humans use language. The outcome: just by giving them a simple prompt, these models can generate impressively original and coherent text.', 'With the Cohereâ€™s API, this capability is served by the Generate endpoint. Given an input (called a â€œpromptâ€), the endpoint will generate a new stream of text. The purpose of a prompt is to provide a context for the text that we want the model to generate.', 'A basic format that generally works well contains a short description of the overall context followed by a few examples of prompts and completions. Needing just a few examples, it establishes patterns, or â€œtrainingâ€ data, for telling the model of what kind of text to generate next. Read this documentation if you would like to learn more.', 'The Generate endpoint can be applied in many different use cases, and one of them is in extracting information from a piece of text. The key is in the prompt, where we need to show a few examples of a piece of text and the kind of information to extract from the text.', 'Weâ€™ll build an extraction step that takes each note â€” letâ€™s call this the â€œparentâ€ note â€” and suggests parts of that note that can be expanded into its own note. These new â€œchildâ€ notes would then become links and be linked back to the parent note.', 'The prompt weâ€™ll use is as follows. It contains a few examples of a note and the corresponding topics or key concepts within the note.', 'Letâ€™s test it with a couple of short notes, as follows.', 'Software Engineering:', 'Software engineering is a very broad field, but itâ€™s also one of the fastest growing professions in the world. Software engineering is the application of engineering principles to software development.', 'Software engineering is about more than just writing code; itâ€™s about designing and developing software that meets the needs of customers and users. Software engineers are responsible for creating new programs and applications, as well as maintaining and fixing existing ones.', 'Artificial Intelligence:', 'Artificial intelligence (AI) is the simulation of human intelligence processes by machines, especially computer systems.', 'Artificial intelligence (AI) is used in many applications today, including voice recognition, self-driving cars, and even some household appliances. AI is also used in video games, where it can control the behavior of non-player characters in order to create more realistic interactions between the player and the game world.', 'We call the Generate endpoint via the co.generate() method to generate the potential links for each of these two notes.', 'We wonâ€™t cover the details here, but if youâ€™d like to understand what the parameters used in this method mean, you can read about them in the API documentation or this blog post.', 'And using our two example notes, the endpoint suggests the following topics:', 'Software Engineering:\nSoftware Development, Software Engineers', 'Artificial Intelligence:\nVideo Games, Non-Player Characters, Realistic Interactions', 'Notice how these suggested topics were taken from the note passage. These then will become new links to be created and linked back to the original note.', 'There are still many ways we can enhance this further. One of them is to add more sophistication to the link suggestions. We used a simple prompt consisting of a few examples of straightforward extractions in this demo. But sometimes we want the model to identify deeper concepts within a text, and thatâ€™s when it needs to see more examples to do its job well. ', 'We can do this by finetuning a model. Finetuning uses a custom dataset to retrain a model, so it can specialize in performing a specific task. Finetuning with the Cohere API is a simple process, which you can read more about in the docs.', 'When building a personal knowledge base, the notes we create come uniquely from our own experiences. We record what weâ€™ve learnt and what weâ€™ve been thinking about, and these build over time. The main ideas and inspiration come from no one else but ourselves.', 'But what if we could get the help of an AI-assistant to make the whole process more effective? Whenever you are stuck, the assistant comes to the rescue and suggests new ideas to be expanded upon or new areas to be studied.', 'Letâ€™s see how we might do this. We can use the same Generate endpoint but with a different prompt. The prompt weâ€™ll use contains a few examples of a topic name and its corresponding note.', 'We call the Generate endpoint, with slight changes to the max_tokens and the temperature parameters (hereâ€™s the documentation again) to generate a new note given a topic.', 'As an example, letâ€™s take one of the suggested topics we got in the previous section: Software Development. Below is the generated note.', 'Software Development:', 'Software development is the process of conceiving, specifying, designing, programming, documenting, testing, and bug fixing involved in creating and maintaining applications, frameworks, or other software components.', 'Software engineering is an engineering branch associated with development of software in a systematic method. The systematic method is known as software development life cycle (SDLC).', 'While this short note is unlikely to be the final version weâ€™d keep, notice that it already contains many concepts and ideas that we could now expand on. So, instead of staring at a blank screen, an AI-assistant is a welcome help in growing a knowledge base.', 'Weâ€™ve now covered the two use cases: building links and generating note ideas. But their benefits will only become evident when there is some scale involved. So, letâ€™s complete this demo with a hypothetical example of growing a knowledge base from scratch and visualizing the resulting graph.', 'Weâ€™ll start by seeding a few initial topics: Computer Science, Software Engineering, Programming, and Artificial Intelligence. We want the model to generate a short note for each of these topics, suggest new links from each note, and then repeat this cycle for a few rounds.', 'Once thatâ€™s done, we may want to visualize the graph of this knowledge base. With Python, we can use libraries such as Pyvis (which is what we are using here).', 'After a few cycles, this is what the graph looks like.', 'Each dot represents a note in which the title is shown. Each connecting line between two notes indicates that one of the notes mentions the other noteâ€™s topic in its contents. And as we traverse the graph, we can trace how one topic relates to another.', 'In the demo, we used the Generate endpoint to help us build a personal knowledge base. We looked at a couple of ways to utilize this endpoint: first, to generate paragraphs of text, and second, to extract links from an existing text.', 'However, there are so many other possible ways to build with this endpoint. For example, you can summarize a long piece of text into a condensed format, rewrite a text to follow a specific tone, build a conversational agent, create a question answering interface, and much more. ', 'And the nice thing is, you donâ€™t have to have a lot of training data to start prototyping with the model â€” just start with a short prompt. This blog post shares a few more ideas of what you can build with this endpoint.', 'To try out the Cohere platform, sign up for an account today!', 'Looking back at the moments that shaped the first six months of C4AI Cohere For AI launched in June of this year as a non-profit research lab and community dedicated to contributing fundamental research in machine learning. The vision for the lab was simple but ambitious: change how, where, and', ""Senior Google/YouTube Exec to join Cohere, focusing on the enormous commercial opportunity of NLP.Since Cohereâ€™s beginning, we've been focused on unlocking the vast potential of language for every developer and business. To do that, weâ€™re making natural language processing more accessible to developers, including those without"", 'Develop, test, and experiment with the industryâ€™s first multilingual text understanding model that supports 100+ languages Humans speak over 71001 languages, yet the majority of language models only support the English language. This makes it incredibly challenging to build products and projects using multilingual language understanding. Cohereâ€™s mission']",https://txt.cohere.ai/augmenting-pkm/,Augmenting Personal Knowledge Management with Language AI,Guide,Blog
"[""We're excited to announce our Scholars Program, inviting a class of emerging talent to work alongside our team â€“ exploring the unknown, together. If you're looking for an opportunity to develop your research skills, your journey starts here."", 'Cohere For AI is a research lab that seeks to solve complex machine learning problems. We believe the best minds transcend borders and that discoveries are often made off the beaten path. Today, I am excited to announce the launch of our Cohere For AI Scholars Program, designed to help change where, how, and by whom research is done.', 'Progress in machine learning is moving at an incredible pace, and broadening access to participation in fundamental research is essential to pioneering new advancements. Still, there are very few settings to conduct research on cutting-edge NLP problems, and limited access to large-scale ML experimental settings. Our goal is to change that and support the next generation of rising stars as they embark on their research journey.', 'The Scholars Program provides the opportunity to work alongside some of the best researchers and engineering expertise in the world â€” exploring the unknown, together. It will serve as an open, supportive environment that provides an alternative point of entry into NLP research. We wonâ€™t insist on prior degrees or formal experience working in a research lab. Instead, our goal is to identify emerging talent around the world. In fact, our one criterion for selection is that you cannot have published a machine learning research paper previously.', 'If accepted, youâ€™ll join a dedicated team of passionate researchers and industry experts from January to August 2023, and will be paired with a project proposal, allowing you to grow as a researcher. Participation is full-time, remote-first and paid. As part of the program, Scholars will have access to a large-scale experimental framework, and will help advance our commitment to supporting responsible, fundamental research on machine learning topics while prioritizing good stewardship of open source scientific practices. ', 'If you are an aspiring NLP researcher and looking for an opportunity to develop your research skills, your journey starts here. ', 'Stay up-to-date on the application process by checking out our website and following us on Twitter. To learn more about our program specifics, the application process and for helpful tips, watch our Information Session video. Applications are due November 7.', ""Cohere For AI launched in June of this year. We are a non-profit research lab and community dedicated to contributing fundamental research in machine learning, working to solve some of the field's most challenging problems. Our programs include supporting community-driven research across fundamental machine learning topics, our full-time research positions and lab, and our speaker series, which provides a forum for important and timely discussions on machine learning topics. We welcome anyone to apply to join our community and register for our upcoming speaker series."", 'Looking back at the moments that shaped the first six months of C4AI Cohere For AI launched in June of this year as a non-profit research lab and community dedicated to contributing fundamental research in machine learning. The vision for the lab was simple but ambitious: change how, where, and', ""Senior Google/YouTube Exec to join Cohere, focusing on the enormous commercial opportunity of NLP.Since Cohereâ€™s beginning, we've been focused on unlocking the vast potential of language for every developer and business. To do that, weâ€™re making natural language processing more accessible to developers, including those without"", 'Develop, test, and experiment with the industryâ€™s first multilingual text understanding model that supports 100+ languages Humans speak over 71001 languages, yet the majority of language models only support the English language. This makes it incredibly challenging to build products and projects using multilingual language understanding. Cohereâ€™s mission']",https://txt.cohere.ai/introducing-the-cohere-for-ai-scholars-program-your-research-journey-starts-here/,Introducing the Cohere For AI Scholars Program: Your Research Journey Starts Here,Careers,Blog
"Language models have shown to do some pretty surprising and impressive things. But the models don't internalize the performance gains given by these prompts. To overcome this, we can look into how humans do it for maybe some loose inspiration.",https://www.youtube.com/watch?v=IKtAFLUAYvM&list=PLLalUvky4CLILc8l3rG5USOal2vPBqyAB&index=1,Learning by Distilling Context with Charlie Snell,Technical Talks,Video
context distillation builds on a lot of the ideas of traditional machine learning. The distillation process is instead driven by the difference in the context tokens that are available to the two models.,https://www.youtube.com/watch?v=IKtAFLUAYvM&list=PLLalUvky4CLILc8l3rG5USOal2vPBqyAB&index=1,Learning by Distilling Context with Charlie Snell,Technical Talks,Video
The framework for context distillation includes an input generator and a prompt template. The next component is the answer extractor which pulls out the final answer from the teacher's generation. There are two ways to combine multiple distillation steps or distill multiple prompts at the same time.,https://www.youtube.com/watch?v=IKtAFLUAYvM&list=PLLalUvky4CLILc8l3rG5USOal2vPBqyAB&index=1,Learning by Distilling Context with Charlie Snell,Technical Talks,Video
"context distillation can learn from abstract instructions and natural language explanations, concrete training examples. It can also learn from step by step reasoning processes. In some cases, it might be preferable to fine tuning depending on your use case.",https://www.youtube.com/watch?v=IKtAFLUAYvM&list=PLLalUvky4CLILc8l3rG5USOal2vPBqyAB&index=1,Learning by Distilling Context with Charlie Snell,Technical Talks,Video
" context distillation can outperform directly learning with gradient descent. The teacher has 27.7% accuracy on four training examples, 28.2 on eight training examples. If you distill eight examples with multiple prompts, you can improve over the four.",https://www.youtube.com/watch?v=IKtAFLUAYvM&list=PLLalUvky4CLILc8l3rG5USOal2vPBqyAB&index=1,Learning by Distilling Context with Charlie Snell,Technical Talks,Video
"A general question I have is when shouldn't you use context installation? In some tasks, using the knowledge in the InContext examples might be more useful than others. It really just depends on the task and how much data you have.",https://www.youtube.com/watch?v=IKtAFLUAYvM&list=PLLalUvky4CLILc8l3rG5USOal2vPBqyAB&index=1,Learning by Distilling Context with Charlie Snell,Technical Talks,Video
"Does the size of the student model matter for InContext installation results? For most of our experiments we took the largest model we could. And so this result of context distillation, we do generally expect that it should work better with larger models.",https://www.youtube.com/watch?v=IKtAFLUAYvM&list=PLLalUvky4CLILc8l3rG5USOal2vPBqyAB&index=1,Learning by Distilling Context with Charlie Snell,Technical Talks,Video
Are there any interdependencies between how much effort it takes to forget something by recursive overriding to remember several different tasks? We found it not to be a huge issue. One way to get around this could be like we did in the last experiment.,https://www.youtube.com/watch?v=IKtAFLUAYvM&list=PLLalUvky4CLILc8l3rG5USOal2vPBqyAB&index=1,Learning by Distilling Context with Charlie Snell,Technical Talks,Video
"A lot of it was actually just this inspiration that we talked about at the beginning, just like, how do humans do it? Can we come up with some analogy that was sort of the starting point for this research?",https://www.youtube.com/watch?v=IKtAFLUAYvM&list=PLLalUvky4CLILc8l3rG5USOal2vPBqyAB&index=1,Learning by Distilling Context with Charlie Snell,Technical Talks,Video
"Is the main benefit from cortex isolation to reduce prompt links? I think fundamentally that's the reason. And if you do this on simple tasks, you might be able to build up the skills to do more complicated tasks.",https://www.youtube.com/watch?v=IKtAFLUAYvM&list=PLLalUvky4CLILc8l3rG5USOal2vPBqyAB&index=1,Learning by Distilling Context with Charlie Snell,Technical Talks,Video
Natural language processing is a field of AI that allows computers to understand language similar to how humans do. Over 80% of the world's data is unstructured. NLP is important because it unlocks that 80 per cent of data that's currently not really in use.,https://www.youtube.com/watch?v=RW3xIDRoFec,How Startups Can Use NLP to Build a Competitive Moat,Cohere Talks,Video
"Coher is built on Google Cloud using the latest technology, and we're also built by exclusive brain engineers. Our mission really is to make it accessible, easy, affordable and safe for companies like yourselves or anyone who's looking to build an NLP solution.",https://www.youtube.com/watch?v=RW3xIDRoFec,How Startups Can Use NLP to Build a Competitive Moat,Cohere Talks,Video
Cohere makes NLP as simple as an API call. You can basically do any transformation operation on text that requires some form of language understanding. NLU can drive efficiencies within your applications or within your day to day. Third point is savings on infrastructure.,https://www.youtube.com/watch?v=RW3xIDRoFec,How Startups Can Use NLP to Build a Competitive Moat,Cohere Talks,Video
I just wanted to highlight some of the use cases that we see companies really get excited about in the market. The first one is classification and it's as easy as giving a signal on a body of text. Another important use case is search. A generate endpoint is one of the most exciting places.,https://www.youtube.com/watch?v=RW3xIDRoFec,How Startups Can Use NLP to Build a Competitive Moat,Cohere Talks,Video
I wanted to talk a little bit about actually building applications with NLP and what that would look like for the average developer. We see a lot of customers or companies now using multiple NLU or NLP tasks within the same product flow.,https://www.youtube.com/watch?v=RW3xIDRoFec,How Startups Can Use NLP to Build a Competitive Moat,Cohere Talks,Video
Our vision for chatbots is a chatbot that truly understands your meaning and is able to carry the conversation in a way that seems very natural. I'm going to show you an example very soon.,https://www.youtube.com/watch?v=RW3xIDRoFec,How Startups Can Use NLP to Build a Competitive Moat,Cohere Talks,Video
"John wants to get his wife a gift for her birthday. He recommends the dance studio, midrise jocker and yoga tank. John adds all three items to his cart. I hope she loves her new gear.",https://www.youtube.com/watch?v=RW3xIDRoFec,How Startups Can Use NLP to Build a Competitive Moat,Cohere Talks,Video
"We have an agent that's truly conversational, is able to ask the right questions. It's also able to go look up information about specific product and share it with the customer. And that's the power that we will be bringing to customer support experiences and chat experiences going forward.",https://www.youtube.com/watch?v=RW3xIDRoFec,How Startups Can Use NLP to Build a Competitive Moat,Cohere Talks,Video
"Coke Here offers free trial keys for you to get started with NLP. You can access the documentation or go to the playground. There, you can take a look at the models within your organization. So super easy to navigate.",https://www.youtube.com/watch?v=RW3xIDRoFec,How Startups Can Use NLP to Build a Competitive Moat,Cohere Talks,Video
"We have three main models that we make available through the playground. First one is Generate, which really is where you can embed or think of it like uploading a bunch of different texts. The last one is Classify, which is more of like a specific endpoint that does classification. I encourage you to sign up and give this a try on your own.",https://www.youtube.com/watch?v=RW3xIDRoFec,How Startups Can Use NLP to Build a Competitive Moat,Cohere Talks,Video
"The Generate model works is that you tell it what you want to do and then if you want the best results, you need to give it a few examples. You can use it for multiple types of NLP tasks and we're here to support you.",https://www.youtube.com/watch?v=RW3xIDRoFec,How Startups Can Use NLP to Build a Competitive Moat,Cohere Talks,Video
"How do I sign up for Cohere? It's really as simple as signing up on our website. If someone else at your company already signed up, you might need to contact them. Feel free to reach out to me or anyone else.",https://www.youtube.com/watch?v=RW3xIDRoFec,How Startups Can Use NLP to Build a Competitive Moat,Cohere Talks,Video
"The choice of the model depends on your task. There's a whole team here on the partnership side and on the sales side, helping companies get started. If you don't have a machine learning team, how can we use Cohere?",https://www.youtube.com/watch?v=RW3xIDRoFec,How Startups Can Use NLP to Build a Competitive Moat,Cohere Talks,Video
"Large language models are going to transform the way we interact with technology in general. I think we're going to see it applied in every industry, from education to financial services to retail ecommerce. The businesses that will survive in the long run are those that are able to make that leap.",https://www.youtube.com/watch?v=RW3xIDRoFec,How Startups Can Use NLP to Build a Competitive Moat,Cohere Talks,Video
The topic of my talk is on modular and compositional transfer learning. I will look into modularity and compositionality. I'll then look into a cross lingual transfer scenario which is an application of the out of distribution generalization capabilities of these modular adapters. Finally look into how we can mitigate catastrophic interference during pretraining with these modular components.,https://www.youtube.com/watch?v=3ycETDjVzOQ&list=PLLalUvky4CLILc8l3rG5USOal2vPBqyAB&index=4,Modular and Composable Transfer Learning with Jonas Pfeiffer,Technical Talks,Video
"The first question is whether or not adapters are actually modular. The question is if we can train these adapters on multiple different tasks and then compose them to perform better in other scenarios. We can see that for high resource languages such as in multianli, the same adapter is always used. But for low resource tasks, we can combine multiple adapters.",https://www.youtube.com/watch?v=3ycETDjVzOQ&list=PLLalUvky4CLILc8l3rG5USOal2vPBqyAB&index=5,Modular and Composable Transfer Learning with Jonas Pfeiffer,Technical Talks,Video
adapters seem to take much longer to train hundreds of epochs as compared to full fine tuning five epochs. The benefit is especially at the parameter count. A fair comparison between single adapters versus fusion shouldn't consider an equivalent number of parameters.,https://www.youtube.com/watch?v=3ycETDjVzOQ&list=PLLalUvky4CLILc8l3rG5USOal2vPBqyAB&index=6,Modular and Composable Transfer Learning with Jonas Pfeiffer,Technical Talks,Video
"The attention mechanism is different. It turns out that the last layer has a lot of noise in it. In Adaptive Drop, however, we do identify that depending on the task type. We didn't analyze it from an attention mechanism yet.",https://www.youtube.com/watch?v=3ycETDjVzOQ&list=PLLalUvky4CLILc8l3rG5USOal2vPBqyAB&index=7,Modular and Composable Transfer Learning with Jonas Pfeiffer,Technical Talks,Video
"Does the architecture of an adapter have to be in a linear network? Can we use convolutions, for instance? I think that depending on the domain that you're looking at, it makes sense to look at convolutions.",https://www.youtube.com/watch?v=3ycETDjVzOQ&list=PLLalUvky4CLILc8l3rG5USOal2vPBqyAB&index=8,Modular and Composable Transfer Learning with Jonas Pfeiffer,Technical Talks,Video
"Bitfit is very similar to Laura as far as I know, because both are kind of sparse. In general, I think that sparse finetuning is super interesting. Would you consider soft prompts and adapters as the same or different?",https://www.youtube.com/watch?v=3ycETDjVzOQ&list=PLLalUvky4CLILc8l3rG5USOal2vPBqyAB&index=9,Modular and Composable Transfer Learning with Jonas Pfeiffer,Technical Talks,Video
"zero shot transfer to door research languages. Both Embert and Madx fail for unseen scripts. By disentangling the task from the language component, we hope to perform better.",https://www.youtube.com/watch?v=3ycETDjVzOQ&list=PLLalUvky4CLILc8l3rG5USOal2vPBqyAB&index=10,Modular and Composable Transfer Learning with Jonas Pfeiffer,Technical Talks,Video
"Maddox approach allows us to extend a pretrained multilingual model to not only unseen languages, but also unseen scripts. We also see very small gains for seen and unseen languages. We have a data set for crosslingual multimodal visual questionanswering.",https://www.youtube.com/watch?v=3ycETDjVzOQ&list=PLLalUvky4CLILc8l3rG5USOal2vPBqyAB&index=11,Modular and Composable Transfer Learning with Jonas Pfeiffer,Technical Talks,Video
The final part is looking at mitigating catastrophic interference during pretraining. We ask the question whether or not modularization duringpretraining actually mitigates this catastrophic interference between languages. And whether modularization at the start makes it easier for us to add new languages down the line.,https://www.youtube.com/watch?v=3ycETDjVzOQ&list=PLLalUvky4CLILc8l3rG5USOal2vPBqyAB&index=12,Modular and Composable Transfer Learning with Jonas Pfeiffer,Technical Talks,Video
"The question is whether or not it's important to pretrain on a language. By adding a small amount of language specific capacity to the model, we are able to mitigate catastrophic interference between languages. The question is what is the best modular architecture?",https://www.youtube.com/watch?v=3ycETDjVzOQ&list=PLLalUvky4CLILc8l3rG5USOal2vPBqyAB&index=13,Modular and Composable Transfer Learning with Jonas Pfeiffer,Technical Talks,Video
The core goal of our work is really this follows we'd like our models to be reliable. What do we mean by reliability is to have a model that performs well consistently over a large question of decision areas. These are areas where the data is generally quite small.,https://www.youtube.com/watch?v=FS3XqGQMDuk&list=PLLalUvky4CLILc8l3rG5USOal2vPBqyAB&index=7,Plex: Towards Reliability using Pretrained Large Model Extensions,Technical Talks,Video
"So with that, you want to introduce our paper on Plex where we really try to push on this reliability goal that Dustin just discussed using what we call pretrained large model extensions. And then we're going to evaluate them on a suite of data sets for the tasks.",https://www.youtube.com/watch?v=FS3XqGQMDuk&list=PLLalUvky4CLILc8l3rG5USOal2vPBqyAB&index=8,Plex: Towards Reliability using Pretrained Large Model Extensions,Technical Talks,Video
"In the paper we look at kind of two modalities, vision and language. And then Eval is where we really get into this evaluation framework for reliability. This we're going to have a set of data sets that will correspond to the data set that we fine tuned on.",https://www.youtube.com/watch?v=FS3XqGQMDuk&list=PLLalUvky4CLILc8l3rG5USOal2vPBqyAB&index=9,Plex: Towards Reliability using Pretrained Large Model Extensions,Technical Talks,Video
"For vision and text, we're using Transformer base models. For tax, these are T five models, again, large, base and small. And then importantly, we add these model extensions. We'll talk about where exactly we put these.",https://www.youtube.com/watch?v=FS3XqGQMDuk&list=PLLalUvky4CLILc8l3rG5USOal2vPBqyAB&index=10,Plex: Towards Reliability using Pretrained Large Model Extensions,Technical Talks,Video
"So again, bass ensemble. This is trying to get the benefits of a full ensemble it more efficiently. Instead of ensembling on the big weight matrix, we'll ensemble on the smaller vectors. Depending on the architecture, you might see something like only a 2% increase in the parameter count.",https://www.youtube.com/watch?v=FS3XqGQMDuk&list=PLLalUvky4CLILc8l3rG5USOal2vPBqyAB&index=11,Plex: Towards Reliability using Pretrained Large Model Extensions,Technical Talks,Video
"The second extension is this idea of a gaussian process last layer. Replace the last dense layer with, in this case, a header schadastic dense layer. This allows you to get noise estimates that are also a function of the inputs. These are final models.",https://www.youtube.com/watch?v=FS3XqGQMDuk&list=PLLalUvky4CLILc8l3rG5USOal2vPBqyAB&index=12,Plex: Towards Reliability using Pretrained Large Model Extensions,Technical Talks,Video
"In general, using uncertainty methods on top of the large preaching models, we essentially see a very roundabout performance across all different kind of tasks. The architecture does have an impact on model performance. In comparison, the Plaques model is just working rather well out of the box.",https://www.youtube.com/watch?v=FS3XqGQMDuk&list=PLLalUvky4CLILc8l3rG5USOal2vPBqyAB&index=13,Plex: Towards Reliability using Pretrained Large Model Extensions,Technical Talks,Video
"Plex model has a significant up to 10% boost in selective prediction, especially when the review fraction is small. As if the model handed these predictions to human expert and asked them to give correct prediction.",https://www.youtube.com/watch?v=FS3XqGQMDuk&list=PLLalUvky4CLILc8l3rG5USOal2vPBqyAB&index=14,Plex: Towards Reliability using Pretrained Large Model Extensions,Technical Talks,Video
"Next slide please. Here is another task that we are able to unlock with the plugs model. This is structured open set recognition which is coming from the nano task. Given a user query we can predict not only the specific intent the user is asking for, we can also predict the domain and the vertical.",https://www.youtube.com/watch?v=FS3XqGQMDuk&list=PLLalUvky4CLILc8l3rG5USOal2vPBqyAB&index=15,Plex: Towards Reliability using Pretrained Large Model Extensions,Technical Talks,Video
Plex model is a zero shot open site recognition. For very challenging other prediction examples the model can still perform rather robustly. We also see a significant improvement in the active learning using uncertainty from the plaques model versus baseline. Up to 40% in the low sample regimes.,https://www.youtube.com/watch?v=FS3XqGQMDuk&list=PLLalUvky4CLILc8l3rG5USOal2vPBqyAB&index=16,Plex: Towards Reliability using Pretrained Large Model Extensions,Technical Talks,Video
The general reliability performance of the model actually scales almost linearly with respect to model size. And we observe a strong correlation between the pretraining performance in terms of the validation negative lock likelihood and the model's general performance in the downstream fine tuning tasks.,https://www.youtube.com/watch?v=FS3XqGQMDuk&list=PLLalUvky4CLILc8l3rG5USOal2vPBqyAB&index=17,Plex: Towards Reliability using Pretrained Large Model Extensions,Technical Talks,Video
"We also open source pretty much all of our code. That includes trading email, all the config, the checkpoints and there's a bunch of different individual layer foundations. For people in the audience, if you want to ask a question, go to the Q amp A.",https://www.youtube.com/watch?v=FS3XqGQMDuk&list=PLLalUvky4CLILc8l3rG5USOal2vPBqyAB&index=18,Plex: Towards Reliability using Pretrained Large Model Extensions,Technical Talks,Video
"The thing that we most experimented with was exactly how to do efficient ensemble. Also not only for parameter efficiency and memory, but also interest time. One of the key difficulties is that if you're trying to ensemble both for pretraining and finetuning.",https://www.youtube.com/watch?v=FS3XqGQMDuk&list=PLLalUvky4CLILc8l3rG5USOal2vPBqyAB&index=19,Plex: Towards Reliability using Pretrained Large Model Extensions,Technical Talks,Video
"Non large is doing pretty well compared to flex space. Performance is polarized in a sense that in some situation works really well. If the non is doing well only prediction wise, it can still have a higher ranking in some subset of tasks.",https://www.youtube.com/watch?v=FS3XqGQMDuk&list=PLLalUvky4CLILc8l3rG5USOal2vPBqyAB&index=20,Plex: Towards Reliability using Pretrained Large Model Extensions,Technical Talks,Video
Do you have advice on when the GP layer or headers get that layer work better to improve uncertainty estimates. Can you please explain a bit more about header in the context of text or nope.,https://www.youtube.com/watch?v=FS3XqGQMDuk&list=PLLalUvky4CLILc8l3rG5USOal2vPBqyAB&index=21,Plex: Towards Reliability using Pretrained Large Model Extensions,Technical Talks,Video
What is the process for coming up with your characterization of reliability look like? Most of the metrics that we were thinking about are like decision making scenarios that involve a lot of these qualities implicitly or explicitly. A lot of it is about talking to folks to see what they actually use in practice.,https://www.youtube.com/watch?v=FS3XqGQMDuk&list=PLLalUvky4CLILc8l3rG5USOal2vPBqyAB&index=22,Plex: Towards Reliability using Pretrained Large Model Extensions,Technical Talks,Video
"Plex has developed a new way to scale up transformer architectures. The method works well across different data sets and different types of models. But within the scope of this paper, the research was limited to Transformers.",https://www.youtube.com/watch?v=FS3XqGQMDuk&list=PLLalUvky4CLILc8l3rG5USOal2vPBqyAB&index=23,Plex: Towards Reliability using Pretrained Large Model Extensions,Technical Talks,Video
Autos from Google and University of Oxford collaborated on the project. They found being able to center a group around one large nice code base helpful. There are so many different challenges in organizing a large effort. Do you have any tips for coordinating collaboration of this kind of size?,https://www.youtube.com/watch?v=FS3XqGQMDuk&list=PLLalUvky4CLILc8l3rG5USOal2vPBqyAB&index=24,Plex: Towards Reliability using Pretrained Large Model Extensions,Technical Talks,Video
"The next question is from Charles again. What do you think is the main reason for accuracy improvements when not referring to an expert? These extensions should lead to better uncertainty estimates. Why do they improve results when the model has selected a class, even if it's very uncertain?",https://www.youtube.com/watch?v=FS3XqGQMDuk&list=PLLalUvky4CLILc8l3rG5USOal2vPBqyAB&index=25,Plex: Towards Reliability using Pretrained Large Model Extensions,Technical Talks,Video
"The thing that I'm most excited about is trying to simulate a lot of these ideas just more into bigger protections, bigger models where there's maybe more emergent capabilities. How do I leverage that in the overarching, like, self driving car system or just sort of a traffic speed system?",https://www.youtube.com/watch?v=FS3XqGQMDuk&list=PLLalUvky4CLILc8l3rG5USOal2vPBqyAB&index=26,Plex: Towards Reliability using Pretrained Large Model Extensions,Technical Talks,Video
Aidan Gomez is a computer scientist and widely recognized AI expert. He co founded AI company Cohere which uses artificial intelligence to help users build the next generation of language based applications. Coheres say their competitive advantage lies in its focus on safety.,https://www.youtube.com/watch?v=ooBt_di8DLs&list=PLLalUvky4CLIclqP_X4va9PMdVoFtjhtb&index=2,#80 AIDAN GOMEZ [CEO Cohere] - Language as Software,Cohere Talks,Video
"When Transformers came out in 2017, it changed the landscape of deep learning forever. It took me a very long time to understand it, and I probably only did understand it after reading Jay's famous blog post, the Illustrator Transformer. A huge piece of the project came together within twelve weeks.",https://www.youtube.com/watch?v=ooBt_di8DLs&list=PLLalUvky4CLIclqP_X4va9PMdVoFtjhtb&index=3,#80 AIDAN GOMEZ [CEO Cohere] - Language as Software,Cohere Talks,Video
DeepMind recently released a paper called Neural Networks and the Chomsky Hierarchy. It showed that Transformers were only able to represent finite languages. How do you think about the practical limitations of Transformers in terms of what algorithms they can learn?,https://www.youtube.com/watch?v=ooBt_di8DLs&list=PLLalUvky4CLIclqP_X4va9PMdVoFtjhtb&index=4,#80 AIDAN GOMEZ [CEO Cohere] - Language as Software,Cohere Talks,Video
The mission with Cohere is to really just give technology language. The goal is to put these large language models into more hands. Two of the reasons are there's a huge compute barrier and only a tiny fraction of developers know how to use them.,https://www.youtube.com/watch?v=ooBt_di8DLs&list=PLLalUvky4CLIclqP_X4va9PMdVoFtjhtb&index=5,#80 AIDAN GOMEZ [CEO Cohere] - Language as Software,Cohere Talks,Video
"GPT-3 founder talks about friction using large language models as a startup owner. Most exciting applications are the open ended applications, he says. Do you think that would ever be allowed on Cohere?",https://www.youtube.com/watch?v=ooBt_di8DLs&list=PLLalUvky4CLIclqP_X4va9PMdVoFtjhtb&index=6,#80 AIDAN GOMEZ [CEO Cohere] - Language as Software,Cohere Talks,Video
"How would you distinguish your service from GPT-3? We're trying to tailor our roadmap towards the needs of users. We don't call them instruct models, we call them command models because of the co and coher. We do have something currently in private beta, hopefully we'll release it soon.",https://www.youtube.com/watch?v=ooBt_di8DLs&list=PLLalUvky4CLIclqP_X4va9PMdVoFtjhtb&index=7,#80 AIDAN GOMEZ [CEO Cohere] - Language as Software,Cohere Talks,Video
"How many concurrent requests can your customers have? Token? As many as you'd like, even now. Do you support, let's say, enterprise security scenarios? Like single sign on key rotation, that kind of thing?",https://www.youtube.com/watch?v=ooBt_di8DLs&list=PLLalUvky4CLIclqP_X4va9PMdVoFtjhtb&index=8,#80 AIDAN GOMEZ [CEO Cohere] - Language as Software,Cohere Talks,Video
The first sort of application that has hit product market fit is Copywriting. I'm really excited about the prospect of stacking calls to these large language models. Next generation of application platforms will be doing something like that.,https://www.youtube.com/watch?v=ooBt_di8DLs&list=PLLalUvky4CLIclqP_X4va9PMdVoFtjhtb&index=9,#80 AIDAN GOMEZ [CEO Cohere] - Language as Software,Cohere Talks,Video
"Large language models are a much more natural modality to the corpus of human knowledge, much more intuitive, natural, seamless. I kind of view a raw large language model trained on the web as the next iteration of a search engine. I think search engines are about to be revolutionized.",https://www.youtube.com/watch?v=ooBt_di8DLs&list=PLLalUvky4CLIclqP_X4va9PMdVoFtjhtb&index=10,#80 AIDAN GOMEZ [CEO Cohere] - Language as Software,Cohere Talks,Video
"Next frontier of large language models is integration of information retrieval. My dream for Cohere is that it knows its users. We need to be able to maintain a state between the model and its user. And then lastly, augmenting big language models with the ability to use tools.",https://www.youtube.com/watch?v=ooBt_di8DLs&list=PLLalUvky4CLIclqP_X4va9PMdVoFtjhtb&index=11,#80 AIDAN GOMEZ [CEO Cohere] - Language as Software,Cohere Talks,Video
Large language models have learned this very intricate statistical correlation which allows near perfect performance in lieu of human cognition. It's possible that evaluating these algorithms against standards designed to gauge human cognition might be barking up the wrong tree. There needs to be something more.,https://www.youtube.com/watch?v=ooBt_di8DLs&list=PLLalUvky4CLIclqP_X4va9PMdVoFtjhtb&index=12,#80 AIDAN GOMEZ [CEO Cohere] - Language as Software,Cohere Talks,Video
"The real value of AI models exists as a kind of entangled form of interactive, creative pairing between a human brain and a model. I think the next step is to continue to outsource things that we don't like doing things that are taxing.",https://www.youtube.com/watch?v=ooBt_di8DLs&list=PLLalUvky4CLIclqP_X4va9PMdVoFtjhtb&index=13,#80 AIDAN GOMEZ [CEO Cohere] - Language as Software,Cohere Talks,Video
"The worry is that we might feel we need to reinvent code because the prompts might become so complex that you need the equivalent of lawyers to understand them. Cohere's whole point is to make things as simple to use as possible. The arrow of progress in this field points towards more abstraction, easier to use, more intuitive interfaces.",https://www.youtube.com/watch?v=ooBt_di8DLs&list=PLLalUvky4CLIclqP_X4va9PMdVoFtjhtb&index=14,#80 AIDAN GOMEZ [CEO Cohere] - Language as Software,Cohere Talks,Video
" Adrian will be sharing his Date idea generator app, which He has built using Cohere, Generate and stream it. Let me know if You have any questions during the session in the chat section or wait until the end so that we can chat directly with Adrian.",https://www.youtube.com/watch?v=bBU46HLMf_U,Building Cohere API Demo App With Streamlit | Adrien Morisot,Building Apps,Video
"Coher: This is the culmination of a few different projects. The first one is semantic search. It enables you to search by meaning, not just comparing words. If you have a large number of embeddings, you can plot them. This kind of visualization gets a lot of information out of vast amounts of text.",https://www.youtube.com/watch?v=23qfPq0m7XA&list=PLLalUvky4CLLoILHO7-73454287kJGMj6&index=2,Exploring News Headlines With Text Clustering | Jay Alammar,Building Apps,Video
"Bala: I've been working on a new prompt that to generate a title, not just using the keywords, but also looking at a number of articles from the cluster. Also an interactive demo that you can use on this data set or other data sets. Do you have any questions?",https://www.youtube.com/watch?v=23qfPq0m7XA&list=PLLalUvky4CLLoILHO7-73454287kJGMj6&index=3,Exploring News Headlines With Text Clustering | Jay Alammar,Building Apps,Video
I just want to talk about my approach to topic modeling. What I'm trying to do is extracting the major themes from one document. The second step is how can we do this with the generative model. We're experimenting with giving it ten articles or ten titles.,https://www.youtube.com/watch?v=23qfPq0m7XA&list=PLLalUvky4CLLoILHO7-73454287kJGMj6&index=4,Exploring News Headlines With Text Clustering | Jay Alammar,Building Apps,Video
"How does one come up with an idea of building a hacker news map? Like, what led you there? I'm always curious about the process of arriving at this Use case for large language models.",https://www.youtube.com/watch?v=23qfPq0m7XA&list=PLLalUvky4CLLoILHO7-73454287kJGMj6&index=5,Exploring News Headlines With Text Clustering | Jay Alammar,Building Apps,Video
Would it make sense to get the embedding of each article that I see throughout the session? Or is there a way to kind of memorize or frame using the embeddings that's already there. I'm just wondering about the scalability.,https://www.youtube.com/watch?v=23qfPq0m7XA&list=PLLalUvky4CLLoILHO7-73454287kJGMj6&index=6,Exploring News Headlines With Text Clustering | Jay Alammar,Building Apps,Video
"Thanks. Jeremy, do you want to follow up on this or did the rest of the presentation answer it? I was just curious if there was a way to share the intuition about how many clusters were the most effective. There are three approaches.",https://www.youtube.com/watch?v=23qfPq0m7XA&list=PLLalUvky4CLLoILHO7-73454287kJGMj6&index=7,Exploring News Headlines With Text Clustering | Jay Alammar,Building Apps,Video
"Pinecon: Could there be other potential use cases to build something with the Embed? They're general problem solving tools for retrieval and search. If you haven't yet spoke Code Search, you can find it under the Top Project Showcase.",https://www.youtube.com/watch?v=23qfPq0m7XA&list=PLLalUvky4CLLoILHO7-73454287kJGMj6&index=8,Exploring News Headlines With Text Clustering | Jay Alammar,Building Apps,Video
"Jay: If we don't have any more questions, we can wrap up here. Thank you, everybody, for coming. If you have any questions, feel free to. Post them in any other channels here. Have a great day.",https://www.youtube.com/watch?v=23qfPq0m7XA&list=PLLalUvky4CLLoILHO7-73454287kJGMj6&index=9,Exploring News Headlines With Text Clustering | Jay Alammar,Building Apps,Video
"Bertopic is an awesome Python library for analyzing large groups or collections of text. In the first episode of Talking a Language AI, the creator of Bertopic, Martin Holtendorst, will give an overview about Bertopic and tips for new users and advanced users alike.",https://www.youtube.com/watch?v=uZxQz87lb84,BERTopic for Topic Modeling - Talking Language AI Ep#1,Building Apps,Video
topic modeling aims to be highly flexible and customizable. What it essentially is doing is extracting topics from documents. The way your topic is approaching that topic modeling task is by reducing it to a clustering task.,https://www.youtube.com/watch?v=uZxQz87lb85,BERTopic for Topic Modeling - Talking Language AI Ep#2,Building Apps,Video
"The topic modeling on this abstract, for example, is about reinforcement learning. We can view the topics that we have created. And there are a bunch of more things that we can do with a topic pole. It gives you a little bit more understanding of what is happening here.",https://www.youtube.com/watch?v=uZxQz87lb86,BERTopic for Topic Modeling - Talking Language AI Ep#3,Building Apps,Video
"With topic molding, it's a subjective approach, there's no ground truth. There should be some visualizations in there so that you can either understand the model or explain what is happening. And for that you need visualizations experimentation, things like that.",https://www.youtube.com/watch?v=uZxQz87lb87,BERTopic for Topic Modeling - Talking Language AI Ep#4,Building Apps,Video
"Keyword is super simple, really basic as a default. Polyphos was developed as more or as a focus on modularity. There are a lot of different ways you can do fuzzy string matching. Why isn't there one package that can do all of that?",https://www.youtube.com/watch?v=uZxQz87lb88,BERTopic for Topic Modeling - Talking Language AI Ep#5,Building Apps,Video
"There are questions about just comparisons with LDA and Top to VEC. How different is the end result of these three topic models? Because we want to compare topic modeling techniques, we again need to resort in a way to evaluation.",https://www.youtube.com/watch?v=uZxQz87lb89,BERTopic for Topic Modeling - Talking Language AI Ep#6,Building Apps,Video
"Per Topic now supports online topic modeling, where you can continuously fine tune your topic model based on topics that come in today. What we mostly see indeed, with topic modeling is for detecting trends. For those use cases it has become a little bit more interesting.",https://www.youtube.com/watch?v=uZxQz87lb90,BERTopic for Topic Modeling - Talking Language AI Ep#7,Building Apps,Video
"I'm really interested in this area of using GPT models in the flow. It already can take quite a while to generate those embeddings. At the moment there comes a lightweight, easy to use, GPT based approach. I'll be the first to want to implement it in the topic.",https://www.youtube.com/watch?v=uZxQz87lb91,BERTopic for Topic Modeling - Talking Language AI Ep#8,Building Apps,Video
Today I'm going to talk about a bunch of tools that all have this theme of data quality. I want to start by sharing my favorite screenshot of a video game in the last year. There are moments when data quality issues arise and it's not this funny.,https://www.youtube.com/watch?v=KRQJDLyc1uM,Tools to Improve Training Data - Talking Language AI Ep#2,Building Apps,Video
Human Learn is a tool that tries to rethink the way that we model. It's just a bunch of psyched learn components that you can just click in your pipeline. The most powerful thing in there is this idea that you don't always need data in order to make a sensible prediction.,https://www.youtube.com/watch?v=KRQJDLyc1uM,Tools to Improve Training Data - Talking Language AI Ep#3,Building Apps,Video
The credit card data set is well known for being an imbalanced classification problem. There are way more non fraudulent transactions than fraudulent transactions. Here is a visual trick to tackle this problem.,https://www.youtube.com/watch?v=KRQJDLyc1uM,Tools to Improve Training Data - Talking Language AI Ep#4,Building Apps,Video
"High plot is more meant for grid search analysis than what I'm doing here. If you want to implement this in a psychedlearn pipeline, it'd be nice if you could just implement it in a function. The real use case for this isn't to do machine learning, it's to do gridsearch analysis.",https://www.youtube.com/watch?v=KRQJDLyc1uM,Tools to Improve Training Data - Talking Language AI Ep#5,Building Apps,Video
"Dion: If you are curious about this, this is what calm code is for. Courses on calm code. Everything's free. Deon is an amazing project that generates sensible checklists of stuff you should do before even considering production. Check that out if you haven't already.",https://www.youtube.com/watch?v=KRQJDLyc1uM,Tools to Improve Training Data - Talking Language AI Ep#6,Building Apps,Video
A couple of questions on using human learning for regression tasks or the visualization for embedding. Those are all tools that are inside of human learn. The visualization stuff isn't a bit more on the experimental side.,https://www.youtube.com/watch?v=KRQJDLyc1uM,Tools to Improve Training Data - Talking Language AI Ep#7,Building Apps,Video
"Even if you have a great model, your metrics can still be off because your data is off. Doubt Lab is a suite of tools that allows you to doubt your data just a bit more. It can also help you prioritize which examples to check first.",https://www.youtube.com/watch?v=KRQJDLyc1uM,Tools to Improve Training Data - Talking Language AI Ep#8,Building Apps,Video
"The call for contributions is for data sets that are classification labeled data sets. I am very much in the market for more examples. You can also just supply me with a notebook with an interesting research result. If that sounds like an easier contribution, reach out to me on GitHub.",https://www.youtube.com/watch?v=KRQJDLyc1uM,Tools to Improve Training Data - Talking Language AI Ep#9,Building Apps,Video
"embeddings exist for all sorts of things these days. Embetter turns a lot of them into cyclone components. It just gives you these Lego bricks for these embeddeddings. I don't do audio just yet, but text and images are definitely supported.",https://www.youtube.com/watch?v=KRQJDLyc1uM,Tools to Improve Training Data - Talking Language AI Ep#10,Building Apps,Video
"These are all sentence encoders. They can grab a column from a panace data frame and then encode it. Note that when you install this tool, you probably do want to pip install embedde. And also note that you don't have to think about tokenization at all.",https://www.youtube.com/watch?v=KRQJDLyc1uM,Tools to Improve Training Data - Talking Language AI Ep#11,Building Apps,Video
"There's one feature that I haven't done yet, and that's the GPU support. I do acknowledge that some of these tools, especially if using Google collab they can get heavy. Adding GPU support will be nice. It's in the back of my mind on the roadmap.",https://www.youtube.com/watch?v=KRQJDLyc1uM,Tools to Improve Training Data - Talking Language AI Ep#12,Building Apps,Video
"In a machine learning pipeline, you want to get from unlabeled data set to some sort of a trained model. And some trick is very easy if you have embeddings around. Also, in terms of label quality, it can mean to be able to make a UI step.",https://www.youtube.com/watch?v=KRQJDLyc1uM,Tools to Improve Training Data - Talking Language AI Ep#13,Building Apps,Video
"Bulk is a command line tool. You can type Bulk text and then a CSV file. If it has a text column, an X column and a Y column, it is able to generate a two dimensional chart. I like to see this tool as a topic discovery kind of thing.",https://www.youtube.com/watch?v=KRQJDLyc1uM,Tools to Improve Training Data - Talking Language AI Ep#14,Building Apps,Video
Lasso is a way to generate a lot of data very quickly visually and sort of interactively. The more appropriate way of going about that then is to just annotate the data yourself. Why doesn't this work in a notebook?,https://www.youtube.com/watch?v=KRQJDLyc1uM,Tools to Improve Training Data - Talking Language AI Ep#15,Building Apps,Video
Vincent: I want to get rid of this notion that labeling is boring. I'm also working on active learning stuff and there will be two new libraries that I hopefully get to work on in December. What's next for him? Vincent: I'm definitely interested in data quality stuff some more.,https://www.youtube.com/watch?v=KRQJDLyc1uM,Tools to Improve Training Data - Talking Language AI Ep#16,Building Apps,Video
The Psychic Learn API clip is automatically supported because you're building on tools that have APIs that can work together. The main downside with Psychic Learn is when you have two components after each other. But the benefit is it just keeps things simple.,https://www.youtube.com/watch?v=KRQJDLyc1uM,Tools to Improve Training Data - Talking Language AI Ep#17,Building Apps,Video
"The superglue benchmark is a language understanding challenge. In specific sort of narrow tasks, some of these models are exceeding human performance. This just gives you a sense of how quickly machine understanding of language and generation of language is accelerating.",https://www.youtube.com/watch?v=e2g5ya4ZFro,Supercharging Semantic Search with Pinecone and Cohere,Building Apps,Video
"To talk about semantic search, we have to talk about embeddings. Embeddings are basically representations, numeric representations of text that capture its meaning. Nlptech is developing quickly. Search is one of the most fascinating areas.",https://www.youtube.com/watch?v=e2g5ya4ZFro,Supercharging Semantic Search with Pinecone and Cohere,Building Apps,Video
"With a few added features such as metadata filtering and efficient search at scale, we can start building really interesting and really powerful tools using semanticsearch. Coherence was founded by ex Google brain researchers. Today there are three endpoints that are that are served on the Omni platform.",https://www.youtube.com/watch?v=e2g5ya4ZFro,Supercharging Semantic Search with Pinecone and Cohere,Building Apps,Video
"A quick demo demonstrates the coherent embedding endpoint alongside pumpkin. With Cohere, it makes it incredibly easy to make these embeddings. And we're going to also have a look at how we can use those to perform filtering as well.",https://www.youtube.com/watch?v=e2g5ya4ZFro,Supercharging Semantic Search with Pinecone and Cohere,Building Apps,Video
"There's so much potential in problem solving using these primitives that I think is very exciting. The best demos will come from developers like you. And every day now, we see interesting demos that all of language models can do.",https://www.youtube.com/watch?v=e2g5ya4ZFro,Supercharging Semantic Search with Pinecone and Cohere,Building Apps,Video
semantic search should not be confined only to these search box. There are other use cases where semantic search can be triggered by something else. This translates into a question classification using a fine tuned model.,https://www.youtube.com/watch?v=e2g5ya4ZFro,Supercharging Semantic Search with Pinecone and Cohere,Building Apps,Video
Coherent coher AI uses Pine cone to search for other similar things that we have already embedded and then returns that to us. Can be really quite useful and flexible. We have a larger or a longer guide for how to use the coherent Endpoint generation inside of a Slack app.,https://www.youtube.com/watch?v=e2g5ya4ZFro,Supercharging Semantic Search with Pinecone and Cohere,Building Apps,Video
"Does the clustering depend on the type of embedding model? So since Bert, we have several developments of ways to generate better and better sentence or text embedding baseline models. Fine tuning is the next step that will lead to better results.",https://www.youtube.com/watch?v=e2g5ya4ZFro,Supercharging Semantic Search with Pinecone and Cohere,Building Apps,Video
The next question is on vector databases. Are you referring to the vector database as the way to sort the embeddings of the corpus and not compute every time on the corpus?,https://www.youtube.com/watch?v=e2g5ya4ZFro,Supercharging Semantic Search with Pinecone and Cohere,Building Apps,Video
Next question is also on approximate search. How do you determine the distance? Is it fixed and can you change it in your search query? What happens when the input to the Embedding model includes not just text but also tables and images?,https://www.youtube.com/watch?v=e2g5ya4ZFro,Supercharging Semantic Search with Pinecone and Cohere,Building Apps,Video
The definition of semantic similarity can be vague. The main approach here would be to fine tune the model on your particular data. Fine tuning usually for the end case that you want or for a specific use case is needed to get these models to do what you want.,https://www.youtube.com/watch?v=e2g5ya4ZFro,Supercharging Semantic Search with Pinecone and Cohere,Building Apps,Video
"Do the sequence of the words in a sentence really matter? There are different ways to tackle a use case like this. Here is focused on English for now. If you want to do more languages, let us know.",https://www.youtube.com/watch?v=e2g5ya4ZFro,Supercharging Semantic Search with Pinecone and Cohere,Building Apps,Video
"Pine Cone first and foremost is vector search. We have a few features like the single stage filtering, the very fast index update, and the scalability. I don't think Elasticsearch is quite there yet, but of course it really depends on what you're trying to do.",https://www.youtube.com/watch?v=e2g5ya4ZFro,Supercharging Semantic Search with Pinecone and Cohere,Building Apps,Video
Am I overkilling the problem by using textualized models? You get the best results with text that are shorter than 512 tokens. What is the search sentence max size?,https://www.youtube.com/watch?v=e2g5ya4ZFro,Supercharging Semantic Search with Pinecone and Cohere,Building Apps,Video
Large generative models can work on few shots without training. What would be the best way to fine tune the parameters of the index? And then the one for me was what are your thoughts on using a larger model like T five XL instead of Bert.,https://www.youtube.com/watch?v=e2g5ya4ZFro,Supercharging Semantic Search with Pinecone and Cohere,Building Apps,Video
"Do the fine tuning process actually modify the embeddings as well? Do you have any comparisons between a 768 Bert like dimensional embedding versus Coheres 4000 Embeddings for a billion scale data set? If either of you have a couple more minutes to answer more questions, that's great.",https://www.youtube.com/watch?v=e2g5ya4ZFro,Supercharging Semantic Search with Pinecone and Cohere,Building Apps,Video
"To build a custom language model for your project or your product. These are tools that can ultimately help you unlock new product or feature capabilities, cut costs, and ultimately be more customer centric. Scott will walk through how to kick off a project in the search platform to get a high quality data set.",https://www.youtube.com/watch?v=btMK-tMh4Mk,Create a Custom Language Model with Surge AI and Cohere,Building Apps,Video
"Join us as we teach you a bit about fine tuning language models for any use case. Like Ellie mentioned, we encourage you to ask questions along the way. And we'll try to get to as many of them as we can at the end of the session.",https://www.youtube.com/watch?v=btMK-tMh4Mk,Create a Custom Language Model with Surge AI and Cohere,Building Apps,Video
Surge AI builds custom high quality data sets for folks like you so that you can ship better models faster. The quality of your training data is a huge factor in determining how well your model works in the real world. Here's a hands on demonstration of building a custom training data set on the Surge platform.,https://www.youtube.com/watch?v=btMK-tMh4Mk,Create a Custom Language Model with Surge AI and Cohere,Building Apps,Video
"We want to build a toxicity classifier for Twitter. We want this model to look at tweets and determine if they are either toxic or not toxic. If we can build a model that can do this accurately, we can drastically speed up content, moderation decisions and workflow.",https://www.youtube.com/watch?v=btMK-tMh4Mk,Create a Custom Language Model with Surge AI and Cohere,Building Apps,Video
"The data set is diverse, it's large enough, and it's ready to start the next phase of the fine tuning process. Now, who's going to walk through the rest of this process of taking the data set using the coherent platform to actually fine tune their base model on this?",https://www.youtube.com/watch?v=btMK-tMh4Mk,Create a Custom Language Model with Surge AI and Cohere,Building Apps,Video
"Ellie: Custom language models are really helpful tools for moving the needle on performance for tasks that are incredibly niche. For example, with the toxicity classification task that we have today, there isn't one standard definition for what defines toxic content. We can test the model in real time in the playground with some examples.",https://www.youtube.com/watch?v=btMK-tMh4Mk,Create a Custom Language Model with Surge AI and Cohere,Building Apps,Video
We want to fine tune a generative AI model. What our model is going to take as an input is a subject or a keyword for an essay and then a tone of voice. It's going to output a paragraph or a couple of paragraphs of text based on the combination. This has tons of use cases for speeding up business workflows or creating interesting fiction content.,https://www.youtube.com/watch?v=btMK-tMh4Mk,Create a Custom Language Model with Surge AI and Cohere,Building Apps,Video
"We'll go through the same workflow we did the first time around, but this time we'll specify a generative task. Once that model has finished training in the Coher platform, you'll receive a specific model ID. You can then plug this into your specific project or application. If folks have any questions, feel free to unmute yourselves.",https://www.youtube.com/watch?v=btMK-tMh4Mk,Create a Custom Language Model with Surge AI and Cohere,Building Apps,Video
"When fine tuning a model, make sure that you have the right prompt and the right sampling parameters. Temperature is the degree of randomness or degree of creativity of the model. I would recommend that folks check out the playground environment and cohere it makes it really easy to experiment.",https://www.youtube.com/watch?v=btMK-tMh4Mk,Create a Custom Language Model with Surge AI and Cohere,Building Apps,Video
"Awesome. One and a half questions and then I'll pass it back to you, Ellie. First, someone's asking how you can become a data labeler for surge. You can reach out to us. Our email is on the data set you'll get after this webinar.",https://www.youtube.com/watch?v=btMK-tMh4Mk,Create a Custom Language Model with Surge AI and Cohere,Building Apps,Video
"Here is how much training data should you have for a fine tune. Sometimes even ten to 100 examples can be a really great starting place. As you increase the size of your training data set, your model just become better and better around the edge cases and nuances.",https://www.youtube.com/watch?v=btMK-tMh4Mk,Create a Custom Language Model with Surge AI and Cohere,Building Apps,Video
"If you're building a conversational AI tool, I'm wondering how you might do a fine tuning. How would you be able to recognize the context and remember earlier parts of conversation. Scott, do you have any recommendations about how to kick off a data labeling job with Surge?",https://www.youtube.com/watch?v=btMK-tMh4Mk,Create a Custom Language Model with Surge AI and Cohere,Building Apps,Video
"The pricing is usually like, bespoke on a project basis. Creating a fine tuned custom model is entirely free. We also have a free developer tier. If you're not serving these model outputs in a production environment, you don't need to pay.",https://www.youtube.com/watch?v=btMK-tMh4Mk,Create a Custom Language Model with Surge AI and Cohere,Building Apps,Video
Anything you want to accomplish is possible with fine tuning large language models. You can fine tune it for that very specific use case. Fine tuning is a really great way to make the customers feel like more comfortable with your product on your platform.,https://www.youtube.com/watch?v=btMK-tMh4Mk,Create a Custom Language Model with Surge AI and Cohere,Building Apps,Video
All search has a bunch of free data sets that you are welcome to use in any way you see fit. You can also leverage the platform to improve the quality of a data set that you come across online. That could be a great starting point for fine tuning a coherent model.,https://www.youtube.com/watch?v=btMK-tMh4Mk,Create a Custom Language Model with Surge AI and Cohere,Building Apps,Video
I do see a question about leveraging different types of models in a singular application. That's definitely something that the Cohere API supports. So you could run a classification task with our classify Endpoint. Then you could trigger a call to our generate endpoint to accomplish some other type of task.,https://www.youtube.com/watch?v=btMK-tMh4Mk,Create a Custom Language Model with Surge AI and Cohere,Building Apps,Video
"HOW TO BUILD A FRONT END FOR A DATA SCIENCE PROJECT IN 1 Today I want to show you how to build a front end for your data science project using this awesome tool that I found called STREAMLET. It just works using Python. To be honest, it's pretty simple to set up.",https://www.youtube.com/watch?v=-IM3531b1XU&list=PLM8lYG2MzHmRpyrk9_j9FW0HiMwD9jSl5&index=1,How to Build a Streamlit App (Beginner level Streamlit tutorial) - Part 1,Building Apps,Video
"STREAMLIT IN PYTHON How do we do containers in streamlining? This is something that was very recently published, actually very recently launched. Containers create sections and columns create sections in a vertical way. The next thing that I want to do is actually bring in my data and visualize it in the next video.",https://www.youtube.com/watch?v=-IM3531b1XU&list=PLM8lYG2MzHmRpyrk9_j9FW0HiMwD9jSl5&index=1,How to Build a Streamlit App (Beginner level Streamlit tutorial) - Part 1,Building Apps,Video
"LOADING THE MACHINE LEARNING MODEL IN PYTHON, Last section is to bring in the machine learning model and display the performance. What I'm going to do here is basically create a random forest regressor. My output feature is set to be trip distance. And the last thing that I want is to show the performance of the model.",https://www.youtube.com/watch?v=CSv2TBA9_2E&list=PLM8lYG2MzHmRpyrk9_j9FW0HiMwD9jSl5&index=3,How to Integrate Machine Learning to Streamlit - Part 3,Building Apps,Video
"STREAMLIT, Last thing I want to show you is Caching and Streamlining. If you don't use Caching, what's going to happen is that every time you change something in this area, every time the user changes his selection, the whole app is going to run again. Caching is a solution for that.",https://www.youtube.com/watch?v=CSv2TBA9_2E&list=PLM8lYG2MzHmRpyrk9_j9FW0HiMwD9jSl5&index=4,How to Integrate Machine Learning to Streamlit - Part 3,Building Apps,Video
"FINALLY, PLOTLY APP, Last thing I want to show you before we go into deployment of this app is some customization. There is not much built in customization when it comes to streamlining apps. In the final video, I will show you how to deploy this app so other people can see it too.",https://www.youtube.com/watch?v=CSv2TBA9_2E&list=PLM8lYG2MzHmRpyrk9_j9FW0HiMwD9jSl5&index=5,How to Integrate Machine Learning to Streamlit - Part 3,Building Apps,Video
"BUILDING A WEB APP FOR YOUR DATA SCIENCE PROJECT WITH STREAM, This is the fourth and the last video on building a web app for your data science project using STREAMLET. There are a couple of steps to deploying Streamlit apps and we're going to go through those steps. The first step is putting our app on GitHub.",https://www.youtube.com/watch?v=B0MUXtmSpiA&list=PLM8lYG2MzHmRpyrk9_j9FW0HiMwD9jSl5&index=4,How to Deploy a Streamlit App - Part 4,Building Apps,Video
"HOW TO START USING STREAMLIT (NO CODING REQUIRED), The streamlit service makes it easy for data scientists to deploy apps. You can share the link to your GitHub repository so that someone can see your work. It's just amazing for especially data scientists or people who want to become data scientists.",https://www.youtube.com/watch?v=B0MUXtmSpiA&list=PLM8lYG2MzHmRpyrk9_j9FW0HiMwD9jSl5&index=4,How to Deploy a Streamlit App - Part 4,Building Apps,Video
"PANDAS, You can use pandas to create plots in your STREAMLET project. This is not the only way you can build a plot. You can also use some other things like plotly to display plots.",https://www.youtube.com/watch?v=QetpwPnEpgA&list=PLM8lYG2MzHmRpyrk9_j9FW0HiMwD9jSl5&index=3,How to Collect User Input with Streamlit - Part 2,Building Apps,Video
"HOW TO MAKE A LIST (MARKDOWN), The next thing that I want to show you is how to make a list. What you can do is to say markdown if you don't know what markdown is. Just basically a way to create rich text. Now you can have a list of your features you can edit as you like.",https://www.youtube.com/watch?v=QetpwPnEpgA&list=PLM8lYG2MzHmRpyrk9_j9FW0HiMwD9jSl5&index=4,How to Collect User Input with Streamlit - Part 2,Building Apps,Video
"PYTHON USER INPUT SECTIONS, We also wanted to use the drop down menu and a text input from the user. Before implementing those, there's one other thing that we have to think about and that's the columns. And it's super, super simple. All you have to say is whatever the user chooses, save it in this variable called next steps",https://www.youtube.com/watch?v=QetpwPnEpgA&list=PLM8lYG2MzHmRpyrk9_j9FW0HiMwD9jSl5&index=5,How to Collect User Input with Streamlit - Part 2,Building Apps,Video
"Our product is a Web based Application which improves the efficiency of chat based support systems by automating repetitive parts of the workflow. This is done by utilising Cohere’s API in order to provide smart shortcuts for the Chat Support Agents. We aim to maximise Customer and Customer Support Agent satisfaction by making the lookup of product and service related answers instantaneous, thereby allowing the Customer Support Agent to put more effort into the interaction with the customer rather than the mundane task of researching answers.",https://github.com/Beenyaa/2022-cohere-hackathon-team-turing,Turing Test,Building Apps,Hackathon Examples
Our application helps Business Analysts and BI application users to interact with MongoDB without actually learning the syntax. It also helps new developers to write queries quickly by using this application to generate boilerplate queries. This application can also be used to generate queries for stress/monkey test an mongoDB application. This can be easily scaled to other noSQL databases with few shot training.,https://github.com/tripun-samsung/cohere-hackathon/blob/main/titans-streamlit-server.py,Generating MongoDb Queries With User Text Input,Building Apps,Hackathon Examples
"On daily bases we use to surf the internet and put lot of bookmarks and after that when we again went it for a bookmark, we trouble a lot there Keeping this in mind we created a AI application, so it can manage all the bookmarks and put in separately in the different tags. In this way it becomes super easy for the user to quickly jump on the what he/she wants to see Every user who surfs the internet on daily bases can use it very easily ThankYou",https://github.com/krrish-v/bookmark-collector,bookmark-manager,Building Apps,Hackathon Examples
"Imagine Art is an inspiration hub for all aspiring & existing artists. Using Co:Here's API playground, Imagine Art can generate a set of images that gives artists a starting point to their blank canvas. Type simple or complex English sentences, and Imagine Art will use AI to provide you similar prompts, which you can then select and land on the final set of pictures",https://github.com/amaanirfan19/Cohere-Hackthon,Imagine Art,Building Apps,Hackathon Examples
"Often we come across documents, or text, in general which contain words and phrases that might be difficult for a normal guy to understand. For example - legal documents (docs published by Public Administration, contracts), and medical reports. We have developed an end to end web application, that takes such texts and tries to provide a lexically and syntactically simpler version of the provided text. These changes can be of the form - replacing complex words and phrases, breaking sentences, etc. We finetuned the small and medium models upon publically available datasets - Asset Data, MedWiki, and SimPA Corpus. We made use of the 'generate' API to get the simplified text. Also we used the 'embed' API to filter out noisy examples from the data, and also to choose the best possible response from the mulitple generations.",https://github.com/deb-kit2/coHereHack,Simplified Universe,Building Apps,Hackathon Examples
"DocuCenter untagles all your document related frustrations. A powerful yet simple, interactive system for storing, tracking, sharing and managing documents. Different document types have different needs. For example: all your documents related to immigration have to be time-tracked. DocuCenter extracts information from all the uploaded documents and embeds them into its renderable knowledge graph to provide assistance such as smart notifications, AI powered communication assist and prompt question answering.",https://github.com/345ishaan/hack_cohere,DocuCenter,Building Apps,Hackathon Examples
"The app lets you check if the queries you have have already been asked on MachineLearning subreddit! It shows 10 related matches to your query along with the relatedness distance, url and date when it was asked. [Cohere was used to generate about 17k embeddings from the queries mined on reddit. It is also used real time to generate the embeddings for the user's query to find related matches. (Though the ~17k embeddings took a lot of time to collect due to rate limit owing to free tier, the api had no downtime and embeddings were seamlessly stored over a period of 6 hours without throwing any exception.) ]",https://github.com/anukriti-ranjan/ML_queries_app,ML Queries App,Building Apps,Hackathon Examples
It's a simple web application which allows you to choose which types of emails are important for you. Based on that it will display only those that could be potentially important for you in the future. Furthermore it only shows you the summaries.,https://github.com/a-s-gorski/cohere-mind-ai-full.git,Mind-ai-full,Building Apps,Hackathon Examples
"WordGsr is a cooperative party minigame played on a single device within the Python console. It can be played in either of two modes - the telephone mode, or the point mode. Players take turns inputting words into the program, which then using the Cohere Generate api, outputs a realistic sentence for other players to guess the original words. The telephone version has the players pass their guesses to the next sentence, with the goal of keeping as close to the original words as possible. The point version is similar, except the players choose a new set of words each turn, and other players can earn points by guessing the words correctly. The program begins within the Main.py file, where the player can pick their desired mode. Then, based on their choice, they are directed to either the pointsVer.py or telephoneVer.py file, which runs the game. Players also get to choose their difficulty level, which changes the complexity of the sentence produced by the AI. This is achieved through changing the complexity the example dataset itself used to train it, located in the Prompt.txt files.",https://github.com/shendrew/WordGSR,WordGsr,Building Apps,Hackathon Examples
"['Cohere offers an API to add cutting-edge language processing to any system. Cohere trains massive language models and puts them behind a simple API. Moreover, through training, users can create massive models customized to their use case and trained on their data. This way, Cohere handles the complexities of collecting massive amounts of text data, the ever evolving neural network architectures, distributed training, and serving models around the clock.', 'Cohere offers access to both generation models (through the generate endpoint) and\nrepresentation models (through the embed endpoint which returns an embedding vector for the input text).', 'Two major categories of large language models are generative language models (like GPT2 and GPT3) and representation language models (like BERT). Cohere offers variants of both types.', 'Here are a few examples of language understanding systems that can be built on top of large language models.', 'Large language models present a breakthrough in text generation. For the first time in history, we have software programs that can write text that sounds like it’s written by humans. These capabilities open doors to use cases like summarization or paraphrasing.', 'Language models can be instructed to generate useful summaries or paraphrases of input text by guiding them using a task description in the prompt.', 'A summarization prompt in the Cohere playground shows this output (in bold):', ' Example summarization prompt and generation. Stop sequence is specified as the period to limit the output to one sentence.', 'Large language models can be adapted to new tasks with impressive speed. For tasks which appear in the training data (i.e. documents on the web), language models can successfully summarize text without being shown any examples at all.', 'Two strategies you can experiment with generative language models are prompt engineering and training (which creates a custom model based on your dataset).', 'Summarization and paraphrasing both use the generate endpoint.', 'New to Cohere?', 'Get Started now and get unprecedented access to world-class Generation and Representation models with billions of parameters.', 'Classification is one of the most common use cases in language processing. Building systems on top of language models can automate language-based tasks and save time and energy.', 'Developers can build classifiers on top of Cohere’s language models. These classifiers can automate language tasks and workflows.', ""There's more than one way to build a classifier on top of Cohere's language models. It's worth experimenting to see which method works best for your use case. The simpler methods can get you quick results, while the more advanced methods need more data and will lead to better results."", 'On the simpler side are methods like using the Classify endpoint for classification. More industrial-grade classifiers can be built by fitting a classifier on top of the embed endpoint (see: Embedding endpoint for classification).', 'Think of how many repeated questions have to be answered by a customer service agent every day. Language models are capable of judging text similarity and determining if an incoming question is similar to questions already answered in the FAQ section.', 'A similarity score can be computed through our embeddings by calculating the\ncosine similarity of two embeddings.', 'There are multiple things your system can do once it receives the similarity scores — one possible next action is to simply show the answer to the most similar question (if above a certain similarity threshold). Another possible next action is to make that suggestion to a customer service agent.', 'Updated about 1 month ago ']",https:/docs.cohere.ai//docs/the-cohere-platform,The Cohere Platform,Guides and Concepts,User Documentation
"['Language is important. It’s how we learn about the world (e.g. news, searching the web or Wikipedia), and also how we shape it (e.g. agreements, laws, or messages). Language is also how we connect and communicate — as people, and as groups and companies.', 'Despite the rapid evolution of software, computers remain limited in their ability to deal with language. Software is great at searching for exact matches in text, but often fails at more advanced uses of language — ones that humans employ on a daily basis.', 'There’s a clear need for more intelligent tools that better understand language.', 'A recent breakthrough in artificial intelligence (AI) is the introduction of language processing technologies that enable us to build more intelligent systems with a richer understanding of language than ever before. Large pre-trained Transformer language models, or simply large language models, vastly extend the capabilities of what systems are able to do with text.', 'Large language models are computer programs that open new possibilities of text understanding and generation in software systems.', 'Consider this: adding language models to empower Google Search was noted as “representing the biggest leap forward in the past five years, and one of the biggest leaps forward in the history of Search“. Microsoft also uses such models for every query in the Bing search engine.', 'Despite the utility of these models, training and deploying them effectively is resource intensive in its requirements of data, compute, and engineering resources.', 'Updated 28 days ago ']",https://docs.cohere.ai/docs/introduction-to-large-language-models,Introduction to Large Language Models,Guides and Concepts,User Documentation
"[""The Cohere Playground is a visual interface for users to test Cohere's large language models without writing a single line of code. To familiarize yourself with our endpoints, we recommend clicking the Generate or Calculate button on each endpoint page and observing the outputs. Use the Playground to test your use cases and when you're ready to start building, simply click Export Code to add Cohere's functionality to your application."", 'Generate produces natural language text in response to an input prompt. As seen in the screenshot below, we supplied the model with a prompt, ""Given a product and keywords, this program will generate exciting product descriptions. Here are some examples:"" and gave two examples of a product and keywords. The bolded text was generated by the model.', '', 'Try asking the model to do any of the following:', 'In each case, give the model a few examples your desired output.', 'Additionally, note the Calculate Likelihood button on the bottom right-hand corner. This feature outputs the likelihood that each token would be generated by the model in the given sequence, as well as the average log-likelihood of each token in the input. Token likelihoods can be retrieved from our Generate endpoint.', '', ""The log-likelihood is useful for evaluating model performance, especially when testing user-trained models. If you're interested in training a model, please submit a Full Access request from your Cohere Dashboard."", 'Using Embed in the Playground enables users to assign numerical representations to strings and visualize comparative meaning on a 2-dimensional plane. Phrases similar in meaning should ideally be closer together on this visualization. Add a couple of your own phrases and see if the Playground visualization feels accurate to you.', '', 'Cohere’s embeddings can be used to train a semantic classifier out of the box, saving users countless hours gathering data to train a model themselves.', 'Cohere’s Classify endpoint enables users to create a classifier from a few labeled examples.', '', 'Larger models are more capable of complex tasks but smaller models have faster response times and are less expensive. Here is a rough guideline for which model size to use for various tasks:', 'x-Large\nx-Large is the most capable generative model and can perform any task other models can with better results. This model is well suited for challenging tasks including complex extraction, rewriting, question-answering, summarization, conversation, and brainstorming.', 'Large\nLarge has demonstrated better performance for more complex extraction and rewriting tasks, and works well for open and closed-form question answering.', 'Medium\nMedium provides a great tradeoff between power and speed. Use this model to power tasks like generating marketing ad-copy, extracting key entities from text, or powering conversational agents.', 'Small\nSmall is our fastest model and can be used for simple generative tasks like generating a list of ideas, simple classification tasks, or rewriting text to remove grammatical errors.', 'Large\nLarge is our most capable representation model and can perform any tasks other models can with better results. The large model performs better at few shot classification tasks in both single label and multi-label scenarios. Large embeddings have 4096 dimensions.', 'Medium\nMedium provides a great tradeoff between power and speed. Medium embeddings have 2048 dimensions.', 'Small\nSmall is our fastest model, and has the lightest storage requirements. Small embeddings have 1024 dimensions.', 'Updated 28 days ago ']",https://docs.cohere.ai/docs/playground-overview,Playground Overview,Guides and Concepts,User Documentation
"[""Cohere's API is created to help you build natural language understanding and generation into your production with a few lines of code. Our Quickstart Tutorials will show you how to implement our API from zero-to-one in under 5 minutes. "", 'Chatbots are designed to understand and respond to human language. They need to be able to understand the text they hear and understand the context of the conversation. They also need to be able to respond to people’s questions and comments in a meaningful way. To accomplish this, chatbots must be able to recognize specific intents that people express in conversation.Here is an example of classifying the intent of customer inquiries on an eCommerce website into three categories: Shipping and handling policy, Start return or exchange, or Track order.', 'Updated about 1 month ago ']",https://docs.cohere.ai/docs/quick-start-guides,Quickstart Tutorials,Guides and Concepts,User Documentation
"['Upon registration, every Cohere user receives a free, rate-limited Trial key to use with our endpoints. If you find that you are running against the Trial key rate limit or want to serve Cohere in production, this page details the process of upgrading to a Production key and going live.', 'Trial keys for all endpoints are rate-limited at 100 calls per minute. If you’d like to use Cohere’s endpoints in a production application or require higher throughput from our endpoints for your usage, you can upgrade to a Production key.', 'With a Trial Key:', 'Organizations can still have unlimited trial keys in the free tier.\nThere is a defined usage limit on all the development API keys per minute (all keys add up to that rate limit).\nWhen a developer/org reaches a rate limit, they will receive an error that they have exceeded the limit/minute.\nPlayground usage counts toward your Trial key rate limit.\nIf calls exceed the throttling we throw an error that says “Trial keys are throttled."" Please upgrade your API key or contact us directly on Discord.\nTrial keys are free to use even after you upgrade to a Production key.', 'Production keys for all endpoints are rate-limited at 10,000 calls per minute and are intended for serving Cohere in a public-facing application and testing purposes. Usage of Production keys is metered at price points which can be found on our pricing page.', 'To get a Production key, you will need to complete a few steps in our Go to Production workflow. You can start the process by navigating to the Billing and Usage page in your Cohere dashboard as the Admin of your organization (or asking your organization Admin to complete these steps). From there, click on the Get your Production key button to start the process.', '', 'The process takes less than 3 minutes to finish, and enables you to generate a Production key that you can use to serve Cohere APIs in production. If you deploy without completing the Go to Production workflow, your API key may be temporarily or permanently revoked.', 'You must acknowledge Cohere’s SaaS Agreement and Terms of Service. Your organization must also read and recognize our Model Limitations, Model Cards, and Data Statement.', 'You will be asked if your usage of Cohere API involves any of the sensitive use cases outlined in our Usage Guidelines. Following your acknowledgement of our terms, you will be able to generate and use a Production key immediately. However, if you indicate your usage involves a sensitive use case, your Production key will still be rate limited the same as a Trial key until our Safety team reaches out and manually approves your use case. This will take no longer than 48 hours.', 'Navigate to our status page which features information including a summary status indicator, component statuses, unresolved incidents, status history, and any upcoming or in-progress scheduled maintenance. We recommend subscribing for updates with an email or phone number to receive notifications whenever Cohere creates, updates or resolves an incident.', 'Updated about 1 month ago ']",https://docs.cohere.ai/docs/going-live,Going Live,Guides and Concepts,User Documentation
"['To use our API, every developer must clearly outline their use case and have it approved by Cohere through our application process. The application requires thoroughly understanding of our models and their limitations, which will be updated as the models improve. Beyond these Usage Guidelines, you should refer to the Generation and Representation model cards for detailed information about each model.', 'By understanding the language models that power our API endpoints, being aware of their limitations, and documenting your development practices, you can do great things with the Cohere Platform.', '(Qiu et al., 2020) describes the history, technical aspects, and applications of pre-trained language models like the ones which power the Cohere Platform. We recommend reading this survey and other language modeling research to learn what kinds of knowledge are encoded in language models and how to use their outputs responsibly in downstream tasks.', 'Language models might encode the following:', ""We encourage careful consideration and documentation of the potential harms of any application developed using the Cohere Platform. If you build an application that uses model outputs, please provide your users a link to the corresponding model card, explaining how your application uses its output. For example, if you trained a downstream classifier using the embed endpoint, users should be provided with thorough documentation (such as model cards and data statements) of that classifier's training procedure and behaviour."", 'The Cohere Platform may not be used for any of the following purposes. The description for each disallowed use case is illustrative but not exhaustive; Cohere reserves the right to terminate access for harms which are not listed at our sole discretion.', 'Usages which appear to violate our guidelines should be reported within 24 hours to Cohere by contacting us at [email\xa0protected].', 'Note about adversarial attacks: Intentional stress testing of the API and adversarial attacks are allowable, but violative generations must be disclosed here, reported immediately, and must not be used for any purpose except for documenting the result of such attacks in a responsible manner.', 'Updated about 1 month ago ']",https://docs.cohere.ai/docs/usage-guidelines,Usage Guidelines,Guides and Concepts,User Documentation
"[""Use Cohere's models with the tools you love."", 'Weaviate is an open source vector search engine that stores both objects and vectors, allowing for combining vector search with structured filtering.', 'The text2vec-cohere module allows you to use Cohere embeddings directly in the Weaviate vector search engine as a vectorization module.', 'The Pinecone vector database makes it easy to build high-performance vector search applications. Use Cohere to generate language embeddings, then store them in Pinecone and use them for Semantic Search.', 'Cohere offers optimized containers that enable low latency inference on a diverse set of hardware accelerators available on AWS, providing different cost and performance points for Sagemaker customers.', 'Integrate the Surge AI labeling platform into your Cohere workflow.', ""Use Scale's labelled datasets with Cohere's Large Language Models."", 'Updated 1 day ago ']",https://docs.cohere.ai/docs/integrations,Integrations,Guides and Concepts,User Documentation
"['Embeddings are a way to represent the meaning of text as a list of numbers. This is useful because once text is in this form, it can be compared to other text for similarity. Using a simple comparison function, we can calculate a similarity score for two embeddings to figure out whether two texts are talking about similar things.', 'In the example below, the embeddings for two similar phrases have a high similarity score, and the embeddings for two unrelated phrases have a low similarity score:', 'Turning text into embeddings.', 'For short texts (shorter than 512 tokens), we return embeddings obtained by averaging the embeddings of each token in the text, following Reimers and Gurevych. The final embedding thus captures semantic information about the entirety of the text. For texts longer than 512 tokens, we first splice the text into 512-token chunks, and average the resulting embeddings of each chunk.', 'Updated 10 days ago ']",https://docs.cohere.ai/docs/embeddings,Embeddings,Guides and Concepts,User Documentation
"['Here, we discuss a few principles and techniques for writing prompts (inputs for our models) that will help you get the best generations for your task. Choosing the right temperature can also have a big influence on generation quality. We discuss temperature separately here.', '', 'We find that there are two main ideas to keep in mind while designing prompts for our models.', 'If you need a summary of an article, for example, a large language model trained on enough data can generate a summary if you guide it as such:', 'This prompt has two components: the text you want summarized, and the task description.', ""When using generate, it is useful to try a range of different prompts for the problem you are trying to solve. Different formulations of the same prompt which might sound similar to humans can lead to generations that are quite different from each other. This might happen, for instance, because our models have learned that the different formulations are actually used in very different contexts and for different purposes. Below we give a number of examples that we've found to work particularly well for different tasks."", 'In the summarization example, if “In summary,” doesn’t lead to a good generation, we may want to try “To summarize in plain language,“ or “The main point to take from this article is that”.', 'Additionally, you can also use the likelihood feature in the playground to see if there are particular words, phrases, or structures that the model has trouble understanding. However, keep in mind that the average likelihood of tokens will always be high at the beginning of the sequence. The model might assign low likelihood to the first time you introduce a novel concept or name, but once it has seen it once it can readily use it in the generation. You can also use the likelihood capability to see if there is any spelling or punctuation that is creating issues for tokenization.', ""It's often useful to include additional components of the task description, naturally these tend to come after the input text we're trying to process."", 'Provide the model with enough context. For example, we can describe the summarization task in more detail before the article.', 'Example: shaping the task we need the model to do in natural language can use text both before and after the input text we aim to process.', ""Let's consider a few more aspects of this by looking at a different example. Suppose that you would like to use our models to assist your customer satisfaction department by automatically generating plausible responses to customer requests (note: the generations are not to be sent to the customers, this is only a simulation)."", 'A customer contacts your company with the following question:', ""How do we design a prompt around this to get useful generations for the agent interacting with the customer? Let's begin with telling our model what the general setting is and what the remainder of the prompt is going to contain:"", ""Great, we've told our model about what to expect and have made it clear that our query is a question of the customer. Next, let's show the model the beginning of the response we would like to give the customer."", ""Note how we've stated clearly that the next sentence is a response to the question, that it comes from a customer service agent, and that we want to give a positive answer. Putting this all together, we obtain the following prompt:"", 'Certain components of prompts (like input and output indicators) are useful in describing a desired task to the model, especially when including multiple examples in the prompt (as the next figures will show).', 'Feeding this into our Medium model multiple times we get the following completions:', 'Note that even though this is a simplified example we get plausible completions from the baseline model using only a small number of customer service interactions! This could be further improved by finetuning it on examples of how you would like the model to handle specific questions and requests.', 'Adding examples to a prompt is one of the key ways to achieving good generations. Examples demonstrate to the model the type of output we target.', ""Give a few examples of the types of generations you want. This is called few-shot learning. Let's look at an example. Say, you'd like to use our models to classify whether a movie review is positive, negative or neutral. Imagine that you feed the following prompt into our model:"", 'An actual generation based on this prompt by our Medium model reads:', ""Clearly, there are generations that our model sees as likely that are not the type of generation we'd like to get."", 'Examples in the prompt should include both an example input and the output we want the model emulate.', 'Putting this all together and feeding this new prompt into the Medium Generation model, we reliably get the generation positive.', 'A simpler version of this prompt can be visualized like this:', 'An example bringing together the various components of a prompt. We can also repeat the task description with each example to emphasize the instruction to the model.', 'Few-shot generations will generally work better with our larger models. You can use the likelihood endpoint to see how uncertain the model is about the correct answers given in the examples.', 'If the command format does not work, try structuring as prose. An intuitive way to interact with the generate models is to give commands to the model about the type of generation that you want e.g. Give a list of artistic professions:. However, since much of the text that our models have seen is internet articles, sometimes this way of writing will be misunderstood. Try rephrasing the command into prose in a way such that the model will give the desired output:', 'In general, you may want to experiment with different styles of writing until you get something that works. Examples include writing in the style of a news article, a blog post, or a dialogue.', 'Here we showcase how we can use to apply the principles above by looking at two specific tasks: generating keywords based on a given passage and generating additional examples given a few existing examples.', ""Keyword generation: Let's imagine that we have text passages that we'd like to automatically tag with the most relevant concepts appearing in the text."", 'By combining a number of the techniques discussed above, we can generate just that! First, we state what the setting for this prompt is at the beginning of the prompt. Then we show the model two examples of what we want it to do: label a passage from John von Neumann\'s Wikipedia page with the label ""John von Neumann"", and label a paragraph from the Wikipedia page on Feminism with the label ""Feminism"". Lastly, we give the model a passage from the Wikipedia page on Python.', 'This prompt reliably generates ""Python"" as an answer – while sometimes also returning ""Guido van Rossum"", another plausible option.', 'Example generation. A common task is to try to get the model to generate examples according to some description. Formulating the prompt as a list in the following style tends to work well.', 'which then gives us generations like:', 'Updated about 1 month ago ']",https://docs.cohere.ai/docs/prompt-engineering,Prompt Engineering,Guides and Concepts,User Documentation
"['Our language models understand ""tokens"" rather than characters or bytes. One token can be a part of a word, an entire word, or punctuation. Very common words like ""water"" will have their own unique tokens. A longer, less frequent word might be encoded into 2-3 tokens, e.g. ""waterfall"" gets encoded into two tokens, one for ""water"" and one for ""fall"". Note that tokenization is sensitive to whitespace and capitalization.', 'Here are some references to calibrate how many tokens are in a text:', 'The number of tokens per word depends on the complexity of the text. Simple text may approach 1 token per word on average, while complex texts may use less common words that require 3-4 tokens per word on average. Our representation models are currently limited to processing sequences with a maximum length of 1024 tokens. Generation models vary, with the Small model having a maximum length of 1024 while Medium and Large support up to 2048 tokens.', 'Our vocabulary of tokens is created using Byte Pair Encoding.', 'Turning text into tokens.', 'The easiest way to determine a good number of tokens is to guess and check using our playground. It is common to request more tokens than required and then run additional processing to retrieve the desired output.', 'Updated about 1 month ago ']",https://docs.cohere.ai/docs/tokens,Tokens,Guides and Concepts,User Documentation
"['This model is in beta.', 'Our number one priority is to ensure that we are making our large language models safe, accessible, and useful. Our Command model is still in beta and we are aware of some of the limitations around safety. As you experiment with the model and run into issues, please help us by flagging it to our team by emailing us at [email\xa0protected]', ""command-xlarge-20221108 is a trained version of Cohere's x-large model that’s conditioned to respond better to zero-shot, instruction-like prompts. Despite its beta status, Command qualitatively outperforms all existing models on zero-shot tasks (prompts that don’t contain examples). You can expect to see the performance of command-beta evolve drastically over the coming weeks."", 'These best practices are specific to the first release of Command and will evolve as we push more improvements to production.', 'Can users train Command?\nUsers cannot train command-beta in OS at this time. However, our team can handle this on a case by case basis. Please email [email\xa0protected] if you’re interested in training this model.', 'When can users expect to see another improvement in performance for Command?\nCommand will emerge from beta in March of 2023, however users can expect performance improvements across the coming weeks.', ""Where can I leave feedback about Cohere's generative models?\nPlease leave feedback in #product-updates on Discord."", 'Updated 10 days ago ']",https://docs.cohere.ai/docs/command-beta,Command (Beta),Guides and Concepts,User Documentation
"['Our models learn to model language by reading text scraped from the internet. Given a sentence, such as I like to bake cookies, the model is asked to repeatedly predict what the next token [?] is:', 'The model learns that the word to is quite likely to follow the word like in English, and that the word cookies is likely to follow the word bake.', ""The likelihood of a token can be thought of as a number (typically between -15 and 0) that quantifies a model's level of surprise that this token was used in a sentence. If a token has a low likelihood, it means the model did not expect this token to be used. Conversely, if a token has a high likelihood, the model was confident that it would be used. Conversely, if a token has a high likelihood, the model was confident that it would be used. For example, using our Large model, the likelihood of to from the sentence I like to is roughly -1.5. This is quite high and means that the model was fairly confident that the tokens I like would be followed by the token to.. Similarly, the likelihood of cookies from the sentence I like to bake cookies is roughly -3.5, a bit lower than the previous example (which makes intuitive sense: brownies or cake would have also been reasonable options), but still quite high. However, if we change the sentence to I like to bake chairs then the likelihood of the token chairs is considerably lower, at around -14. This means the model is extremely surprised at its use within the sentence."", 'Likelihood of a token', 'Updated about 1 month ago ']",https://docs.cohere.ai/docs/likelihood,Likelihood,Guides and Concepts,User Documentation
"['When you call the Generate endpoint, you have the option to generate multiple generations in a single call. This is done by setting the num_generations parameter.', 'Generating multiple outputs in a single API call.', 'The model’s outputs will vary depending on the generation settings you have specified, such as temperature, top-k, and top-p.', 'Each generation comes with its set of likelihood values, which consists of:', 'This example uses the input: “This curved gaming monitor delivers ...”', 'The output generated with a maximum token set of 4 and sorted by average token likelihood are:', 'You can use these outputs in a number of ways, for example, by selecting the one with the highest likelihood as the final output or by presenting these as options in your application.', 'Updated about 1 month ago ']",https://docs.cohere.ai/docs/number-of-generations,Number of Generations,Guides and Concepts,User Documentation
"['Sampling from generation models incorporates randomness, so that the same prompt may yield different outputs each time you hit ""generate"". Temperature is a number used to tune the degree of randomness.', 'A lower temperature means less randomness; a temperature of 0 will always yield the same output. Lower temperatures (less than 1) are more appropriate when performing tasks that have a ""correct"" answer, like question answering or summarization. If the model starts repeating itself this is a sign that the temperature is too low.', 'High temperature means more randomness, which can help the model give more creative outputs. If the model starts going off topic or giving non-sensical outputs, this is a sign that the temperature is too high.', 'Adjusting the temperature setting', 'Temperature can be tuned for different problems, but most people will find that a temperature of 1 is a good starting point.', 'As sequences get longer, the model naturally becomes more confident in its predictions, so you can raise the temperature much higher for long prompts without going off topic. In contrast, using high temperatures on short prompts can lead to outputs being very unstable.', 'Updated about 1 month ago ']",https://docs.cohere.ai/docs/temperature,Temperature,Guides and Concepts,User Documentation
"['The method of picking output tokens is a key concept in text generation with language models. There are several methods (also called decoding strategies) for picking the output token and two of the leading ones are top-k sampling and top-p sampling.', 'Let’s look at the example where the input to the model is the prompt The name of that country is the:', 'Example output of a generation language model.', 'The output token in this case, United, was picked in the last step of processing -- after the language model has processed the input and calculated a likelihood score for every token in its vocabulary. This score indicates the likelihood that it will be the next token in the sentence (based on all the text the model was trained on).', 'The model calculates a likelihood for each token in its vocabulary. The decoding strategy then picks one as the output.', 'You can see in this example that we picked the token with the highest likelihood, ‘United’.', 'Always picking the highest scoring token is called ""Greedy Decoding"". It\'s useful but has some drawbacks.', ""Greedy decoding is a reasonable strategy but has some drawbacks such as outputs with repetitive loops of text. Think of the suggestions in your smartphone's auto-suggest. When you continually pick the highest suggested word, it may devolve into repeated sentences."", 'Another commonly used strategy is to sample from a shortlist of the top 3 tokens. This approach allows the other high-scoring tokens a chance of being picked. The randomness introduced by this sampling helps the quality of generation in a lot of scenarios.', 'Adding some randomness helps make output text more natural. In top-3 decoding, we first shortlist three tokens then sample one of them considering their likelihood scores.', 'More broadly, choosing the top three tokens means setting the top-k parameter to 3. Changing the top-k parameter sets the size of the shortlist the model samples from as it outputs each token. Setting top-k to 1 gives us greedy decoding.', 'Adjusting to the top-k setting.', 'The difficulty of selecting the best top-k value opens the door for a popular decoding strategy that dynamically sets the size of the shortlist of tokens. This method, called Nucleus Sampling, shortlists the top tokens whose sum of likelihoods does not exceed a certain value. A toy example with a top-p value of 0.15 could look like this:', 'In top-p, the size of the shortlist is dynamically selected based on the sum of likelihood scores reaching some threshold.', 'Top-p is usually set to a high value (like 0.75) with the purpose of limiting the long tail of low-probability tokens that may be sampled. We can use both top-k and top-p together. If both k and p are enabled, p acts after k.', 'Updated about 1 month ago ']",https://docs.cohere.ai/docs/controlling-generation-with-top-k-top-p,Top-k & Top-p,Guides and Concepts,User Documentation
"[""Cohere's platform gives you the ability to train a Large Language Model (LLM) and customize it with a dataset to excel at a specific task. Custom models can lead to some of the best performing NLP models for a wide number of tasks."", 'In this article, we look at training a generation model. See here for training a representation model.', 'Custom models use training data to turn a baseline model into a fine-tuned model.', ""Training large language models is only required when you need to teach the model something extremely niche, like the different gaits of a horse or your company's unique knowledge base. Common knowledge, like the colour of the sky, does not require training. Training is also helpful for generating or understanding data in a specific writing style or format."", ""Let's take a representation model as an example, where we finetune a model for a classification task with training data consisting of three classes."", 'To get an idea of how a representation model performs, we can project the embeddings it generates on a 2-dimensional plot, as per the image below. This image was taken from actual model outputs in the Playground.', 'The distance between two data points represents how semantically similar they are—the closer they are, the more similar they are, and vice versa. A good model will have a clear separation between classes. To test the model, here we have fifteen data points, five for each class, in which the classes are unknown to the model.', 'With a baseline model (left plot), we get a good separation between classes, which shows that it can perform well in this task.', 'But with a trained model (right plot), the separation becomes even more apparent. Similar data points are now pushed even closer together and further apart from the rest. This indicates that the model has adapted to the additional data it receives during training, hence is more likely to perform even better in this task.', 'In real applications, this makes a huge difference. One example is a toxicity classifier to help content moderators automatically flag toxic content on their platforms. Not all online platforms define toxicity the same way, and each will have different language nuances to accommodate. For example, a gaming platform, an online community for kids, and a social media platform—each would have a different interpretation of the exact same data. This is where model training can help, where a model can be customized to your specific needs.', 'Creates a custom model that adapts to the training data.', 'Updated about 1 month ago ']",https://docs.cohere.ai/docs/training-custom-models,Training Custom Models,Guides and Concepts,User Documentation
"[""Token likelihood is a useful tool for model evaluation. For instance, let's say you've trained a custom model and would like to know how much it's improved over the default model - you could use token likelihoods to compare the performance of the models on some held-out text. Here is a quick demonstration of how to use the return_likelihoods parameter from the Generate endpoint for model evaluation."", ""Let's say we've custom trained a medium model on Shakespeare data. We'd like to confirm that this custom model has higher likelihood on Shakespeare text compared to the default model. To do this, we could hold out the following snippet from the training data:"", 'Then we could use the following example code to retrieve the average log-likelihood of the above snippet:', 'The following are the average log-likelihoods of the snippet using the baseline and custom medium models:', 'This demonstrates that customizing this model increased the likelihood of Shakespeare data!', 'Updated 14 days ago ']",https://docs.cohere.ai/docs/likelihood-evaluation,Comparing Baseline and Custom Models,Guides and Concepts,User Documentation
"['Training a generation model consists of a few simple steps. Let’s go through the steps for training a generation model.', 'On the Cohere dashboard, go to the models page and click on ""Create a custom model"".', '', 'Click on the tile that says ""Generate"".', '', 'Upload your data by clicking on ‘Choose a .txt file’. Your data should be in TXT format.\nIf your data contains separators to distinguish between training examples, add the separator string in the ‘Data separator’ field (for example: --SEPARATOR--). If your data doesn’t contain separators, leave the field blank.', '', 'Once done, click on ‘Review data’.', '', 'The next window will show you a few samples of your data that has been split. If you included data separators, the data will be split according to the separator. If you didn’t, the split will be done automatically.', 'If you are happy with how the samples look, click on ‘Continue’ at the bottom of the page.', '', 'Give your model a nickname! Now, everything is set for custom training to begin. Press Start Training to begin!', '', 'You can view the status of training by clicking on the tile of the custom model on the models page.', '', ""You can also monitor a more detailed log by clicking on the status page and viewing the model's training journey."", '', 'As the model improves, you will be able to see the scores of the model also increase over time.', '', 'Once training is completed, the status will be shown as ‘Ready’.', '', ""To try out this model, you can either click on 'Try in Playground' on the models overview page or on the specific custom model page. "", '', 'Updated about 1 month ago ']",https://docs.cohere.ai/docs/training-a-generative-model,Training a Generative Model,Guides and Concepts,User Documentation
"['In this article, we look at training a representation model, which covers both the Embed and Classify endpoints. ', ""See here if you'd like to get an overview of training a generation model."", 'Text classification is one of the most common language understanding tasks. A lot of business use cases can be mapped to text classification. Examples include:', ""In this article, we'll train a representation model for sentiment classification."", ""A sentiment classifier assigns a piece of text as either 'positive' or 'negative'."", 'Training leads to the best classification results a language model can achieve. That said, untrained baseline embeddings can perform well in a lot of tasks (See the text classification article for an example of how to train a sentiment classifier on top of baseline embedding models). But if we need to get that extra boost in performance, training makes our LLM become a specialist for the task we care about.', 'The training file is a Comma Separated Values (CSV) file with a column for text and another for the number of the class. The contents of that file can look like this:', 'A table with example texts and a numeric label for each text (0 for negative texts, 1 for positive texts).', 'The CSV file can be prepared in Excel or in text format like this with a .csv extension.', 'That CSV file is then what you upload in the Representation training dialog box in the Playground.', 'New to Cohere?', 'Get started now and get unprecedented access to world-class Generation and Representation models with billions of parameters.', 'A representation LLM is excellent at generating sentence embeddings (lists of numbers that capture the meaning of the sentences). These embeddings are great at indicating how similar sentences are to each other. We can plot them to explore their similarities and differences (points that are close together have similar embeddings).', 'Consider a case where we have five customer messages. Visualizing their embeddings can look like this:', 'Scatter plot of five message example. Three of them are about shipping and are clustered close together.', 'Such an embedding captures semantic similarity – so for example, messages about shipping are close to each other on the left.', 'If we want to build the best sentiment classifier, however, then we need our embedding model to care about sentiment more than it cares about semantic similarity.', 'If we colour the points depending on their sentiment, it could look like this:', 'The same scatter plot of the five messages, except the colours of the points indicate which messages are positive and which are negative.', 'Successfully training a representation model on customer sentiment leads to a model which embeds sentences in this fashion:', 'A different scatterplot. Now positive messages are grouped together on the right, and negative messages are clustered together on the left.', 'Training an embedding model on customer sentiment leads to an embedding model where the embeddings of positive comments are similar to each other and distinct from those of negative comments. This leads to better sentiment classification results.', 'There are several things to take into account to achieve the best trained embeddings:', 'Training a representation model consists of a few simple steps. Let’s go through the steps for training a representation model.', 'On the Cohere dashboard, go to the models page and click on ""Create a custom model""', '', 'Click on the tile that says ""Classify"" or ""Embed"".', 'Both classify and embed endpoints will custom train a representation model', '', 'Upload your training dataset data by going to ‘Training data’ and clicking on the upload file button. Your data should be in CSV format with exactly two columns—the first and second columns consisting of the examples and labels respectively. ', '', 'Optionally, you can upload a validation dataset. This will not be used during training but instead, will be used for evaluating the model’s performance post-training. To do so, go to ‘Upload validation set (optional)’ and repeat the same steps you just did with the training dataset. If you don’t upload a validation dataset, the platform will automatically set aside a validation dataset from the training dataset.', 'At this point in time, if there are labels with less than 5 unique examples, we will remove those labels from your training set. ', '', ""As shown above, the label 'Area' had fewer than 5 examples so it has been removed from the training set."", 'Once done, click on ‘Next’.', ""The preview window will show a few samples of your training dataset, and if you uploaded it, your validation dataset.\nToggle between the tabs 'Training' and 'Validation' to see a sample of your respective datasets. "", '', 'At the bottom of this page, the distribution of labels in each respective dataset is shown. ', '', ""If you are happy with how the samples look, click on 'Continue'."", ""Now, everything is set for training to begin. Click on 'Start training' to proceed."", '', 'You can view the status of training by clicking on the tile of the custom model on the models page.', '', ""You can also monitor a more detailed log by clicking on the status page and viewing the model's training journey."", '', 'As the model improves, you will be able to see the scores of the model also increase over time', '', 'Once training is completed, the status will be shown as ‘Ready’.', '', ""To try out this model, you can either click on 'Try in Playground' on the models overview page or on the specific custom model page. "", '', 'We can’t wait to see what you start building! Share your projects or find support on our Discord.', 'Updated about 1 month ago ']",https://docs.cohere.ai/docs/training-a-representation-model,Training a Representation Model,Guides and Concepts,User Documentation
"['In this post, we answer frequently asked questions about training models.', 'While our Classify endpoint enables a user to build a classifier with just 5 examples per label, this classifier runs on our baseline model which has not been trained for specific use cases. Your dataset must contain at least 250 labelled examples to start training.', 'If you are unable to locate a relevant labelled dataset from online sources, we suggest trying to generate labelled examples using our Generate endpoint. Check out this sample preset of a user generating product feedback to train a product feedback classifier.', ""Ensure your data is in a two-column csv. One column should be the sample text you'd like to classify or search, and the second column should be a label for the text. We recommend using a comma , as your delimiter."", 'Here are a few example lines from a dataset that could be used to train a model that classifies headlines as positive, negative, and neutral with our Classify endpoint:', 'To pass data validation, ensure that:', ""Cohere's Classify endpoint will return predictions for classes that sum up to 1. We currently do not support outputting classifications for multiple labels (known as multi-label classification). Each example text should be mapped to one label only."", 'Take this example below:', 'Currently, we will process this data and train with two labels, technology,health and technology,economy instead of the desired three labels, technology, health, and economy.', 'In this case you will need to select one label for each headline.', ""At this time, if you are intending to train a representation model to use Cohere's Embed endpoint to perform a search task (not predicting a label), you will still need to assign a label to texts for representation training. "", 'For example, if you are building a search engine for Hacker News posts and you want to either cluster similar posts or associate posts with a certain keyword, you would create a labelled dataset with the post titles mapped to the keyword. See a few sample lines labelled below:', 'If you are topic modelling and trying to find clusters, we recommend trying the baseline model. Check out our blog post on topic modelling Hacker News posts.', 'When you are viewing auto evaluation metrics during or after your model has finished training, you may find that the F1, Recall, and Precision metrics are missing. This may occur if your dataset is extremely imbalanced (e.g. A binary dataset with 95% positive labels and 5% negative labels) and the trained model fails to predict one of the labels at all. This does not prevent you from using this trained model, it is simply a warning.', 'To resolve this warning, try adding more examples for labels with less data. ', 'Trainings are completed sequentially, and when you launch a training session, it is added to the end of a queue. Depending on the length of our training queue, training may take between 1 hour to a day to complete. ', 'To use your trained model in our API or SDKs, you must call it by its model UUID and not by its name. To get the model UUID, select the model in the playground and click Export Code. Select the library you are using and copy the code to call the model.', 'This is a screenshot of how to locate the model path to call your custom model.', 'All trained models are paused after 24 hours of inactivity. To restart your model, select your model in the trained models panel and click on the Wake button, pictured below:', 'This is a screenshot of how to awaken a paused model.', 'Our engineers review every individual failed training and will attempt to rectify it without any action on your part. We reach out to individuals with failed custom models we cannot resolve manually.', 'Please reach out to [email\xa0protected] or post in our co:mmunity Discord if you have unanswered questions about training models.', 'Updated about 1 month ago ']",https://docs.cohere.ai/docs/training-troubleshooting,Troubleshooting a Custom Model,Guides and Concepts,User Documentation
"['When you train a custom model, we provide you some measures to see how well your model might perform at the task provided.', 'Please note that Generate model outputs are often best evaluated qualitatively, so the performance metrics provided alone will not provide a comprehensive understanding of the model’s performance.', 'When you train a Generate custom model, you will see metrics that look like this:', '', 'Accuracy is a measure of how many predictions the model made correctly out of all the predictions in an evaluation. To evaluate Generate models for accuracy, we ask it to predict certain words in the user uploaded data.', 'The number in the pill (eg. 2%) is the difference between the accuracy of the default model when the user started training, and the accuracy of the model that is deployed. This difference is a proxy for how much accuracy improvement was gained by training the model on the dataset.', 'Loss is a measure that describes how bad or wrong a prediction is. Accuracy may tell you how many predictions the model got wrong, but it will not describe how incorrect the wrong predictions are. If every prediction is perfect, the loss will be 0.', 'To evaluate Generate models for loss, we ask the model to predict certain words in the user provided data and evaluate how wrong the incorrect predictions are. A loss around 11 indicates totally random performance. ', 'For this reason, the loss should decrease as the model improves. The number in the pill (e.g -0.17) is the difference between the loss when the default model started training and when it was deployed. This difference is a proxy for how much loss improvement was gained by training the model on your dataset.', 'Classify and Embed custom Models are both trained using data of examples mapping to predicted labels, and for that reason they are evaluated using the same methods and performance metrics. You can also provide a test set of data that we will use to calculate performance metrics. If a test set is not provided, we will split your training data randomly to calculate performance metrics. ', 'When you train Classify and Embed custom models, you will see metrics that look like this:', '', 'Accuracy is a measure of how many predictions the model made correctly out of all the predictions in an evaluation. To evaluate Embed and Classify models for accuracy, we ask the model to predict labels for the examples in the test set. In this case, the model predicted 79.51% of the labels correctly.', 'The number in the pill (eg. 53%) is the difference between the accuracy of the default model when the user started training, and the accuracy of the model that is deployed. This difference is a proxy for how much accuracy improvement was gained by training the model on the dataset.', 'Loss is a measure that describes how bad or wrong a prediction is. Accuracy may tell you how many predictions the model got wrong, but it will not describe how incorrect the wrong predictions are. If every prediction is perfect, the loss will be 0.', 'To evaluate Classify and Embed models for loss, we ask the model to predict labels for the examples in the test set and evaluate how wrong the incorrect predictions are. ', 'For this reason, the loss should decrease as the model improves. The number in the pill (e.g -0.34) is the difference between the loss when the default model started training and when it was deployed. This difference is a proxy for how much loss improvement was gained by training the default model on your dataset.', 'Precision is a measure that shows, for a given label, how correct the model was when it predicted the label. It’s calculated by taking the number of true positives and dividing it by the sum of true positives and false positives.', 'For example, let’s say we have a test set of 100 examples. 50 of them are label A and 50 of them are label B. If the model guessed label A for every prediction (100 times), every incorrectly predicted label B would be a false positive. The precision of label A would be 50%.', 'This is calculated for every label. The number shown in the metrics are the macro-weighted average of the precision across labels. ', 'Recall is a measure that shows how often the model predicted a given label correctly. It’s calculated by taking the number of true positives and dividing it by the sum of true positives and false negatives. ', 'For example, let’s say we have a test set of 100 examples. 50 of them are label A and 50 of them are label B. If the model guessed label A for every prediction (100 times), there would be no false negative predictions of label A. The recall of label A would be 100%.', 'This is calculated for every label. The number shown in the metrics are the macro-weighted average of the recall across labels.', 'Optimizing for either precision or recall often means sacrificing quality in the other. In the example above, 100% recall for label A does not mean that it was a great model, as evidenced by the precision. The F1 score attempts to provide a balanced measure of performance between precision and recall. ', 'The number shown in the metrics are the macro-weighted average of F1 across labels.', 'For Recall, Precision, and F1, the number in the pill is a proxy for how much improvement was gained by training the default model on your dataset.', 'You can see the detailed calculations to evaluate Embed and Classify models in this blog post.', 'Updated about 1 month ago ']",https://docs.cohere.ai/docs/custom-model-metrics,Custom Model Metrics,Guides and Concepts,User Documentation
"['At Cohere, we are committed to breaking down barriers and expanding access to cutting-edge NLP technologies that power projects across the globe. By making our innovative multilingual language models available to all developers, we continue to move toward our goal of empowering developers, researchers, and innovators with state-of-the-art NLP technologies that push the boundaries of Language AI.', 'Our Multilingual Model maps text to a semantic vector space, positioning text with a similar meaning in close proximity. This process unlocks a range of valuable use cases for multilingual settings. For example, one can map a query to this vector space during a search to locate relevant documents nearby. This often yields search results that are several times better than keyword search.', '', 'To get started using the multilingual embedding models, you can either query our endpoints or install our SDK to use the model within Python:', 'Updated 4 days ago ']",https://docs.cohere.ai/docs/multilingual-language-models,Multilingual Embedding Models,Guides and Concepts,User Documentation
"['Language detection is a necessary first step for businesses that deal with multilingual user bases. Whether you are working with a single multi-lingual model or a multi model environment, understanding the language of a request (e.g. query, input) is paramount to a good user experience. ', 'Co.detect_language is an endpoint gives the following information for a text input: ', 'Create a single model that can handle English and non-English use cases, allowing you to simplify model architecture and perform cross-lingual searches.', 'Use multiple models for English and non-English embeddings. If a query is in English, it will be automatically routed to an English embedding model, if not, it will be routed to our multilingual embedding model. ', 'Here is a list of ISO language codes our models support. ', ' If you are not familiar with ISO codes, you can cross-index the codes with full language names here.', 'Updated 4 days ago ']",https://docs.cohere.ai/docs/language-detection,Language Detection,Guides and Concepts,User Documentation
"['Semantic search no longer restricts itself to queries and documents in the same language but also works across languages. For example, if we phrase the search query in Arabic (“?? ?? ????? ???????? ????????”), we get the same results, while keyword search can obviously not retrieve any relevant documents.', '', 'This enables interesting use cases, for example, in the financial domain, to quickly find relevant information irrespective of the language in which they have been published.', 'Updated 7 days ago ']",https://docs.cohere.ai/docs/multilingual-semantic-search,Multilingual Semantic Search,Guides and Concepts,User Documentation
"['Successful products like the iPhone quickly get tens of thousands of reviews on eCommerce marketplaces and on social media, which are written in many languages. Getting insights from these reviews enables companies to better understand their customer base and to better drive their product roadmap. ', 'However, methods for content aggregation only worked well for English, and it wasn’t possible to see patterns across languages or to compare markets.', '', 'Cohere’s multilingual model maps text in different languages to the same vector spaces, allowing users to derive insights across languages and find patterns for specific markets (e.g., which markets care about the picture quality of smartphones).', 'Updated 7 days ago ']",https://docs.cohere.ai/docs/customer-feedback-aggregation,Customer Feedback Aggregation,Guides and Concepts,User Documentation
"['In today’s world, content moderation remains a major challenge. As platforms like online games increasingly attract an international audience, the complexity of content moderation has grown as hateful content makes its way across multiple languages and has a greater probability of passing through content moderation tools.', 'To tackle this challenge, we use multilingual embeddings to build a content moderation tool that works across 100+ languages and only requires training data in English.', '', 'For content moderation, we just need a handful of training examples of harmful and acceptable content in one language. For example, in English, we can then train a classifier to find the decision boundary in the vector space that helps us determine which type of content is undesirable on the platform.', 'Updated 4 days ago ']",https://docs.cohere.ai/docs/cross-lingual-content-moderation,Cross-Lingual Content Moderation,Guides and Concepts,User Documentation
"['This Guide Uses the Classify Endpoint.', 'You can find more information about the endpoint here.', 'The Classify endpoint streamlines the task of running a text classification task. Via a single endpoint, you can deploy different kinds of content moderation use cases according to your needs.', 'As online communities continue to grow, content moderators need a way to  moderate user-generated content at scale. To appreciate the wide-ranging need for content moderation, we can refer to the paper A Unified Typology of Harmful Content by Banko et al. [Source]. It provides a unified typology of harmful content generated within online communities and a comprehensive list of examples, which can be grouped into four types:', 'There are publicly available datasets within the content moderation space which you can experiment with, for example:', '', 'Here we take a quick look at performing a toxicity detection using the Classify endpoint of the Cohere API. In this example, our task is to classify a list of example social media comments as either toxic or benign.', '', 'LLMs work by conditioning it with some examples of what we want its outputs to look like. In our case, we’ll provide a few examples of labeled data, whereby each data point contains the text online comment and the associated toxicity label. Then we feed the model with the inputs we want to classify and the model will return the predicted class it belongs to.', 'We’ll use the Cohere Playground, which is an interface that helps you quickly prototype and experiment with LLMs.', 'First, we choose the model we want to use and enter the labeled examples. The model will work fine with as few as 5 examples per class, but in general, the more data, the better. In this example, we’ll provide 5 examples for each class: toxic and benign.', '', 'Here’s a better look at all ten examples:', 'Next we enter the list of inputs we want to classify and run the classification. Here we have 3 inputs per class, making it 6 total.', '', 'Here’s a better look at all six inputs and outcomes:', 'In this small example, the model got all classifications correct. We can then generate the equivalent code to access the Classify endpoint by exporting the code from the Playground.', '', 'The following is the corresponding code snippet for the API call. From here, we can further build the content moderation solution according to the scale and integration needs.', 'To get the best classification performance, you will likely need to perform custom training, which is a method for customizing an LLM model with your own dataset. This is especially true for a content moderation task, where no two communities are the same and where the nature of the content is always evolving. The model will need to capture the nuances of the content within a given community at a given time, and custom model training is a way to do that.', 'The Cohere platform lets you train a model using a dataset you provide. Refer to this article for a step-by-step guide.', 'In summary, Cohere’s LLM API empowers developers to build content moderation systems at scale without having to worry about building and deploying machine learning models in-house. In particular, teams can perform text classification tasks via the Classify endpoint. Try it now!', 'Updated 14 days ago ']",https://docs.cohere.ai/docs/content-moderation-with-classify,Content Moderation,Guides and Concepts,User Documentation
"['This Guide Uses the Generate Endpoint.', 'You can find more information about the endpoint here.', 'Extracting a piece of information from text is a common need in language processing systems. LLMs can at times extract entities which are harder to extract using other NLP methods (and where pre-training provides the model with some context on these entities). This is an overview of using generative LLMs to extract entities.', '', 'This example uses Cohere\'s generative models to extract the name of a film from the title of an article. We\'ll use post titles from the r/Movies subreddit. For each title, we\'ll extract which movie the post is about. If the model is unable to detect the name of a movie being mentioned, it will return ""none"".', 'The full code example is in the notebook and colab', 'In our prompt, we\'ll present the model with examples for the type of output we\'re after. We basically get a set of subreddit article titles, and label them ourselves. The label here is the name of the movie mentioned in the title (and ""none"" if no movie is mentioned).', '', ""We'll create a prompt that demonstrates the task to the model. The prompt contains the examples above, and then presents the input text and asks the model to extract the movie name."", '', ""So let's get a few example titles from the movies subreddit, label them, and make an extraction prompt out of them:"", ""Let's point out a few ideas in this prompt:"", ""Let's get the top ten posts in r/movies of 2021. We can preview the top three:"", 'We can then proceed with the extraction. We basically plug each post title into the input text part of the prompt, and retrieve the output of the model.', ""These are the model's results:"", 'The model got 9/10 correctly. It didn\'t pick up on Shaolin Soccer and God of Gambler in example #4. It also called the second example ""Pixar\'s Luca"" instead of ""Luca"".', 'Find the full code in the notebook/colab. It proceeds to evaluate performance on a small test set.', ""This type of extraction is interesting because it doesn't just blindly look at the text. The model has picked up on movie information during its pretraining process and that helps it understand the task from only a few examples."", 'You can think about extending this to other subreddits, to extract other kinds of entities and information. Join our Discord Community to share ideas and ask questions about NLP and ML and let us know what you are experimenting with and what kind of results you see! ', 'Happy building!', 'Updated about 1 month ago ']",https://docs.cohere.ai/docs/entity-extraction,Entity Extraction,Guides and Concepts,User Documentation
"['This Guide Uses the Embed Endpoint.', 'You can find more information about the endpoint here.', 'Language models give computers the ability to search by meaning and go beyond searching by matching keywords. This capability is called semantic search.', '', 'In this article, we\'ll build a simple semantic search engine. The applications of semantic search go beyond building a web search engine. They can empower a private search engine for internal documents or records. It can be used to power features like StackOverflow\'s ""similar questions"" feature.', 'You can find the code in the notebook and colab.', 'New to Cohere?', 'Get Started now and get unprecedented access to world-class Generation and\nRepresentation models with billions of parameters.', ""We'll use the trec dataset which is made up of questions and their categories."", '', ""Let's now embed the text of the questions."", 'To get a thousand embeddings of this length should take a few seconds.', '', ""Let's build an index using the library called annoy. Annoy is an library created by Spotify to do  nearest neighbour search; nearest neighbour search is an optimization problem of finding the point in a given set that is closest (or most similar) to a given point. "", 'After building the index, we can use it to retrieve the nearest neighbours either of existing questions (section 3.1), or of new questions that we embed (section 3.2).', ""If we're only interested in measuring the similarities between the questions in the dataset (no outside queries), a simple way is to calculate the similarities between every pair of embeddings we have."", ""We're not limited to searching using existing items. If we get a query, we can embed it and find its nearest neighbours from the dataset."", 'Create the graph locally and hover over the points to read the text. Do you see some of the patterns in clustered points? Similar questions, or questions asking about similar topics?', 'This concludes this introductory guide to semantic search using sentence embeddings. As you continue the path of building a search product additional considerations arise (like dealing with long texts, or training to better improve the embeddings for a specific use case).', 'We can’t wait to see what you start building! Share your projects or find support on our community discord.', 'Updated about 1 month ago ']",https://docs.cohere.ai/docs/semantic-search,Semantic Search,Guides and Concepts,User Documentation
"['This Guide Uses the Classify Endpoint.', 'You can find more information about the endpoint here.', 'In this section, we show how to use the Classify endpoint to do sentiment classification for customer satisfaction survey responses an e-commerce website may receive.', '', ""For this demo, let's assume that we want to classify a set of reviews for a newly released feature into positive and negative classes. We might for instance have a review like this:"", 'The item exceeded my expectations', 'that we want to classify as a positive review.', ""Naturally, the same techniques that we'll use for this problem can be used for any other task where we want to classify a given text according to a fixed set of classes."", 'Classify takes in example inputs with their labels, as well as the input texts we aim to classify. It then trains a classifier using the power of an embeddings model. ', ""Labeled examples are used to demonstrate the classification task to the model so it grasps the task. Examples provide two important pieces of information:\n1- The inputs and expected outputs for the task we're interested in.\n2- The number of output classes. Every class should appear in at least one example in the labeled examples."", 'In this case we will be passing in the following examples: ', 'These are the input texts that we would like to classify:', 'Adding everything above together, we can call the API with the following arguments:', 'The corresponding code snippet for the API call is as follows.', 'It gives us the following values:', 'which indicates that, as we would expect, our model thinks that both texts are negative.', 'The playground has a user interface to help you set up the classification prompts, which can then be exported as code.', 'In the Cohere Playground, click on ‘Classify’.\nSelect the model size of your choice. Our smaller model is faster, while our larger model has a better grasp of language and are more able to capture and replicate the patterns in the input prompt.', '', 'Add your labeled examples in the ‘Examples’ section. The first column is for the examples while the subsequent columns are for the associated labels. Our example here consists of 2 labels but there is no limit as to how many labels you can specify, depending on the task you have.', 'You can also add your labeled examples using a CSV file by selecting upload your labelled examples.', '', 'Add at least 2 examples for each label. The more examples you have, the higher the chance of getting more accurate outcomes.', 'If you are not sure, there are also some preset examples to help you get started.', '', 'Add the inputs you want to classify in the ‘Inputs’ section. Once done, click on ‘Classify’ to start the classification step.', '', 'Once the classification step is completed, you will see the output labels next to the inputs you added.', ""In the ‘Results’ section, you will also see the confidence levels associated with each output. The confidence level represents the model's degree of certainty that the query falls under a given label. The label with the highest confidence is chosen."", '', 'Now the code is ready to be exported. Click on ‘Export code’ and you can choose to export from a few different options. You can use this to start integrating the current API configuration to your application.', '', 'You can opt to train a model if you have a dataset of at least 250 labeled examples (500 or more for best results) with at least 5 examples per label. ', 'A trained model can potentially lead to a better classification performance than a baseline model. See here to get an overview of what model training is about.', 'To train a model for your classification task, navigate to the models page and click on Create a custom model.', '', 'The subsequent steps are the same as how you would train a representation model. For this, follow the steps described here.', 'Updated 11 days ago ']",https://docs.cohere.ai/docs/text-classification-with-classify,Text Classification (Classify),Guides and Concepts,User Documentation
"['This Guide Uses the Embed Endpoint.', 'You can find more information about the endpoint here.', ""This notebook shows how to build a classifiers using Cohere's embeddings. You can find the code in the notebook and colab."", 'First we embed the text in the dataset, then we use that to train a classifier.', ""The example classification task here will be sentiment analysis of film reviews. We'll train a simple classifier to detect whether a film review is negative (class 0) or positive (class 1)."", ""We'll go through the following steps:"", '', ""We'll only use a subset of the training and testing datasets in this example. We'll only use 500 examples since this is a toy example. You'll want to increase the number to get better performance and evaluation."", 'The train_test_split method split arrays or matrices into random train and test subsets.', 'We are calling the co.embed() method to convert our text examples into numerical representations. ', 'We now have two sets of embeddings, embeddings_train contains the embeddings of the training sentences while embeddings_test contains the embeddings of the testing sentences.', 'Curious what an embedding looks like? we can print it:', 'The results look something like this', ""Now that we have the embedding we can train our classifier. We'll use an SVM from sklearn. We call the make_pipeline which configures a pipeline. The purpose of the pipeline is to assemble several steps that can be cross-validated together while setting different parameters. "", ' Validation accuracy on Large is 88.8%!', ""This was a small scale example, meant as a proof of concept and designed to illustrate how you can build a custom classifier quickly using a small amount of labelled data and Cohere's embeddings. Increase the number of training examples to achieve better performance on this task."", 'Updated about 1 month ago ']",https://docs.cohere.ai/docs/text-classification-with-embed,Text Classification (Embed),Guides and Concepts,User Documentation
"['This Guide Uses the Generate Endpoint.', 'You can find more information about the endpoint here.', ""This article demonstrates a simple way of using Cohere's generation models to summarize text. "", '', 'You can find the code in the notebook and colab.', 'We will use a simple prompt that includes two examples and a task description:', 'Our prompt is geared for paraphrasing to simplify an input sentence. It contains two examples that demonstrate the task to the model. The sentence we want it to summarize is:', 'Killer whales have a diverse diet, although individual populations often specialize in particular types of prey.', 'We get several completions from the model via the API', 'We are taking the token likelihoods of each generated paragraph and summing to get to a total ""paragraph"" score. ', 'We then rank each paragraph by their likelihood score. ', 'The model suggests the following candidate summaries for the sentence:', '""Killer whales have a diverse diet, although individual populations often specialize in particular types of prey.""', ""In a lot of cases, better generations can be reached by creating multiple generations then ranking and filtering them. In this case we're ranking the generations by their average likelihoods."", ""It's worth spending some time learning the various hyperparameters of the generation endpoint. For example, temperature tunes the degree of randomness in the generations. Other parameters include top-k and top-p as well as frequency_penalty and presence_penalty which can reduce the amount of repetition in the output of the model. See the API reference of the generate endpoint for more details on all the parameters."", 'Updated about 1 month ago ']",https://docs.cohere.ai/docs/text-summarization-guide,Text Summarization,Guides and Concepts,User Documentation
"[""The Responsible Use documentation aims to guide developers in using language models constructively and ethically. Toward this end, we've published guidelines for using our API safely, as well as our processes around harm prevention. We provide model cards to communicate the strengths and weaknesses of our models and to encourage responsible use (motivated by Mitchell, 2019). We also provide a data statement describing our pre-training datasets (motivated by Bender and Friedman, 2018)."", 'Model Cards:', 'If you have feedback or questions, please feel free to let us know — we are here to help.', 'We aim to mitigate adverse use of our models with the following:', 'Updated about 1 month ago ']",https://docs.cohere.ai/docs/responsible-use,Overview,Guides and Concepts,User Documentation
"['The following factors may impact our language models’ performance.', 'Language: Due to the lack of available training data and evaluation datasets for the majority of the world’s languages, the model is unlikely to perform well on languages other than the dominant dialects of English (Joshi, 2020;  Dodge, 2021). We are actively working to increase the number of languages supported by the Cohere API.', 'Example: Our language models may fail to meaningfully represent non-English phrases.', 'Socio-economic: The majority of publicly available data used to train the model is from wealthier individuals in more developed countries, and is largely Western-centric (Pew, 2021). As a result, performance will likely degrade on text about concepts, people and places from other regions, especially that of the Global South.', 'Example: The models may prefer phrases and ideas associated with Western ideals, or with wealthier and more technologically developed cultures.', 'Historical: At any point, the model will only represent the concepts, events, places, and people from data on which it was trained. Information from after the dataset was gathered will not be represented. For example, if an event occurred today, the model would not be able to return a meaningful representation of the event name. Additionally, the model may amplify outdated societal biases about groups of people.', 'Example: The models may fail to generate the correct answer to a factual question if the information regarding that fact has recently changed since the models were trained.', 'Ungrounded: Model outputs are derived statistically rather than from any direct modeling of the meaning of words and phrases, and therefore they should not be interpreted as a grounded means for understanding text (Bender, 2020).', 'Biases: Language models capture the hegemonic viewpoint, reflecting and magnifying biases that exist on the internet (Bender,2021). As a result, marginalized groups can be harmed by entrenching existing stereotypes, or producing demeaning portrayals (Crawford, 2017). Despite our active efforts to mitigate these biases, we acknowledge that this is an ongoing research area (Gonen, 2019).', ' _Example: The models may associate gender, racial, and other identities with professions and concepts which are semantically unrelated to those identities. These associations are likely to reflect biases present in the historical data the model was trained on. For research on bias in embeddings, see, for example, (Kurita et al., 2019); for a survey of the space of language model generation bias, see (Sheng et al., 2021).', 'Updated about 1 month ago ']",https://docs.cohere.ai/docs/model-limitations,Model Limitations,Guides and Concepts,User Documentation
"['Dataset Names: coheretext-filtered, coheretext-unfiltered\nDataset Developers: Cohere Infrastructure Team\nData Statement Authors: Cohere Safety Team & Responsibility Council\nSize: ~200GB filtered, ~3TB unfiltered', 'The unfiltered dataset is used to train Representation models that reflect the world, including its current harms and biases. This enables them to be effective for use cases such as content moderation.', 'The filtered dataset is used to train the Generation models to complete sentences based on a prompt, while minimizing harmful generations. Our use of filtered training data is motivated by the observation of (Bender et al., 2021) that uncurated data used to train language models encodes the dominant view, further harming people at the margins. Cohere continues to invest significant resources towards dataset curation to prevent harm.', 'This model is trained on the Google Books dataset, CommonCrawl, and text from the internet scraped by the Cohere infrastructure team. The top ten domains scraped by our team include: wordpress.com, medium.com, stackexchange.com, tumblr.com, elsevier.com, genius.com, bbc.co.uk, libsyn.com, yahoo.com, nytimes.com', 'The scraped data is similar in composition to many other large, Internet-sourced language modeling datasets, and hence reflects perspectives that skew young, white, and male (Bender et al., 2021). Language models trained on such data encode the hegemonic viewpoint; Jo and Gebru, 2021 detail issues and solutions around this topic in-depth. Enhancing the diversity of our training data is a top priority as we continue to iterate our data collection process.', 'Filtering harmful, biased, or otherwise undesirable documents from training data can improve language model performance (Raffel et al., 2020) and reduce the chances of the model perpetuating harm. However, doing so with precision is critical so that we do not silence marginalized voices (Bender et. al, 2021).', 'With these considerations in mind, we designed a document curation process which aims to minimize undesirable text within our training data. The best way to do this is an active area of research within Cohere and the broader machine learning research community (Sharoff, 2020). As Cohere learns more about the types of harm large language models exhibit, it will adapt the composition of its datasets accordingly.', 'We recognize the dangers of using a blockword list (i.e. removing any documents containing words from a list of selected words). Our filtration techniques are designed to retain counterspeech by taking into account language and context in a nuanced way. For example, we do not want to remove documents addressing racism, but we do want to filter racist texts. An example of a harm filtration technique we use has been published to Arxiv.', 'We currently train our language models on English documents only, and model performance is evaluated on English benchmarks. The heuristics we use to detect non-English text during document curation are imperfect and other languages may still remain in the dataset. Multilingual datasets and benchmarks will be incorporated into future iterations of our data and evaluation pipelines.\nFooter', 'Updated 4 months ago ']",https://docs.cohere.ai/docs/data-statement,Data Statement,Guides and Concepts,User Documentation
"['The model outlined in this card provides generated text completions based on an input prompt. It powers the Generate endpoint.', 'Model architecture: Generative Pretrained Transformer\nModel release date: See release notes\nModel sizes: Medium, Extremely Large\nModel Card Author(s): Cohere Safety Team & Responsibility Council', 'Training Dataset: coheretext-filtered dataset', 'Performance has been evaluated on the following research benchmarks. These metrics are reported on the Extremely Large (Beta) model. To gain a deeper understanding of what these benchmarks mean for your use case, read more about  Hellaswag and COPA.', 'Performance has been evaluated on the following safety-related research benchmarks. These metrics are reported on the Large model.', 'We are researching how to expand our safety benchmarking to the multilingual context; multilingual benchmarks will be introduced in the future.', 'Generations may be used for interactive autocomplete, augmenting human writing processes, summarization, text rephrasing, and other text-to-text tasks in non-sensitive domains.', 'Outputs from Classify can be used for classification and analysis tasks, such as selecting the most likely completion for a sentence. Token likelihoods from Likelihood might be used to make fun claims about the “randomness” of your favourite author’s writing, or to explore the statistical differences between human-written and machine-generated text (see Gehrmann et al., 2019).', '', 'Generations can address a large number of use cases. Check the presets for interesting examples.', 'Always refer to the Usage Guidelines for guidance on using the Cohere Platform responsibly. Additionally, please consult the following model-specific usage notes:', 'Language models learn the statistical relationships present in training datasets, which may include toxic language and historical biases along race, gender, sexual orientation, ability, language, cultural, and intersectional dimensions. We recommend that developers using the Generation model take model toxicity and bias into account and design applications carefully to avoid the following:', 'Toxic Degeneration: Despite our ongoing efforts to remove harmful text from the training corpus, models may generate toxic text. This may include obscenities, sexually explicit content, and messages which mischaracterize or stereotype groups of people based on problematic historical biases perpetuated by internet communities (see Gehman et al., 2020 for more about toxic language model degeneration). We have put safeguards in place to avoid generating harmful text, but we highly recommend that developers build additional guardrails to ensure that text presented to end users is not toxic or harmful.', 'Reinforcing historical social biases: Language models capture problematic associations and stereotypes prominent on the internet and society at large. They should not be used to make decisions about individuals or the groups they belong to. For example, it is dangerous to use Generation model outputs in CV ranking systems due to known biases (Nadeem et al., 2020).', 'Guided by the NAACL Ethics Review Questions, we describe below the model-specific concerns around misuse of the Generation model. By documenting adverse use cases, we aim to encourage Cohere and its customers to prevent adversarial actors from leveraging our models to the following malicious ends.', 'Note: The examples in this section are not comprehensive and are only meant to illustrate our understanding of potential harms. The examples are meant to be more model-specific and tangible than those in the Usage Guidelines. Each of these malicious use cases violates our usage guidelines and Terms of Use, and Cohere reserves the right to restrict API access at any time.', 'Updated about 1 hour ago ']",https://docs.cohere.ai/docs/generation-card,Generation,Guides and Concepts,User Documentation
"['The model outlined in this card provides embedding representations of text. It powers the Embed and Classify endpoint.', 'Model architecture: Masked Language Model\nModel release dates: See release notes\nModel sizes: Small, Medium, Large\nModel Card Author(s): Cohere Safety Team & Responsibility Council', 'Training Dataset: coheretext-unfiltered dataset', 'Performance has been evaluated on the following safety-related research benchmarks. These metrics are reported for the Small model. ', 'For StereoSet Stereotype Score, 50 is best. For Language Modeling Score, 100 is best.', 'For SEAT tests, a dash ""-"" indicates no significant evidence of bias was found. Otherwise, a number indicates the bias effect size. We are researching how to expand our safety benchmarking to the multilingual context; multilingual benchmarks will be introduced in the future.', 'Embeddings may be used for purposes such as estimating semantic similarity between two sentences, choosing a sentence which is most likely to follow another sentence, sentiment analysis, topic extraction, or categorizing user feedback. Performance of embeddings will vary across use cases depending on the language, dialect, subject matter, and other qualities of the represented text.', 'Always refer to the Usage Guidelines for guidance on using the Cohere Platform responsibly. Additionally, please consult the following model-specific usage notes:', 'There is extensive research into the social biases learned by language model embeddings (Bolukbasi et al., 2016; Manzini et al., 2019; Kurita et al., 2019; Zhao et al., 2019). We recommend that developers using the Representation model take this into account when building downstream text classification systems. Embeddings may inadvertently capture inaccurate associations between groups of people and attributes such as sentiment or toxicity. Using embeddings in downstream text classifiers may lead to biased systems that are sensitive to demographic groups mentioned in the inputs. For example, it is dangerous to use embeddings in CV ranking systems due to known gender biases in the representations (Kurita et al., 2019).', 'Guided by the NAACL Ethics Review Questions, we describe below the model-specific concerns around misuse of the Representation model. By documenting adverse use cases, we aim to encourage Cohere and its customers to prevent adversarial actors from leveraging our models to the following malicious ends.', 'Note: The examples in this section are not comprehensive and are only meant to illustrate our understanding of potential harms. The examples are meant to be more model-specific and tangible than those in the Usage Guidelines. Each of these malicious use cases violates our usage guidelines and Terms of Use, and Cohere reserves the right to restrict API access at any time.', 'Updated about 1 month ago ']",https://docs.cohere.ai/docs/representation-card,Representation,Guides and Concepts,User Documentation
"['Training large language models consumes a significant amount of energy (Strubell, 2019). In the spirit of carbon neutrality and minimizing the carbon footprint of model training, all models are trained on Google Cloud, which has net zero emissions and the goal of being 100% renewable by 2030. Models are trained on Google Cloud TPUs, which are significantly more energy efficient than traditional GPUs.', 'While training models with net zero emissions is a good first step, we acknowledge the controversy of carbon neutrality. In the long run, we aim to reduce our carbon footprint by using more efficient training processes, designing smaller models, and training on energy-efficient devices.', 'For transparency and accountability, carbon emissions are reported below per model training run using the ML CO2 Impact Tool, which follows the methodology described in (Lecoste, 2019). Estimates are approximate upper bounds and are applicable to both Generation and Representation models. Estimates for custom model training are currently excluded.', 'Transatlantic flight eq. calculated based on a total CO2 emission of 41284.1 kg (Toronto to London)', 'Updated about 1 month ago ']",https://docs.cohere.ai/docs/environmental-impact,Environmental Impact,Guides and Concepts,User Documentation
"['The Cohere platform builds natural language understanding and generation into your product with a few lines of code. Our large language models can solve a broad spectrum of natural language use cases, including classification, semantic search, paraphrasing, summarization, and content generation. ', 'By training a custom model, users can customize large language models to their use case and trained on their data.', 'The models can be accessed through the playground, SDK and the CLI tool.', 'Install package:', 'Install package:', 'Install the npm package:', 'To make a request to any model, you must pass in the Authorization Header and the request must be made through a POST request.\nThe content of Authorization should be in the shape of BEARER [API_KEY]. All request bodies are sent through JSON.', 'Model names are found within the dashboard, and details about endpoints are available within the documentation.\nDetailed model information can be found in the Model Cards.']",https://docs.cohere.ai/reference/about,About,API Reference,User Documentation
"['Working in Teams in the Cohere platform enables users to share API keys and custom models. There are two role types to manage access to the platform: Owner and User. Below are details on how to invite others to your Team and the difference in access permissions between the two roles. ', 'If you sign up with Cohere without being invited to a Team, you automatically become the “Owner” of your Team. To invite others to your team, navigate to the Cohere Dashboard, then click on the “Team” page in the sidebar. ', '', 'Clicking “+ Invite Teammates” will open a modal where you can send email invites and specify the role that best suits your teammates. ', '', 'Users that already have a Cohere account and are not part of your team cannot be invited to join your team at this time. ', 'Users have permissions to: ', 'In addition to the above, Owners have permissions to:', 'Crucially, users are abstracted from accessing Production API key details to ensure security.']",https://docs.cohere.ai/reference/teams-and-roles,Teams and Roles,API Reference,User Documentation
"['The API currently uses very simple dated versioning in the format YYYY-MM-DD. This is not to be confused with our model-versioning which is independent. All model versions are compatible with all API versions. The version must match absolutely to be applied, eg if 2022-12-06 is a version and you input 2022-12-07, the API will return an error.', 'The version is supplied via a Cohere-Version header and is used as following;', 'If no version is supplied in the header, then the API will default to no version, meaning pre-2021-11-08. Important note that the SDKs will default you to the most recent version, which is currently 2022-12-06.', 'Removes the confidences array from the response of Classify in favor of the labels map.', 'This version introduces multiple generations, meaning that the generations endpoint will now accept a num_generations argument in the JSON and will always return an array of generations. See generate reference for details.', 'See specific endpoint documentation for details on how no version behaves.']",https://docs.cohere.ai/reference/versioning,Versioning,API Reference,User Documentation
"['Cohere uses conventional HTTP response codes to indicate the success or failure of an API request. In general:', 'With a non-2xx response code, the response will be an error object in the following shape:', 'Here are code examples for how error handling might look in our SDKs:']",https://docs.cohere.ai/reference/errors,Errors,API Reference,User Documentation
"['This endpoint generates realistic text conditioned on a given input.', 'The Generate endpoint generates text given an input, called a prompt. The prompt provides a context for the text that we want the model to generate.', 'Prompt engineering is a fascinating topic. It is about figuring out the optimal way to prompt a model for a particular task, so we can shape the output to be how we want it to be.', 'In this example, we have a startup idea generator. We want the endpoint to generate a startup idea and its name, given an industry/vertical as the input.', ""Install the SDK, if you haven't already."", 'Next, set up the Cohere client.', 'A basic prompt format that generally works well contains: ', 'The Generate endpoint has a number of settings we can use to control the kind of output it generates. The full list is available in the API reference, but let’s look at a few:\nmodel - Either medium or xlarge. Generally, smaller models are faster while larger models will perform better.\nmax_tokens - The maximum length of text to be generated. One word contains approximately 2-3 tokens.\ntemperature - Ranges from 0 to 5. Controls the randomness of the output. Lower values tend to generate more “predictable” output, while higher values tend to generate more “creative” output. The sweet spot is typically between 0 and 1.\nstop_sequences - A stop sequence will cut off your generation at the end of the sequence. This effectively informs the model of when to stop. Add your stop sequence at the end of each example in the prompt (refer to the prompt we’d created, which uses “--” as the stop sequence).', 'Call the Generate endpoint via the co.generate() method, specifying the prompt and the rest of the model settings.']",https://docs.cohere.ai/reference/generate,/generate,API Reference,User Documentation
"['This endpoint generates realistic text conditioned on a given input.', 'The Generate endpoint generates text given an input, called a prompt. The prompt provides a context for the text that we want the model to generate.', 'Prompt engineering is a fascinating topic. It is about figuring out the optimal way to prompt a model for a particular task, so we can shape the output to be how we want it to be.', 'In this example, we have a startup idea generator. We want the endpoint to generate a startup idea and its name, given an industry/vertical as the input.', ""Install the SDK, if you haven't already."", 'Next, set up the Cohere client.', 'A basic prompt format that generally works well contains: ', 'The Generate endpoint has a number of settings we can use to control the kind of output it generates. The full list is available in the API reference, but let’s look at a few:\nmodel - Either medium or xlarge. Generally, smaller models are faster while larger models will perform better.\nmax_tokens - The maximum length of text to be generated. One word contains approximately 2-3 tokens.\ntemperature - Ranges from 0 to 5. Controls the randomness of the output. Lower values tend to generate more “predictable” output, while higher values tend to generate more “creative” output. The sweet spot is typically between 0 and 1.\nstop_sequences - A stop sequence will cut off your generation at the end of the sequence. This effectively informs the model of when to stop. Add your stop sequence at the end of each example in the prompt (refer to the prompt we’d created, which uses “--” as the stop sequence).', 'Call the Generate endpoint via the co.generate() method, specifying the prompt and the rest of the model settings.']",https://docs.cohere.ai/reference/generate,Co.Generatepost,API Reference,User Documentation
"['This endpoint returns text embeddings. An embedding is a list of floating point numbers that captures semantic information about the text that it represents.', 'Embeddings can be used to create text classifiers as well as empower semantic search. To learn more about embeddings, see the embedding page.', 'The Embed endpoint takes a piece of text and turns it into a vector embedding. Embeddings represent text in the form of numbers that capture its meaning and context. This gives us the ability to turn unstructured text data into a structured form that can be processed and analyzed.']",https://docs.cohere.ai/reference/embed,/embed,API Reference,User Documentation
"['This endpoint returns text embeddings. An embedding is a list of floating point numbers that captures semantic information about the text that it represents.', 'Embeddings can be used to create text classifiers as well as empower semantic search. To learn more about embeddings, see the embedding page.', 'The Embed endpoint takes a piece of text and turns it into a vector embedding. Embeddings represent text in the form of numbers that capture its meaning and context. This gives us the ability to turn unstructured text data into a structured form that can be processed and analyzed.']",https://docs.cohere.ai/reference/embed,Co.Embedpost,API Reference,User Documentation
"['This endpoint makes a prediction about which label fits the specified text inputs best. To make a prediction, Classify uses the provided examples of text + label pairs as a reference.', ""Note: Custom Models trained on classification examples don't require the examples parameter to be passed in explicitly."", 'Install the SDK.', 'Set up the Cohere client.', 'These are the training examples we give the model to show the classes we want it to classify. Each example contains the text itself and the corresponding label, or class. The minimum number of examples required is two per class.', 'These are the list of text pieces you’d like to classify.', 'With the Classify endpoint, setting up the model is quite straightforward. The main thing to do is to define the model type. For our example, we’ll use the default, which is medium. Putting everything together with the Classify endpoint looks like the following:']",https://docs.cohere.ai/reference/classify,/classify,API Reference,User Documentation
"['This endpoint makes a prediction about which label fits the specified text inputs best. To make a prediction, Classify uses the provided examples of text + label pairs as a reference.', ""Note: Custom Models trained on classification examples don't require the examples parameter to be passed in explicitly."", 'Install the SDK.', 'Set up the Cohere client.', 'These are the training examples we give the model to show the classes we want it to classify. Each example contains the text itself and the corresponding label, or class. The minimum number of examples required is two per class.', 'These are the list of text pieces you’d like to classify.', 'With the Classify endpoint, setting up the model is quite straightforward. The main thing to do is to define the model type. For our example, we’ll use the default, which is medium. Putting everything together with the Classify endpoint looks like the following:']",https://docs.cohere.ai/reference/classify,Co.Classifypost,API Reference,User Documentation
"['This endpoint splits input text into smaller units called tokens using byte-pair encoding (BPE). To learn more about tokenization and byte pair encoding, see the tokens page.']",https://docs.cohere.ai/reference/tokenize,/tokenize,API Reference,User Documentation
"['This endpoint splits input text into smaller units called tokens using byte-pair encoding (BPE). To learn more about tokenization and byte pair encoding, see the tokens page.']",https://docs.cohere.ai/reference/tokenize,Co.Tokenizepost,API Reference,User Documentation
"['This endpoint takes tokens using byte-pair encoding and returns their text representation. To learn more about tokenization and byte pair encoding, see the tokens page.']",https://docs.cohere.ai/reference/detokenize-1,/detokenize,API Reference,User Documentation
"['This endpoint takes tokens using byte-pair encoding and returns their text representation. To learn more about tokenization and byte pair encoding, see the tokens page.']",https://docs.cohere.ai/reference/detokenize-1,Co.Detokenizepost,API Reference,User Documentation
"['The Cohere Platform CLI Tool is an alternative to our web interface, which allows you to login to your Cohere account, manage API Keys, and run finetunes.', ""This CLI tool is POSIX compliant (you can expect arguments and flags to work the same as they do with other popular CLI tools). Don't forget to use co --help or co [COMMAND] --help if you don't want to check back to this page!"", 'Use the following curl command to download the correct package, or use a download link below to get a tar.']",https://docs.cohere.ai/reference/command,Installation,API Reference,User Documentation
"['This endpoint classifies text into one of several classes. It uses a few examples to create a classifier from a generative model. In the background, it constructs a few-shot classification prompt and uses it classify the input texts you pass to it.', 'This is an interactive tutorial!', 'To run this tutorial, click on Examples and select one of the options.', 'Sentiment analysis is a type of classification task that analyzes the tone of a piece of text. It is used in a variety of different ways, or example, on social media comments and customer reviews. It is commonly used to see how people feel about their products or company, but it can also be used to help businesses understand how different trends in the economy may impact their business.', 'Here we look at an example of analyzing the sentiments of customer feedback about a product into Positive, Negative, or Neutral.', 'Install the SDK', 'Set up the Cohere client.', 'These are the list of text pieces you’d like to classify.', 'With the Classify endpoint, setting up the model is quite straightforward. The main thing to do is to define the model type. For our example, we’ll use the default, which is medium. Putting everything together with the Classify endpoint looks like the following:']",https://docs.cohere.ai/reference/sentiment-analysis,/classify,API Reference,User Documentation
"['This endpoint classifies text into one of several classes. It uses a few examples to create a classifier from a generative model. In the background, it constructs a few-shot classification prompt and uses it classify the input texts you pass to it.', 'This is an interactive tutorial!', 'To run this tutorial, click on Examples and select one of the options.', 'Sentiment analysis is a type of classification task that analyzes the tone of a piece of text. It is used in a variety of different ways, or example, on social media comments and customer reviews. It is commonly used to see how people feel about their products or company, but it can also be used to help businesses understand how different trends in the economy may impact their business.', 'Here we look at an example of analyzing the sentiments of customer feedback about a product into Positive, Negative, or Neutral.', 'Install the SDK', 'Set up the Cohere client.', 'These are the list of text pieces you’d like to classify.', 'With the Classify endpoint, setting up the model is quite straightforward. The main thing to do is to define the model type. For our example, we’ll use the default, which is medium. Putting everything together with the Classify endpoint looks like the following:']",https://docs.cohere.ai/reference/sentiment-analysis,Sentiment Analysispost,API Reference,User Documentation
"['This endpoint classifies text into one of several classes. It uses a few examples to create a classifier from a generative model. In the background, it constructs a few-shot classification prompt and uses it classify the input texts you pass to it.', 'This is an interactive tutorial!', 'To run this tutorial, click on Examples and select one of the options.', 'Chatbots are designed to understand and respond to human language. They need to be able to understand the text they hear and understand the context of the conversation. They also need to be able to respond to people’s questions and comments in a meaningful way. To accomplish this, chatbots must be able to recognize specific intents that people express in conversation.', 'Here is an example of classifying the intent of customer inquiries on an eCommerce website into Shipping and handling policy, Start return or exchange, or Track order.', 'Install the SDK.', 'Set up the Cohere client.', 'These are the training examples we give the model to show the classes we want it to classify. Each example contains the text itself and the corresponding label, or class. The minimum number of examples required is five per class.', 'These are the list of text pieces you’d like to classify.', 'With the Classify endpoint, setting up the model is quite straightforward. The main thing to do is to define the model type. For our example, we’ll use the default, which is medium. Putting everything together with the Classify endpoint looks like the following:']",https://docs.cohere.ai/reference/intent-recognition,/classify,API Reference,User Documentation
"['This endpoint classifies text into one of several classes. It uses a few examples to create a classifier from a generative model. In the background, it constructs a few-shot classification prompt and uses it classify the input texts you pass to it.', 'This is an interactive tutorial!', 'To run this tutorial, click on Examples and select one of the options.', 'Chatbots are designed to understand and respond to human language. They need to be able to understand the text they hear and understand the context of the conversation. They also need to be able to respond to people’s questions and comments in a meaningful way. To accomplish this, chatbots must be able to recognize specific intents that people express in conversation.', 'Here is an example of classifying the intent of customer inquiries on an eCommerce website into Shipping and handling policy, Start return or exchange, or Track order.', 'Install the SDK.', 'Set up the Cohere client.', 'These are the training examples we give the model to show the classes we want it to classify. Each example contains the text itself and the corresponding label, or class. The minimum number of examples required is five per class.', 'These are the list of text pieces you’d like to classify.', 'With the Classify endpoint, setting up the model is quite straightforward. The main thing to do is to define the model type. For our example, we’ll use the default, which is medium. Putting everything together with the Classify endpoint looks like the following:']",https://docs.cohere.ai/reference/intent-recognition,Intent Recognitionpost,API Reference,User Documentation
"['This endpoint classifies text into one of several classes. It uses a few examples to create a classifier from a generative model. In the background, it constructs a few-shot classification prompt and uses it classify the input texts you pass to it.', 'This is an interactive tutorial!', 'To run this tutorial, click on Examples and select one of the options.', 'The internet is dominated by user-generated content. While it provides an avenue for online platforms to grow, it is a bane for content moderators managing them. It is impossible for humans to manually moderate all the user content that is created. This is why an automated solution is needed, such as in flagging for toxic content.', 'Here we look at an example of classifying online user comments for toxicity by classifying them in Toxic or Not Toxic.', 'Install the SDK.', 'Set up the Cohere client.', 'These are the training examples we give the model to show the classes we want it to classify. Each example contains the text itself and the corresponding label, or class. The minimum number of examples required is five per class.', 'These are the list of text pieces you’d like to classify.', 'With the Classify endpoint, setting up the model is quite straightforward. The main thing to do is to define the model type. For our example, we’ll use the default, which is medium. Putting everything together with the Classify endpoint looks like the following:']",https://docs.cohere.ai/reference/toxicity-detection,/classify,API Reference,User Documentation
"['This endpoint classifies text into one of several classes. It uses a few examples to create a classifier from a generative model. In the background, it constructs a few-shot classification prompt and uses it classify the input texts you pass to it.', 'This is an interactive tutorial!', 'To run this tutorial, click on Examples and select one of the options.', 'The internet is dominated by user-generated content. While it provides an avenue for online platforms to grow, it is a bane for content moderators managing them. It is impossible for humans to manually moderate all the user content that is created. This is why an automated solution is needed, such as in flagging for toxic content.', 'Here we look at an example of classifying online user comments for toxicity by classifying them in Toxic or Not Toxic.', 'Install the SDK.', 'Set up the Cohere client.', 'These are the training examples we give the model to show the classes we want it to classify. Each example contains the text itself and the corresponding label, or class. The minimum number of examples required is five per class.', 'These are the list of text pieces you’d like to classify.', 'With the Classify endpoint, setting up the model is quite straightforward. The main thing to do is to define the model type. For our example, we’ll use the default, which is medium. Putting everything together with the Classify endpoint looks like the following:']",https://docs.cohere.ai/reference/toxicity-detection,Toxicity Detectionpost,API Reference,User Documentation
"['This endpoint classifies text into one of several classes. It uses a few examples to create a classifier from a generative model. In the background, it constructs a few-shot classification prompt and uses it classify the input texts you pass to it.', 'This is an interactive tutorial!', 'To run this tutorial, click on Examples and select one of the options.', 'Customer support tickets can come from all directions, and manually analyzing and routing information is an overwhelming job. A text classification system can help support teams accelerate this process. It can augment a team’s capacity by automatically assigning each ticket to the right type or next action.', 'Here we look at an example of classifying customer emails to an insurance company into four types of requests, Finding policy details, Change account settings, Filing a claim and viewing status, and Cancelling coverage.', 'Install the SDK.', 'Set up the Cohere client.', 'These are the training examples we give the model to show the classes we want it to classify. Each example contains the text itself and the corresponding label, or class. The minimum number of examples required is two per class.', 'These are the list of text pieces you’d like to classify.', 'With the Classify endpoint, setting up the model is quite straightforward. The main thing to do is to define the model type. For our example, we’ll use the default, which is medium. Putting everything together with the Classify endpoint looks like the following:']",https://docs.cohere.ai/reference/customer-support,/classify,API Reference,User Documentation
"['This endpoint classifies text into one of several classes. It uses a few examples to create a classifier from a generative model. In the background, it constructs a few-shot classification prompt and uses it classify the input texts you pass to it.', 'This is an interactive tutorial!', 'To run this tutorial, click on Examples and select one of the options.', 'Customer support tickets can come from all directions, and manually analyzing and routing information is an overwhelming job. A text classification system can help support teams accelerate this process. It can augment a team’s capacity by automatically assigning each ticket to the right type or next action.', 'Here we look at an example of classifying customer emails to an insurance company into four types of requests, Finding policy details, Change account settings, Filing a claim and viewing status, and Cancelling coverage.', 'Install the SDK.', 'Set up the Cohere client.', 'These are the training examples we give the model to show the classes we want it to classify. Each example contains the text itself and the corresponding label, or class. The minimum number of examples required is two per class.', 'These are the list of text pieces you’d like to classify.', 'With the Classify endpoint, setting up the model is quite straightforward. The main thing to do is to define the model type. For our example, we’ll use the default, which is medium. Putting everything together with the Classify endpoint looks like the following:']",https://docs.cohere.ai/reference/customer-support,Customer Supportpost,API Reference,User Documentation
"['This endpoint generates realistic text conditioned on a given input.', 'This is an interactive tutorial!', 'To run this tutorial, click on Examples and select one of the options.', 'The goal of text summarization is to condense the original text into a shorter version that retains the most important information. In this example, we want to summarize a passage from a news article into its main point.', ""Install the SDK, if you haven't already."", 'Next, set up the Cohere client.', 'Create a prompt consisting of a few examples passages and their summaries.', 'The Generate endpoint has a number of settings you can use to control the kind of output it generates. The full list is available in the API reference, but let’s look at a few:', 'Call the Generate endpoint via the co.generate() method, specifying the prompt and the rest of the model settings.']",https://docs.cohere.ai/reference/text-summarization-example,/generate,API Reference,User Documentation
"['This endpoint generates realistic text conditioned on a given input.', 'This is an interactive tutorial!', 'To run this tutorial, click on Examples and select one of the options.', 'The goal of text summarization is to condense the original text into a shorter version that retains the most important information. In this example, we want to summarize a passage from a news article into its main point.', ""Install the SDK, if you haven't already."", 'Next, set up the Cohere client.', 'Create a prompt consisting of a few examples passages and their summaries.', 'The Generate endpoint has a number of settings you can use to control the kind of output it generates. The full list is available in the API reference, but let’s look at a few:', 'Call the Generate endpoint via the co.generate() method, specifying the prompt and the rest of the model settings.']",https://docs.cohere.ai/reference/text-summarization-example,Text Summarizationpost,API Reference,User Documentation
"When an account is created, we automatically create an Trial API key for you. This API key will be available on the dashboard for you to copy, as well as in the dashboard section called “API Keys",https://cohere.ai/pricing#freqAskedQuestion,Pricing,Pricing,User Documentation
"To get a Production key, you'll need to have Owner privileges (or ask your organization Owner to complete the following steps). Navigate to the Billing and Usage page in your Cohere dashboard. Click on the Get Your Production key button and fill out the Go to Production workflow.",https://cohere.ai/pricing#freqAskedQuestion,Pricing,Pricing,User Documentation
"A Trial API key has a rate limit of 100 calls per minute, and a Production API key has a rate limit of 10,000 calls per minute. API calls made from a Trial API key are free and there are no limitations to how many calls you make. API calls made from a Production API key will be charged on a pay-as-you-go basis. Trial keys are not permitted to be used for production or commercial purposes.",https://cohere.ai/pricing#freqAskedQuestion,Pricing,Pricing,User Documentation
"Every account begins as a personal account and only has access to Trial API keys.  As a personal account, you will not be able to add other members until you become part of an organization.",https://cohere.ai/pricing#freqAskedQuestion,Pricing,Pricing,User Documentation
"At Cohere, an organization is a group of personal accounts that share a singular billing portal. Organizations are not automatically given Production API key access, and a member of the organization must still fill out our application form for production access. Personal accounts cannot share billing information with other accounts.",https://cohere.ai/pricing#freqAskedQuestion,Pricing,Pricing,User Documentation
"Your model selection reflects your relative prioritization of model performance and speed. Larger models offer better performance and are capable of more complex tasks, while smaller models have faster response times.",https://cohere.ai/pricing#freqAskedQuestion,Pricing,Pricing,User Documentation
API calls made from a Trial API key will be free. API calls made from a Production key will be billed on a pay-as-you-go basis. Your bill will be issued at the end of every calendar month.,https://cohere.ai/pricing#freqAskedQuestion,Pricing,Pricing,User Documentation
"Organize information for more effective content moderation, analysis and chat bot experiences. Access large language models that can understand text and take appropriate action — like highlight a post that violates your community guidelines, or trigger accurate chatbot responses. Just set your parameters, and Classify will do the rest.",https://cohere.ai/classify,Classify,Endpoints,Product Documentation
"The power of understanding, Classify uses cutting-edge machine learning to analyze and bucket text into specific categories. Build automated text classifiers into your application to do things like identify toxic language, automatically route customer queries, or detect breaking trends in product reviews.",https://cohere.ai/classify,Classify,Endpoints,Product Documentation
"Keep your community safe, Use Classify to identify hate speech, abusive language, spam, profanity, or anything that meets user-provided filters.",https://cohere.ai/classify,Classify,Endpoints,Product Documentation
"Harness intent recognition, Leverage Classify to triage inbound chatbot or email requests to understand user intent and automatically issue responses.",https://cohere.ai/classify,Classify,Endpoints,Product Documentation
"Serve your customers better, save time by tasking Classify to route inbound customer support requests to their respective teams.",https://cohere.ai/classify,Classify,Endpoints,Product Documentation
"Access industry-leading sentiment analysis, develop a stronger customer affinity by classifying posts, reviews, etc to understand how they perceive your company/brand.",https://cohere.ai/classify,Classify,Endpoints,Product Documentation
"Integrate large language models into your builds,  we’ve made an API that can be used in different libraries that fit every stack. No matter your level of developer experience, Cohere makes it easy to build machine learning into your application with our Python, Node, and Go SDKs. Start now Our platform can be plugged into any library, making it possible for NLP to be integrated into every build ",https://cohere.ai/classify,Classify,Endpoints,Product Documentation
"Large language models, our models have been trained on billions of words, allowing them to understand nuance and context.",https://cohere.ai/classify,Classify,Endpoints,Product Documentation
"Make it yours, our models have read billions and billions of words. But they can be made even more effective with a little input from you. Our finetuning feature allows you to tweak our base models to make them more applicable to your specific task or domain.",https://cohere.ai/classify,Classify,Endpoints,Product Documentation
"Meet your AI-generated content writer, generate is powered by a large language model that has read billions of words, learning the patterns and idiosyncrasies of sentences. Using this knowledge, it writes content, predicts outcomes or answers questions at your command.",https://cohere.ai/generate,Generate,Endpoints,Product Documentation
"Reading billions of words, to write the ones you need. The Generate API is trained on vast amounts of text spanning all topics and industries. With Generate, you ‘instruct’ the model with your specific text generation ask. This could be a copywriting task, named entity recognition, or even paraphrasing or summarization.",https://cohere.ai/generate,Generate,Endpoints,Product Documentation
"Write ads and descriptions faster, use Generate to perform time-consuming and repetitive copywriting tasks, like product descriptions or email responses.",https://cohere.ai/generate,Generate,Endpoints,Product Documentation
"Paraphrase sentences and paragraphs, generate allows you to re-word text to suit a specific reader, or reformat existing content into unique pieces.",https://cohere.ai/generate,Generate,Endpoints,Product Documentation
"Make the world bite-sized, use Generate to automatically condense key information from texts into digestible summaries.",https://cohere.ai/generate,Generate,Endpoints,Product Documentation
"Find what you're looking for, use our models to identify and extract specific data defined by your unique business needs.",https://cohere.ai/generate,Generate,Endpoints,Product Documentation
"Make it yours, our models have read billions and billions of words. But they can be made even more effective with a little training from you. Finetuning is when you teach a model niche knowledge through text examples — industry context, typical language and words used, common questions and answers, all of which improve the model’s accuracy and context.",https://cohere.ai/generate,Generate,Endpoints,Product Documentation
"Uncover trends and patterns in text, turn text into numerical representations of language for deeper insights at scale. Embed makes it possible to algorithmically categorize and score text quickly to extract meaning.",https://cohere.ai/embed,Embed,Endpoints,Product Documentation
"How It Works, Embeddings are numerical representations of meaning in text. Because they are numbers, they can be compared to each other for similarity. They can also be plotted on a chart that shows which texts are similar to each other. Large language models produce highly nuanced embeddings.",https://cohere.ai/embed,Embed,Endpoints,Product Documentation
"Semantic Search, enable users to search using conversational language",https://cohere.ai/embed,Embed,Endpoints,Product Documentation
"Topic Modeling, cluster similar topics and discover thematic trends across a body of text sources.",https://cohere.ai/embed,Embed,Endpoints,Product Documentation
"Recommendations,bBuild a recommendation engine and engage your users with more relevant content.",https://cohere.ai/embed,Embed,Endpoints,Product Documentation
"Multilingual embeddings, run topic modeling, semantic search, recommendations across 100+ languages with just one model.",https://cohere.ai/embed,Embed,Endpoints,Product Documentation
"Build better customer relationships, with the help of NLP. It’s easy to build customer love when things go right. But when things go wrong, your customer service needs to step up. Natural language processing (NLP) can help teams deliver at scale. By understanding the meaning behind text, Cohere can automatically route inbound inquiries, making it easier for customer support teams to step in and resolve issues quickly.",https://cohere.ai/use-case-customer-support,Customer Support,Use Cases,Product Documentation
"The tyranny of tickets, when it comes to customer service, support teams can find themselves in a flurry of endless tickets. Requests can come from all angles, and organizing them is a gargantuan task. Manual text analysis and routing processes take a lot of time. Team members need to read and understand what a query is about, such as billing, account lockouts, or technical issues, before sending the issue on to the appropriate owner. Meanwhile, customers are left waiting.",https://cohere.ai/use-case-customer-support,Customer Support,Use Cases,Product Documentation
"Cohere: Speaking the language of customer service, Cohere’s enterprise-grade NLP platform can help any business automate the processing of text-based customer communications. Whether it’s a few hundred emails, or hundreds of thousands of messages across multiple channels, Cohere can quickly read, understand, and organize them all — so customer service teams can take fast action.",https://cohere.ai/use-case-customer-support,Customer Support,Use Cases,Product Documentation
"Cohere gives every developer easy access to NLP. We’ve made an API that works with every stack. No matter your level of developer experience, the Cohere Platform makes it easy to integrate machine learning into your applications and systems with our Python, Node, and Go SDKs. Our versatile NLP platform offers three endpoints for generation, classification, or embedding text data at massive scale. Developers can then use Cohere's endpoints to handle specific tasks, such as text analysis, text classification, and topic labeling.",https://cohere.ai/use-case-customer-support,Customer Support,Use Cases,Product Documentation
"Use Cohere’s Classify for text analysis and topic labeling. Starting from the same Transformer architecture as Google’s Search and Translate, Cohere’s Classify endpoint can analyze and label incoming text (like customer requests) based on a predefined set of relevant categories (like billing, accounts, technical, feature request, or how-to). Behind the scenes are Cohere’s large language models, which developers can further finetune with their own dataset per their business or industry. Here's how it works, set the road rules: Define the issue types relevant to your business. Then, train Classify with examples of customer requests for each of these categories. This helps our model understand the different words and phrases that your customers are using to describe their issues. Start the engine: Classify then uses this knowledge to automatically parse all inbound customer requests (text analysis), determine the specific issue type for each one (text classification), and organize them by issue type (topic labeling). Get driving: Once the classification process is complete, you can use that data to route each request to the team or agent best suited to handle an issue type. Or, improve your auto-responder workflow to offer self-service help options to your customers. Give your customers and team time back in their day. Using Classify to automate inquiry routing can truly transform your service operations. For your customers, quick resolution of their problems helps to build brand loyalty and affinity. For your customer support team, an automated triage system improves speed, efficiency, and productivity — all at scale",https://cohere.ai/use-case-customer-support,Customer Support,Use Cases,Product Documentation
"Focus on the hard stuff, By automatically responding to simple inquiries with relevant help articles, Classify enables agents to spend more time where their skills are needed — on complex problems. Make it personalized, unlike the limited sorting solutions offered by help desk platforms, Cohere lets you define your own issue types and categories. Whether you need broad categories, or prefer a more granular approach, Classify works for you. Not the other way around.",https://cohere.ai/use-case-customer-support,Customer Support,Use Cases,Product Documentation
"Understand your customers better with sentiment analysis, understanding how people feel about products, companies, and brands is critical to success. But it’s hard to distill useful insights from the many ways that people express themselves. Language AI, a subset of Natural language processing (NLP), can help analyze them all. Large language models, like those that power Cohere, can be used to build sentiment analysis tools to quickly give you insights into consumer attitudes, so you can devise new product strategies, respond quickly to brand risks, and drive growth.",https://cohere.ai/use-case-sentiment-analysis,Sentiment Analysis,Use Cases,Product Documentation
"A black hole of reviews, today, businesses gain insight from structured data from surveys, NPS, or customer ratings, but that’s only part of the picture. To better understand user sentiment, they need to tap into the wealth of publicly available, free-form commentary from customers, influencers, analysts, news media, and others. This becomes even more important during a product launch or high-profile incident. But analyzing thousands of qualitative, anecdotal comments isn’t always feasible for marketing or communications teams. It’s labor intensive and time consuming, leaving less time for other tasks. However, by excluding this data, brands often miss meaningful customer feedback and insights.",https://cohere.ai/use-case-sentiment-analysis,Sentiment Analysis,Use Cases,Product Documentation
"Cohere: Giving all your customers a voice. Cohere’s enterprise-grade NLP platform can help any business analyze public sentiment across the internet in real time. Whether people share thoughts on social media, product reviews, blogs, articles, or other sources, Cohere can read and understand their meaning and sentiment, and then classify and organize the data. As a result, business stakeholders can respond more quickly and effectively.",https://cohere.ai/use-case-sentiment-analysis,Sentiment Analysis,Use Cases,Product Documentation
"Use Cohere’s Classify for sentiment analysis at scale, starting from the same Transformer architecture as Google’s Search and Translate, Cohere’s Classify endpoint can quickly read, understand, and identify the sentiment behind millions of pieces of unstructured text, classifying it as positive, negative, or neutral. Behind the scenes, Cohere’s large language models are continuously learning emerging language patterns and trends that convey sentiment. Developers can further finetune Cohere’s large language models with their own dataset per their business or industry. Set the road rules, define the different sentiment categories that you’re looking to label (think positive, negative, and neutral). Secondly, identify your data sources and train Classify with examples for each category. Start the engine, Classify then sorts inbound text snippets from your data sources into sentiment categories — all in real time. Get driving, with quantified sentiment data at hand, you can then use it to derive valuable insights that can better inform decision-making.",https://cohere.ai/use-case-sentiment-analysis,Sentiment Analysis,Use Cases,Product Documentation
"Leverage more data for deeper analysis, when it comes to data, more is better. Gathering data across the broad landscape of public feedback, opinions, attitudes, and desires helps you better understand your market. With Cohere’s Classify, you can build robust, AI-powered sentiment analysis tools that empower those teams who need to make data-driven decisions.",https://cohere.ai/use-case-sentiment-analysis,Sentiment Analysis,Use Cases,Product Documentation
"Drive insights from gargantuan amounts of data, Cohere can process large volumes of text without the need for spreadsheets or manual sorting. By automating sentiment analysis, you can unlock previously untapped data sources. Make decisions with real-time data, identify sentiment trends as they happen. Cohere can automatically process user-generated content as it becomes available and flag if there’s any sudden change in customer sentiment.",https://cohere.ai/use-case-sentiment-analysis,Sentiment Analysis,Use Cases,Product Documentation
"Product-led companies, using Cohere’s Classify, your product teams can analyze customer comments in marketplaces, social media, product review sites, and others to uncover how customers feel about the usability or functionality of your products. They can further train Classify to identify the feature requests or improvements that elicited the highest emotional score from your customers, and use them to prioritize your product roadmap.",https://cohere.ai/use-case-sentiment-analysis,Sentiment Analysis,Use Cases,Product Documentation
"Marketing & communications teams, Sentiment analysis powered by Cohere can help your brand marketers determine whether their brand strategies are resonating with customers or falling short. Influencer marketers can identify product evangelists across owned product sites, marketplaces, and more. And communications teams can glean insights from public attitudes that can help them protect the reputation of your brand and company.",https://cohere.ai/use-case-sentiment-analysis,Sentiment Analysis,Use Cases,Product Documentation
"Capital market businesses, quant funds, hedge funds, fintech platforms, and other financial service providers can use Cohere’s Classify to analyze a range of unstructured financial data sources, such as transcripts from earnings calls and Q&A or analyst reports. By understanding the public sentiment around particular companies or markets, firms can make better informed investment decisions.",https://cohere.ai/use-case-sentiment-analysis,Sentiment Analysis,Use Cases,Product Documentation
"Improve intent recognition in chatbot conversations, communicating with a chatbot can be a frustrating experience when we don’t ask questions in a way that the bot expects. Natural language processing (NLP) can help bridge the gap. Cohere helps chatbot applications understand the meaning behind a unique turn of phrase or the tonality of a reply, allowing the bot to address a customer’s needs with greater speed and accuracy.",https://cohere.ai/use-case-intent-recognition,Intent Recognition,Use Cases,Product Documentation
"Keywords aren’t enough. Many chatbot platforms are powered by basic keyword recognition. This means that the bot’s ability to “understand” queries is dependent upon customers using very specific phrases. Developers could augment this by painstakingly predicting the myriad ways that a customer could phrase a specific query, including slang, misspellings, and differences in context. However, that task would be time consuming, if not downright impossible",https://cohere.ai/use-case-intent-recognition,Intent Recognition,Use Cases,Product Documentation
"Billions of examples, Cohere’s models are trained on billions of sentences, allowing them to understand and recognize the intent behind a specific phrase. Our models excel at intent recognition tasks and can power sophisticated chatbots that move beyond basic keyword recognition.",https://cohere.ai/use-case-intent-recognition,Intent Recognition,Use Cases,Product Documentation
"Cohere: Continuously learning from billions of examples, at the heart of Cohere’s enterprise-grade NLP platform are large language models trained on billions of words, enabling them to recognize and understand the meaning behind a specific phrase. Cohere’s models excel at intent recognition tasks and can power sophisticated chatbots that deliver great user experiences.",https://cohere.ai/use-case-intent-recognition,Intent Recognition,Use Cases,Product Documentation
"Use Cohere’s Classify for intent recognition and text classification. Starting from the same Transformer architecture as Google’s Search and Translate, Cohere’s Classify endpoint can read, understand, and label the intent behind unstructured customer queries with exceptional speed and accuracy. Developers can further finetune Cohere’s large language models with their own dataset per their business or industry. Set the road rules, define your core customer intent categories, and train Cohere’s Classify model by providing it with example customer queries for each category. Start the engine, Classify then combines this custom understanding of your intent categories with a deep understanding of language and context provided by our large language models to create a finetuned model, ready to handle your customer data. Get driving, every time a user enters a prompt into your chatbot, Cohere will classify the request by intent, allowing your bot to provide the most relevant answer back.",https://cohere.ai/use-case-intent-recognition,Intent Recognition,Use Cases,Product Documentation
"With Cohere’s Classify, your AI-powered chatbots or conversational tools can consistently and accurately detect the intent behind user requests — including compound queries with multiple data points to consider. As a result, your bots are more intelligent and your customers are more satisfied with their interaction with your business.",https://cohere.ai/use-case-intent-recognition,Intent Recognition,Use Cases,Product Documentation
"Ensure your chatbots speak the same language as your customers, making Cohere a part of your chatbot experience benefits both your customers and your team by Direct your agents where they’re needed, by automating first-pass responses and routine tasks, customer support teams have more time to handle complex one-off or multi-threaded interaction. Give your customers the answers they want, by training chatbots to better understand customer queries, your customers can get accurate, timely information and your support team can improve their time to resolution metrics. Make it personalized, ensure that all your customers are considered by finetuning and deploying Cohere to serve different needs.",https://cohere.ai/use-case-intent-recognition,Intent Recognition,Use Cases,Product Documentation
"Identify toxic language in online communities using NLP, toxicity pervades every online community, creating unsafe spaces and driving people away from platforms. Natural language processing (NLP) can help stem the tide. Cohere helps online platforms identify toxic language and build content moderation solutions that are fit for purpose, so they can focus on delivering amazing user experiences.",https://cohere.ai/use-case-toxic-language,Toxic Language,Use Cases,Product Documentation
"Catch me if you can, content moderation tools already exist. But it’s difficult to get ahead of online toxicity because it’s ever-evolving. New terminology pops up. Users find ways to work around word or phrase bans. And every community has different guidelines based on its audience or content. It’s a complex problem that is currently being met with rudimentary AI or keyword search. But these often allow nuanced (e.g., an insult that requires an understanding of pop culture) or nonuniform (e.g., a slur deliberately spelled incorrectly) hate speech to slip through the net.",https://cohere.ai/use-case-toxic-language,Toxic Language,Use Cases,Product Documentation
"Cohere: Rooting out toxicity in community discourse. Cohere’s enterprise-grade NLP platform helps businesses of all types identify toxic language across millions of online conversations with greater breadth and accuracy. Even as people find new ways to hide toxic speech, Cohere can quickly identify it, so content moderation teams can gain insight and build better strategies to minimize harm.",https://cohere.ai/use-case-toxic-language,Toxic Language,Use Cases,Product Documentation
"Use Cohere’s Classify for automated text classification, starting from the same Transformer architecture as Google’s Search and Translate, Cohere’s Classify endpoint can read and understand text-based conversations, and identify toxicity. Behind the scenes, Cohere’s large language models are continuously learning toxic language patterns, and can recognize when language is used casually or in a malicious manner. Developers can further finetune the models with their own data set per their business or industry. Set the road rules, first, train Classify by inputting a few example comments from your community. Then, mark each as either “Toxic” or “Non-toxic,” or by any other label that makes sense to your content moderation workflow, like “Violates Policy” or “Permissible.”. Start the engine, Classify uses this understanding to read and process millions of new comments (text analysis), determine which are toxic or non-toxic (text classification), and organize them based on the labels you set up (topic labeling). Get driving, Once the classification process is complete, you can then use that data in your content moderation workflow to automatically flag or remove toxic comments.",https://cohere.ai/use-case-toxic-language,Toxic Language,Use Cases,Product Documentation
"Make online communities safe for everyone. Toxicity is rife in many types of communities today. In multiplayer gaming, for example, four out of five players have experienced some form of harassment. By augmenting your content moderation stack with Cohere’s Classify, you can accelerate the fight against toxicity on your platform. As a result, you’ll be better equipped to build safer communities, minimize harmful content, and reduce churn.",https://cohere.ai/use-case-toxic-language,Toxic Language,Use Cases,Product Documentation
"Prevent customers from leaving your platform, People come to your platform to enjoy your content and build relationships, but toxic experiences drive many users away — often permanently. Cohere can help you increase retention by maintaining safe online spaces that make your users feel comfortable.",https://cohere.ai/use-case-toxic-language,Toxic Language,Use Cases,Product Documentation
"Build trust with your users, and the general public, Preserving the integrity of your brand and platform becomes more challenging as you increase your userbase. Leveraging Cohere allows you to crack down on toxic language in all its evolving forms — protecting your users, and your brand’s reputation.",https://cohere.ai/use-case-toxic-language,Toxic Language,Use Cases,Product Documentation
"Supercharge your moderation efforts, Content moderation teams are stretched thin by the ever-evolving problem of toxicity. Automating toxic language detection with Cohere enables you to reduce the burden on your team, gain deeper insight into trends, and take faster action to address harmful behavior.",https://cohere.ai/use-case-toxic-language,Toxic Language,Use Cases,Product Documentation
"Social media platforms, Cohere’s large language models are trained on billions of words and phrases across the Internet — including user-generated posts and comments. Classify can help you identify different forms of toxic content on your platform with confidence. As a result, your moderators are better able to mitigate the spread of hate speech, content that promotes violence, spam, profanity, and more.",https://cohere.ai/use-case-toxic-language,Toxic Language,Use Cases,Product Documentation
"Gaming platforms, most gamers want better solutions that enforce compliance with a game’s code of conduct. Using Cohere’s Classify to automate toxic language detection allows you to stay on top of bad behavior, flag language that’s inappropriate for younger players, and report incidents in a scalable and privacy-conscious manner. As a result, your community team is better able to execute your platform’s content moderation and banning policies.",https://cohere.ai/use-case-toxic-language,Toxic Language,Use Cases,Product Documentation
"Dating platforms, dating app users regularly block other profiles due to misbehavior and offensive content. But no one wants to feel like their private conversations are being read by another person. By using Cohere’s Classify to automatically flag toxic or inappropriate language, your users can feel safe on your platform while maintaining a sense of privacy.",https://cohere.ai/use-case-toxic-language,Toxic Language,Use Cases,Product Documentation
